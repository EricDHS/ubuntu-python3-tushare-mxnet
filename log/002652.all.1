Open
round is 0
0    6.09482
dtype: float32
Epoch 8, train loss: 0.34867477783051404 test loss: 0.46148073579307824
0    6.38164
dtype: float32
Epoch 9, train loss: 0.2785475703212734 test loss: 0.3769819653798835
0    6.381761
dtype: float32
Epoch 10, train loss: 0.24948841755866485 test loss: 0.31653459212772667
0    6.650545
dtype: float32
Epoch 11, train loss: 0.22141047687602605 test loss: 0.36434763084552185
0    6.28987
dtype: float32
Epoch 12, train loss: 0.26371608311474387 test loss: 0.4351376189700773
0    6.148433
dtype: float32
Epoch 13, train loss: 0.2730615587051115 test loss: 0.4256415093145675
0    6.636199
dtype: float32
Epoch 14, train loss: 0.1837423545484267 test loss: 0.295847527022316
0    7.260588
dtype: float32
Epoch 15, train loss: 0.10292827575136036 test loss: 0.17446000242904358
0    7.171488
dtype: float32
Epoch 16, train loss: 0.09560851963881278 test loss: 0.15741118371993956
0    7.592542
dtype: float32
Epoch 17, train loss: 0.07912333624417908 test loss: 0.16286563125441098
0    7.682508
dtype: float32
Epoch 18, train loss: 0.08559655266888022 test loss: 0.16919784310705566
0    7.500809
dtype: float32
Epoch 19, train loss: 0.07317446070280581 test loss: 0.14928492374089397
0    7.488822
dtype: float32
Epoch 20, train loss: 0.07397364671593318 test loss: 0.15873816365817303
0    7.768642
dtype: float32
Epoch 21, train loss: 0.09571861199145941 test loss: 0.1916090926082301
0    7.858594
dtype: float32
Epoch 22, train loss: 0.1057751701296384 test loss: 0.1959187624946045
0    7.839192
dtype: float32
Epoch 23, train loss: 0.10152308822914438 test loss: 0.1865896847880292
0    7.608356
dtype: float32
Epoch 24, train loss: 0.07697513234041414 test loss: 0.14324845958283383
0    7.740962
dtype: float32
Epoch 25, train loss: 0.09051059487175157 test loss: 0.16964564455110118
0    7.654995
dtype: float32
Epoch 26, train loss: 0.08637489456448093 test loss: 0.18213658823267542
0    7.511868
dtype: float32
Epoch 27, train loss: 0.0782984604838204 test loss: 0.1578613873447996
0    7.570967
dtype: float32
Epoch 28, train loss: 0.07889058492831111 test loss: 0.16019039940751562
0    7.646994
dtype: float32
Epoch 29, train loss: 0.09219761230651279 test loss: 0.18648828977883591
0    7.347701
dtype: float32
Epoch 30, train loss: 0.06449239650844338 test loss: 0.13514286783906557
0    7.765965
dtype: float32
Epoch 31, train loss: 0.0982427871843863 test loss: 0.17638195883356292
0    7.670273
dtype: float32
Epoch 32, train loss: 0.09957945131106662 test loss: 0.20967218085614442
0    7.823592
dtype: float32
Epoch 33, train loss: 0.1055544915531644 test loss: 0.20237591338039118
0    7.789637
dtype: float32
Epoch 34, train loss: 0.10156175867960725 test loss: 0.20436489972388855
0    7.888163
dtype: float32
Epoch 35, train loss: 0.1051170926208432 test loss: 0.191276202905018
0    7.626517
dtype: float32
Epoch 36, train loss: 0.07576711505244874 test loss: 0.14520086848300814
0    7.326618
dtype: float32
Epoch 37, train loss: 0.06217632807777507 test loss: 0.1293066253115625
0    7.530619
dtype: float32
Epoch 38, train loss: 0.07278784173009303 test loss: 0.15583338559170667
0    7.452562
dtype: float32
Epoch 39, train loss: 0.06496816973541647 test loss: 0.13009168573184252
0    7.068756
dtype: float32
Epoch 40, train loss: 0.0717476963503778 test loss: 0.1432196367856381
0    7.113845
dtype: float32
Epoch 41, train loss: 0.06276430411072424 test loss: 0.12894942489934538
0    7.038167
dtype: float32
Epoch 42, train loss: 0.0701447923985435 test loss: 0.13850546000056183
0    6.718522
dtype: float32
Epoch 43, train loss: 0.10433399480585748 test loss: 0.17714057603427186
0    6.674808
dtype: float32
Epoch 44, train loss: 0.10878194197934966 test loss: 0.15991677240275948
0    7.1681
dtype: float32
Epoch 45, train loss: 0.06007470048383215 test loss: 0.13112904226200828
0    6.934509
dtype: float32
Epoch 46, train loss: 0.07459667494011123 test loss: 0.14046841654133002
0    6.844988
dtype: float32
Epoch 47, train loss: 0.08685147802979698 test loss: 0.1627261237173523
0    7.026888
dtype: float32
Epoch 48, train loss: 0.06622516045195566 test loss: 0.13843994200108212
0    6.86916
dtype: float32
Epoch 49, train loss: 0.0747852379310706 test loss: 0.13474865420265153
0    6.887392
dtype: float32
Epoch 50, train loss: 0.07063924039098951 test loss: 0.13184551241423856
0    7.151546
dtype: float32
Epoch 51, train loss: 0.057262431751611526 test loss: 0.13014900274593674
0    7.217285
dtype: float32
Epoch 52, train loss: 0.056963809622756434 test loss: 0.12694323049435394
0    7.114167
dtype: float32
Epoch 53, train loss: 0.057826789511681936 test loss: 0.12598743430718326
0    7.144801
dtype: float32
Epoch 54, train loss: 0.057318186059864655 test loss: 0.1256613202967039
0    7.003008
dtype: float32
Epoch 55, train loss: 0.06435253318499655 test loss: 0.13352540658233258
0    7.268095
dtype: float32
Epoch 56, train loss: 0.05801859945820803 test loss: 0.13384653528382734
0    7.437526
dtype: float32
Epoch 57, train loss: 0.07462614474881049 test loss: 0.1690540600861522
0    7.46039
dtype: float32
Epoch 58, train loss: 0.06964756166693595 test loss: 0.14655384865682186
0    7.609062
dtype: float32
Epoch 59, train loss: 0.08693583896370423 test loss: 0.1745831839015324
0    7.380944
dtype: float32
Epoch 60, train loss: 0.060873560237153325 test loss: 0.13807187139016777
0    7.075647
dtype: float32
Epoch 61, train loss: 0.05873065948388588 test loss: 0.12796638180147307
0    7.151147
dtype: float32
Epoch 62, train loss: 0.05641062540318981 test loss: 0.12796419995432876
0    7.141608
dtype: float32
Epoch 63, train loss: 0.05893830833640822 test loss: 0.13061402147201848
0    7.367068
dtype: float32
Epoch 64, train loss: 0.059198464732251786 test loss: 0.13463561932999235
0    7.565543
dtype: float32
Epoch 65, train loss: 0.0752769751654255 test loss: 0.1567153746301532
0    7.483736
dtype: float32
Epoch 66, train loss: 0.07093090029326087 test loss: 0.1576227061629663
0    7.454328
dtype: float32
Epoch 67, train loss: 0.06290201593391921 test loss: 0.1420925240169866
0    6.592581
dtype: float32
Epoch 68, train loss: 0.10775810516427957 test loss: 0.164241782684118
0    6.189446
dtype: float32
Epoch 69, train loss: 0.18232537361897444 test loss: 0.2806781599414081
0    6.528881
dtype: float32
Epoch 70, train loss: 0.13511983382606468 test loss: 0.26093054039898445
0    6.630338
dtype: float32
Epoch 71, train loss: 0.10721988359125988 test loss: 0.18133342782137193
0    7.099875
dtype: float32
Epoch 72, train loss: 0.057373869784307016 test loss: 0.12712355814483642
0    6.957682
dtype: float32
Epoch 73, train loss: 0.06366519467984122 test loss: 0.13231896504670562
0    7.242498
dtype: float32
Epoch 74, train loss: 0.0545442468868457 test loss: 0.12805592311626318
0    7.357288
dtype: float32
Epoch 75, train loss: 0.057355995506465474 test loss: 0.1319675744642121
0    7.586829
dtype: float32
Epoch 76, train loss: 0.08008244983908551 test loss: 0.1581145179088255
0    7.719769
dtype: float32
Epoch 77, train loss: 0.09662179871702202 test loss: 0.1761297401045997
0    7.182269
dtype: float32
Epoch 78, train loss: 0.05372592552635842 test loss: 0.12787216566952014
0    7.156674
dtype: float32
Epoch 79, train loss: 0.052948079606000197 test loss: 0.12911422476646456
0    7.460824
dtype: float32
Epoch 80, train loss: 0.06883453209876203 test loss: 0.1560799808055503
0    7.406775
dtype: float32
Epoch 81, train loss: 0.057794827599468565 test loss: 0.13193900736146702
0    6.7659
dtype: float32
Epoch 82, train loss: 0.08783356894844983 test loss: 0.1536122340075597
0    6.909135
dtype: float32
Epoch 83, train loss: 0.07044851075893553 test loss: 0.13715672604133475
0    6.654094
dtype: float32
Epoch 84, train loss: 0.10916367386357699 test loss: 0.18273938871090023
0    6.468858
dtype: float32
Epoch 85, train loss: 0.11937288515262663 test loss: 0.16327556906668605
0    6.823884
dtype: float32
Epoch 86, train loss: 0.07721590450598212 test loss: 0.1400961451484755
0    7.174996
dtype: float32
Epoch 87, train loss: 0.053936396592240705 test loss: 0.12764669516139168
0    6.918654
dtype: float32
Epoch 88, train loss: 0.06491214770893113 test loss: 0.12989643902506526
0    7.071471
dtype: float32
Epoch 89, train loss: 0.05501616817544876 test loss: 0.12893440389352576
0    6.852565
dtype: float32
Epoch 90, train loss: 0.07247278033112324 test loss: 0.1360791105118313
0    7.319609
dtype: float32
Epoch 91, train loss: 0.054762870077150944 test loss: 0.1350556280178718
0    7.154864
dtype: float32
Epoch 92, train loss: 0.051501000459453064 test loss: 0.12937780156558773
0    6.874907
dtype: float32
Epoch 93, train loss: 0.0739740835187363 test loss: 0.14584326363696756
0    6.882228
dtype: float32
Epoch 94, train loss: 0.0701595896832706 test loss: 0.14120265261312792
0    6.723625
dtype: float32
Epoch 95, train loss: 0.08261096300098425 test loss: 0.14708074872762505
0    6.392687
dtype: float32
Epoch 96, train loss: 0.12702187101544213 test loss: 0.19520313292795924
0    6.712936
dtype: float32
Epoch 97, train loss: 0.08315751409379987 test loss: 0.15004832175406854
0    6.950047
dtype: float32
Epoch 98, train loss: 0.058761148751221286 test loss: 0.13109619574828574
0    6.989649
dtype: float32
Epoch 99, train loss: 0.05785701768692146 test loss: 0.1325853986661168
0    7.036978
dtype: float32
Epoch 100, train loss: 0.05268122204659913 test loss: 0.13295604400919692
0    7.004715
dtype: float32
Epoch 101, train loss: 0.05572799434951826 test loss: 0.13254378211964238
0    7.089074
dtype: float32
Epoch 102, train loss: 0.052220244235514704 test loss: 0.1322881214116304
0    7.465178
dtype: float32
Epoch 103, train loss: 0.06626071867845326 test loss: 0.15450223285593037
0    7.229849
dtype: float32
Epoch 104, train loss: 0.05182653900591795 test loss: 0.1364465881377233
0    7.343639
dtype: float32
Epoch 105, train loss: 0.055527258485797495 test loss: 0.13782369303909364
0    7.426178
dtype: float32
Epoch 106, train loss: 0.06302780100681296 test loss: 0.14875607106550595
0    7.324047
dtype: float32
Epoch 107, train loss: 0.06477847445254359 test loss: 0.16317681282221785
0    7.348559
dtype: float32
Epoch 108, train loss: 0.060004387201565354 test loss: 0.1469734246570226
0    7.159642
dtype: float32
Epoch 109, train loss: 0.049987730603889786 test loss: 0.13365560492737585
0    6.997907
dtype: float32
Epoch 110, train loss: 0.05571150655490814 test loss: 0.13372226590789793
0    6.713961
dtype: float32
Epoch 111, train loss: 0.08182422643749744 test loss: 0.1561709234008257
0    7.118989
dtype: float32
Epoch 112, train loss: 0.05168018448117171 test loss: 0.13392589136181218
0    7.512442
dtype: float32
Epoch 113, train loss: 0.06977479355649943 test loss: 0.15670442054367897
0    7.425971
dtype: float32
Epoch 114, train loss: 0.06446141093896202 test loss: 0.15801131311789732
0    7.437896
dtype: float32
Epoch 115, train loss: 0.06932601688070808 test loss: 0.16897380183620136
0    7.226956
dtype: float32
Epoch 116, train loss: 0.05131281887238795 test loss: 0.13970945932397408
0    7.325962
dtype: float32
Epoch 117, train loss: 0.054893278591231005 test loss: 0.14255498080815351
0    7.195385
dtype: float32
Epoch 118, train loss: 0.049989279112117105 test loss: 0.13575207386464486
0    7.002068
dtype: float32
Epoch 119, train loss: 0.054225981947632285 test loss: 0.13544538607798753
0    7.374917
dtype: float32
Epoch 120, train loss: 0.060304828235975105 test loss: 0.14722785385440615
0    7.487921
dtype: float32
Epoch 121, train loss: 0.07648047817957757 test loss: 0.1721894085259355
0    7.529902
dtype: float32
Epoch 122, train loss: 0.07719689663765472 test loss: 0.15946000925312315
0    7.654747
dtype: float32
Epoch 123, train loss: 0.09409202625875066 test loss: 0.18461956916795133
0    7.526354
dtype: float32
Epoch 124, train loss: 0.07253633803514486 test loss: 0.1526352290878414
0    7.337078
dtype: float32
Epoch 125, train loss: 0.05576135756742818 test loss: 0.14403853886893594
0    7.109162
dtype: float32
Epoch 126, train loss: 0.05055149939439867 test loss: 0.13455165051472667
0    6.945807
dtype: float32
Epoch 127, train loss: 0.057469233655418714 test loss: 0.13828346597765856
0    6.895622
dtype: float32
Epoch 128, train loss: 0.05642737591839351 test loss: 0.1351056474519045
0    7.146657
dtype: float32
Epoch 129, train loss: 0.048638709240358034 test loss: 0.1367786293551647
0    7.206016
dtype: float32
Epoch 130, train loss: 0.049745905686243846 test loss: 0.1413663541081585
0    6.971995
dtype: float32
Epoch 131, train loss: 0.054797842809913615 test loss: 0.1382383363341379
0    6.642704
dtype: float32
Epoch 132, train loss: 0.08744994933383539 test loss: 0.1580121628478401
0    7.110274
dtype: float32
Epoch 133, train loss: 0.048750001750333394 test loss: 0.1398768416399617
0    6.914853
dtype: float32
Epoch 134, train loss: 0.05451232273331398 test loss: 0.13444914155662027
0    6.618223
dtype: float32
Epoch 135, train loss: 0.08642395543924265 test loss: 0.1540176986854805
0    6.762808
dtype: float32
Epoch 136, train loss: 0.07404506999243707 test loss: 0.1560233309103758
0    6.765189
dtype: float32
Epoch 137, train loss: 0.06489479073557124 test loss: 0.14039743314276512
0    6.624426
dtype: float32
Epoch 138, train loss: 0.08200019497168773 test loss: 0.15331072008418825
0    6.583644
dtype: float32
Epoch 139, train loss: 0.0858568972543424 test loss: 0.14326707742832445
0    6.731165
dtype: float32
Epoch 140, train loss: 0.06925501983209409 test loss: 0.14501440866262752
0    6.904636
dtype: float32
Epoch 141, train loss: 0.05939742269888733 test loss: 0.14236033995363315
0    6.998619
dtype: float32
Epoch 142, train loss: 0.051294104631456 test loss: 0.13732403076804134
0    7.18452
dtype: float32
Epoch 143, train loss: 0.04894753401441688 test loss: 0.14242030996661056
0    7.360367
dtype: float32
Epoch 144, train loss: 0.061380266613568414 test loss: 0.15951502173283866
0    7.2125
dtype: float32
Epoch 145, train loss: 0.05178265699797761 test loss: 0.14445331583137783
0    7.288605
dtype: float32
Epoch 146, train loss: 0.056398364487913626 test loss: 0.15504092170140923
0    7.132987
dtype: float32
Epoch 147, train loss: 0.04842566457298144 test loss: 0.13868215874842177
0    7.140393
dtype: float32
Epoch 148, train loss: 0.048148306784813216 test loss: 0.141875032795956
0    6.917544
dtype: float32
Epoch 149, train loss: 0.05296965346138134 test loss: 0.13695438586577272
0    6.812534
dtype: float32
Epoch 150, train loss: 0.059605572380477326 test loss: 0.13828612474100788
0    7.053505
dtype: float32
Epoch 151, train loss: 0.04835904605462659 test loss: 0.1384623421325217
0    6.942867
dtype: float32
Epoch 152, train loss: 0.052645692376082937 test loss: 0.13456096691025074
0    7.103384
dtype: float32
Epoch 153, train loss: 0.04827800813270625 test loss: 0.141388641175058
0    7.114587
dtype: float32
Epoch 154, train loss: 0.04804400826007511 test loss: 0.13827553929275108
0    6.949636
dtype: float32
Epoch 155, train loss: 0.051971388860816474 test loss: 0.13550480948258706
0    7.29877
dtype: float32
Epoch 156, train loss: 0.053888944034602246 test loss: 0.14596994545586783
0    7.446371
dtype: float32
Epoch 157, train loss: 0.07221562703046 test loss: 0.1702157048048321
0    7.151358
dtype: float32
Epoch 158, train loss: 0.04957107380716729 test loss: 0.15100365706835486
0    7.276808
dtype: float32
Epoch 159, train loss: 0.053754885275253954 test loss: 0.1478398005749454
0    7.142976
dtype: float32
Epoch 160, train loss: 0.04742812521417961 test loss: 0.1445995359417912
0    6.964228
dtype: float32
Epoch 161, train loss: 0.05106153934437422 test loss: 0.1398508008992514
0    7.243836
dtype: float32
Epoch 162, train loss: 0.05060774006380546 test loss: 0.14894903493498393
0    7.229476
dtype: float32
Epoch 163, train loss: 0.049627417308156854 test loss: 0.1456622437097332
0    7.16438
dtype: float32
Epoch 164, train loss: 0.04768263585845284 test loss: 0.14600295238906383
0    7.425562
dtype: float32
Epoch 165, train loss: 0.06338787849070252 test loss: 0.15841464352704465
0    7.164876
dtype: float32
Epoch 166, train loss: 0.04688304530920603 test loss: 0.14130818348872445
0    7.192554
dtype: float32
Epoch 167, train loss: 0.04757976598714442 test loss: 0.14352044866007957
0    7.187228
dtype: float32
Epoch 168, train loss: 0.047665262234126454 test loss: 0.14322339108639104
0    7.445203
dtype: float32
Epoch 169, train loss: 0.06436087106806973 test loss: 0.15741638915352885
0    7.075702
dtype: float32
Epoch 170, train loss: 0.04748939287415358 test loss: 0.14087120499333983
0    7.289944
dtype: float32
Epoch 171, train loss: 0.05267759244185851 test loss: 0.1455729509550001
0    7.310348
dtype: float32
Epoch 172, train loss: 0.054494525921856315 test loss: 0.15044708547991106
0    7.13019
dtype: float32
Epoch 173, train loss: 0.046846995437526344 test loss: 0.1412955553837567
0    7.183596
dtype: float32
Epoch 174, train loss: 0.04757270071942616 test loss: 0.1450858662579064
0    6.847404
dtype: float32
Epoch 175, train loss: 0.05878624066355636 test loss: 0.14442536774642686
0    6.970407
dtype: float32
Epoch 176, train loss: 0.0500538814868012 test loss: 0.14368509009926583
0    6.829583
dtype: float32
Epoch 177, train loss: 0.06236522850537763 test loss: 0.14950138003708324
0    6.615547
dtype: float32
Epoch 178, train loss: 0.07671652194564153 test loss: 0.14856479924112911
0    6.761849
dtype: float32
Epoch 179, train loss: 0.06836888297364556 test loss: 0.14906514793114148
0    7.161414
dtype: float32
Epoch 180, train loss: 0.04769872561356803 test loss: 0.15043423190577243
0    7.254894
dtype: float32
Epoch 181, train loss: 0.05140022465873368 test loss: 0.15216238162721285
0    7.038152
dtype: float32
Epoch 182, train loss: 0.0463933104166739 test loss: 0.14470697304652752
0    7.261856
dtype: float32
Epoch 183, train loss: 0.05332743867550183 test loss: 0.15785364486311917
0    7.227711
dtype: float32
Epoch 184, train loss: 0.05084661223241978 test loss: 0.15588924321535372
0    7.151202
dtype: float32
Epoch 185, train loss: 0.04622131445666209 test loss: 0.1426472491503874
0    7.13458
dtype: float32
Epoch 186, train loss: 0.04617418966046721 test loss: 0.14174631574420068
0    7.021216
dtype: float32
Epoch 187, train loss: 0.047280818626062066 test loss: 0.14115093995176103
0    7.249465
dtype: float32
Epoch 188, train loss: 0.05239551378976068 test loss: 0.15569214669859766
0    6.889524
dtype: float32
Epoch 189, train loss: 0.054729345273762595 test loss: 0.14076215959418226
0    6.867464
dtype: float32
Epoch 190, train loss: 0.05630856916968635 test loss: 0.14387927756478208
0    7.187529
dtype: float32
Epoch 191, train loss: 0.048734489205057095 test loss: 0.14742649509809685
0    7.100224
dtype: float32
Epoch 192, train loss: 0.04644409857590362 test loss: 0.1389250145046573
0    7.077579
dtype: float32
Epoch 193, train loss: 0.04724041572232496 test loss: 0.14082842385157657
0    6.863442
dtype: float32
Epoch 194, train loss: 0.05636865638070969 test loss: 0.14296147983817062
0    7.157294
dtype: float32
Epoch 195, train loss: 0.04641602665508218 test loss: 0.13902391634999228
0    7.074066
dtype: float32
Epoch 196, train loss: 0.045675931486122305 test loss: 0.14086106769673748
0    7.157287
dtype: float32
Epoch 197, train loss: 0.04701447399957967 test loss: 0.1449098060053557
0    7.157597
dtype: float32
Epoch 198, train loss: 0.045779428694224654 test loss: 0.1415948318571099
0    7.345377
dtype: float32
Epoch 199, train loss: 0.05603348852135884 test loss: 0.15050308288682418
0    7.16285
dtype: float32
Epoch 200, train loss: 0.04663570291650691 test loss: 0.14300161340004816
0    7.267221
dtype: float32
Epoch 201, train loss: 0.05117129290668466 test loss: 0.14683851619796678
0    7.21788
dtype: float32
Epoch 202, train loss: 0.05197564721133177 test loss: 0.15262483722107997
0    7.311909
dtype: float32
Epoch 203, train loss: 0.05478058830047369 test loss: 0.15387710919134015
0    7.230157
dtype: float32
Epoch 204, train loss: 0.051207704671362014 test loss: 0.15197562813792154
0    7.457243
dtype: float32
Epoch 205, train loss: 0.07368169682560376 test loss: 0.18072990248765763
0    7.475345
dtype: float32
Epoch 206, train loss: 0.06680612544063314 test loss: 0.15979086019196034
0    7.523925
dtype: float32
Epoch 207, train loss: 0.07601866765076067 test loss: 0.1791408787957875
0    7.86635
dtype: float32
Epoch 208, train loss: 0.11447411096889105 test loss: 0.22552069039612863
0    7.566489
dtype: float32
Epoch 209, train loss: 0.07627973037805363 test loss: 0.1678717530427602
0    7.456803
dtype: float32
Epoch 210, train loss: 0.06310330133786647 test loss: 0.1491308193396647
0    7.244396
dtype: float32
Epoch 211, train loss: 0.048550932466405294 test loss: 0.14549798100175115
0    7.123729
dtype: float32
Epoch 212, train loss: 0.04588622713587706 test loss: 0.14487500828455005
0    7.093023
dtype: float32
Epoch 213, train loss: 0.04550007766675084 test loss: 0.14633946368426753
0    7.213616
dtype: float32
Epoch 214, train loss: 0.04689352439124423 test loss: 0.14862346465434878
0    7.254286
dtype: float32
Epoch 215, train loss: 0.04861958512721433 test loss: 0.15129870486324012
0    7.217247
dtype: float32
Epoch 216, train loss: 0.04660949974676713 test loss: 0.14916220145611964
0    6.991491
dtype: float32
Epoch 217, train loss: 0.04938937975949372 test loss: 0.14547545229177078
0    6.809111
dtype: float32
Epoch 218, train loss: 0.06924762007291127 test loss: 0.15259045844878844
0    6.553131
dtype: float32
Epoch 219, train loss: 0.09356844538594783 test loss: 0.1588629513084261
0    6.904463
dtype: float32
Epoch 220, train loss: 0.05755014594204906 test loss: 0.153743369694461
0    6.641379
dtype: float32
Epoch 221, train loss: 0.07967763314117139 test loss: 0.15736152017037475
0    7.101653
dtype: float32
Epoch 222, train loss: 0.04566720296420511 test loss: 0.14814796000416652
0    7.173357
dtype: float32
Epoch 223, train loss: 0.04767088414418213 test loss: 0.15100305874991757
0    7.244753
dtype: float32
Epoch 224, train loss: 0.05026883894848582 test loss: 0.15181124513390198
0    7.178876
dtype: float32
Epoch 225, train loss: 0.046015919935044634 test loss: 0.1451838599126244
0    7.017185
dtype: float32
Epoch 226, train loss: 0.04765833964469017 test loss: 0.14313745558873872
0    6.667427
dtype: float32
Epoch 227, train loss: 0.08973187567239763 test loss: 0.19278533106340526
0    6.710186
dtype: float32
Epoch 228, train loss: 0.0747685743533867 test loss: 0.15434439459171898
0    6.923433
dtype: float32
Epoch 229, train loss: 0.05460537358323025 test loss: 0.14899892542918802
0    7.118553
dtype: float32
Epoch 230, train loss: 0.045036177481627956 test loss: 0.14641103735715488
0    7.033836
dtype: float32
Epoch 231, train loss: 0.04796756733117049 test loss: 0.14857260349050702
0    7.006836
dtype: float32
Epoch 232, train loss: 0.0475624652648457 test loss: 0.1467010116823101
0    6.971556
dtype: float32
Epoch 233, train loss: 0.053717119509102185 test loss: 0.1513785029328519
0    7.018157
dtype: float32
Epoch 234, train loss: 0.046360461128957094 test loss: 0.14624961485749813
0    6.716249
dtype: float32
Epoch 235, train loss: 0.0626781059104685 test loss: 0.15037211723416652
0    6.982786
dtype: float32
Epoch 236, train loss: 0.04540782635361949 test loss: 0.14939806274790046
0    6.932102
dtype: float32
Epoch 237, train loss: 0.05089883203157488 test loss: 0.15424984514462478
0    7.07835
dtype: float32
Epoch 238, train loss: 0.0447631125482216 test loss: 0.15050832714637039
0    7.319108
dtype: float32
Epoch 239, train loss: 0.05482255421695267 test loss: 0.1603907385362722
0    7.104498
dtype: float32
Epoch 240, train loss: 0.044383652057806734 test loss: 0.15143952537203242
0    7.208629
dtype: float32
Epoch 241, train loss: 0.04593913803703914 test loss: 0.15319559700926555
0    6.86814
dtype: float32
Epoch 242, train loss: 0.05657939335823541 test loss: 0.15241708985030503
0    6.705561
dtype: float32
Epoch 243, train loss: 0.07997662400363688 test loss: 0.1683240142742114
0    6.718709
dtype: float32
Epoch 244, train loss: 0.07245997291471669 test loss: 0.16380721573535711
0    6.813257
dtype: float32
Epoch 245, train loss: 0.06648047818988304 test loss: 0.1597491161440438
0    7.224523
dtype: float32
Epoch 246, train loss: 0.045521406543541955 test loss: 0.1469515320214356
0    7.060186
dtype: float32
Epoch 247, train loss: 0.04806978840726481 test loss: 0.1468666116982574
0    7.095466
dtype: float32
Epoch 248, train loss: 0.04396252925090828 test loss: 0.1474242650433256
0    7.178988
dtype: float32
Epoch 249, train loss: 0.046165815263699186 test loss: 0.1519180176779634
0    7.04881
dtype: float32
Epoch 250, train loss: 0.04417596085810399 test loss: 0.14716313241297999
0    7.101903
dtype: float32
Epoch 251, train loss: 0.0434577170328614 test loss: 0.14940028013865497
0    7.349669
dtype: float32
Epoch 252, train loss: 0.05467320018616331 test loss: 0.15746181978143567
0    7.373549
dtype: float32
Epoch 253, train loss: 0.06053146917589901 test loss: 0.16411698662747443
0    7.466223
dtype: float32
Epoch 254, train loss: 0.06735508957335504 test loss: 0.16194738253862262
0    7.485137
dtype: float32
Epoch 255, train loss: 0.06925193046649306 test loss: 0.16711632320070297
0    7.223339
dtype: float32
Epoch 256, train loss: 0.049341073360026196 test loss: 0.15616635944956414
0    6.998244
dtype: float32
Epoch 257, train loss: 0.04559697407732896 test loss: 0.14821823706458184
0    7.201113
dtype: float32
Epoch 258, train loss: 0.0449204032185467 test loss: 0.15169481038039606
0    7.207484
dtype: float32
Epoch 259, train loss: 0.044578160861391096 test loss: 0.15166008840326625
0    7.198125
dtype: float32
Epoch 260, train loss: 0.04417435592539977 test loss: 0.15346982586178803
0    7.278233
dtype: float32
Epoch 261, train loss: 0.047360926552504005 test loss: 0.15589531244034568
0    7.164442
dtype: float32
Epoch 262, train loss: 0.043982053868248154 test loss: 0.15197760976057198
0    7.290871
dtype: float32
Epoch 263, train loss: 0.04967778812718244 test loss: 0.15322100357669724
0    7.17244
dtype: float32
Epoch 264, train loss: 0.0453916830538588 test loss: 0.1519633580156901
0    7.184106
dtype: float32
Epoch 265, train loss: 0.043804606440553284 test loss: 0.15003054123870616
0    6.950716
dtype: float32
Epoch 266, train loss: 0.04912685844632362 test loss: 0.14652185649859484
0    7.044272
dtype: float32
Epoch 267, train loss: 0.04318976439944171 test loss: 0.14864430062932313
0    7.34836
dtype: float32
Epoch 268, train loss: 0.059342863309757174 test loss: 0.16757200115472737
0    7.019558
dtype: float32
Epoch 269, train loss: 0.04424274821358517 test loss: 0.15057375247489566
0    7.011423
dtype: float32
Epoch 270, train loss: 0.043846039657832216 test loss: 0.15112392910833694
0    6.65732
dtype: float32
Epoch 271, train loss: 0.08399351109990143 test loss: 0.1773422442805022
0    7.020334
dtype: float32
Epoch 272, train loss: 0.044967781546191736 test loss: 0.1504555510564239
0    7.127129
dtype: float32
Epoch 273, train loss: 0.04293390713956517 test loss: 0.14957981318181518
0    7.115695
dtype: float32
Epoch 274, train loss: 0.04278072853352796 test loss: 0.14883081628964281
0    7.074232
dtype: float32
Epoch 275, train loss: 0.04275578375414001 test loss: 0.1500871120945446
0    7.375218
dtype: float32
Epoch 276, train loss: 0.05498640647621745 test loss: 0.1572554273443592
0    7.474252
dtype: float32
Epoch 277, train loss: 0.06037609580871301 test loss: 0.1554674811867608
0    7.31054
dtype: float32
Epoch 278, train loss: 0.04866345878656123 test loss: 0.15327148478435032
0    7.18158
dtype: float32
Epoch 279, train loss: 0.04245587402556539 test loss: 0.1493625632163544
0    7.310492
dtype: float32
Epoch 280, train loss: 0.04904260210783993 test loss: 0.1548095643345714
0    7.309533
dtype: float32
Epoch 281, train loss: 0.050913777565781325 test loss: 0.15441950652510744
0    7.036075
dtype: float32
Epoch 282, train loss: 0.04436513504082076 test loss: 0.14790347931039147
0    6.918363
dtype: float32
Epoch 283, train loss: 0.05259915093222748 test loss: 0.15503117673629732
0    6.87428
dtype: float32
Epoch 284, train loss: 0.05753801608005593 test loss: 0.16187570938795215
0    6.964861
dtype: float32
Epoch 285, train loss: 0.0498877243518482 test loss: 0.15283744190491794
0    6.739524
dtype: float32
Epoch 286, train loss: 0.07664310215752863 test loss: 0.17519251337665176
0    6.702137
dtype: float32
Epoch 287, train loss: 0.07601854797544291 test loss: 0.17079614684250086
0    6.731407
dtype: float32
Epoch 288, train loss: 0.07607369833495606 test loss: 0.17162478545381643
0    6.819342
dtype: float32
Epoch 289, train loss: 0.06575745669349811 test loss: 0.16396649833564955
0    7.251019
dtype: float32
Epoch 290, train loss: 0.045327600846394936 test loss: 0.1560104622054646
0    7.232641
dtype: float32
Epoch 291, train loss: 0.0441705688342534 test loss: 0.15608874382141552
0    7.057087
dtype: float32
Epoch 292, train loss: 0.04295090847946611 test loss: 0.15395487802630572
0    7.017327
dtype: float32
Epoch 293, train loss: 0.04621792587306263 test loss: 0.15540914656650226
0    7.091657
dtype: float32
Epoch 294, train loss: 0.042700770560978034 test loss: 0.15345256445642405
0    7.013349
dtype: float32
Epoch 295, train loss: 0.04454189007872583 test loss: 0.1549103903035029
0    6.910379
dtype: float32
Epoch 296, train loss: 0.05308259801243179 test loss: 0.15881096837036796
0    6.69012
dtype: float32
Epoch 297, train loss: 0.08433150570241249 test loss: 0.18766178044884765
0    6.423488
dtype: float32
Epoch 298, train loss: 0.11515032708817503 test loss: 0.2112790204040397
0    6.841308
dtype: float32
Epoch 299, train loss: 0.06789738854576573 test loss: 0.17529764318783964
Final train loss is: 0.06789738854576573, Test loss is: 0.17529764318783964
0    6.841308
dtype: float32
round is 1
0    6.025489
dtype: float32
Epoch 9, train loss: 0.364524846560415 test loss: 0.5894697873983434
0    7.801641
dtype: float32
Epoch 10, train loss: 0.2354513409608919 test loss: 0.32925241240065173
0    6.269972
dtype: float32
Epoch 11, train loss: 0.25297989977670876 test loss: 0.4850556492457159
0    6.997119
dtype: float32
Epoch 12, train loss: 0.17475587409502646 test loss: 0.37469863828829814
0    6.652231
dtype: float32
Epoch 13, train loss: 0.21806008671009838 test loss: 0.39621434212955237
0    6.402184
dtype: float32
Epoch 14, train loss: 0.22779081767316903 test loss: 0.3782516844705939
0    8.320481
dtype: float32
Epoch 16, train loss: 0.1914635593979899 test loss: 0.19489208066553998
0    8.201923
dtype: float32
Epoch 17, train loss: 0.1790273030204996 test loss: 0.18024337995655423
0    8.545324
dtype: float32
Epoch 18, train loss: 0.21140811169821414 test loss: 0.1480918770322553
0    7.449633
dtype: float32
Epoch 19, train loss: 0.13801875385939052 test loss: 0.18338449135509935
0    8.076438
dtype: float32
Epoch 20, train loss: 0.16707840722265663 test loss: 0.14341389888271625
0    7.458153
dtype: float32
Epoch 21, train loss: 0.11213036876991317 test loss: 0.1573597339360309
0    7.592616
dtype: float32
Epoch 22, train loss: 0.11219499970923545 test loss: 0.13212753676851358
0    7.757172
dtype: float32
Epoch 23, train loss: 0.1259249845804636 test loss: 0.12185644814249924
0    7.933857
dtype: float32
Epoch 24, train loss: 0.12815586447975688 test loss: 0.11247027935936804
0    6.641708
dtype: float32
Epoch 25, train loss: 0.1369418877444331 test loss: 0.17073692732308832
0    5.950273
dtype: float32
Epoch 26, train loss: 0.2756828099426396 test loss: 0.2509428015255975
0    7.197679
dtype: float32
Epoch 27, train loss: 0.1457267706518004 test loss: 0.15688190575388075
0    8.231204
dtype: float32
Epoch 28, train loss: 0.15920127005465218 test loss: 0.11324607455308108
0    8.046199
dtype: float32
Epoch 29, train loss: 0.1559637881578693 test loss: 0.11473418956832848
0    8.000606
dtype: float32
Epoch 30, train loss: 0.14544343861754228 test loss: 0.11325927078064364
0    7.608022
dtype: float32
Epoch 31, train loss: 0.11231773178499622 test loss: 0.10725972033479084
0    7.840005
dtype: float32
Epoch 32, train loss: 0.13076583263858785 test loss: 0.10519586846752696
0    8.62802
dtype: float32
Epoch 33, train loss: 0.1855661076857063 test loss: 0.1552820924924607
0    7.723655
dtype: float32
Epoch 34, train loss: 0.10546882733496495 test loss: 0.10244907034487712
0    6.979404
dtype: float32
Epoch 35, train loss: 0.08726069416451412 test loss: 0.1045794976458194
0    6.437419
dtype: float32
Epoch 36, train loss: 0.1560265559632057 test loss: 0.14511031466710875
0    6.454537
dtype: float32
Epoch 38, train loss: 0.12564684997230213 test loss: 0.12455133427928432
0    6.092292
dtype: float32
Epoch 39, train loss: 0.23509711135428354 test loss: 0.17892621612132173
0    6.214506
dtype: float32
Epoch 40, train loss: 0.16462747150159454 test loss: 0.14040877019803827
0    5.543373
dtype: float32
Epoch 41, train loss: 0.31008728223448156 test loss: 0.22501141703232788
0    6.939699
dtype: float32
Epoch 42, train loss: 0.09976401278645032 test loss: 0.09801769306253355
0    6.89799
dtype: float32
Epoch 43, train loss: 0.08637553015209254 test loss: 0.09490143256513862
0    6.845144
dtype: float32
Epoch 44, train loss: 0.08711007437336334 test loss: 0.0939176900142182
0    6.925674
dtype: float32
Epoch 45, train loss: 0.0861193398604591 test loss: 0.09690261926370711
0    6.671481
dtype: float32
Epoch 46, train loss: 0.11756872442038727 test loss: 0.10971926095609066
0    5.646659
dtype: float32
Epoch 47, train loss: 0.23366318073580022 test loss: 0.1781480078662583
0    6.948311
dtype: float32
Epoch 48, train loss: 0.07781746012558112 test loss: 0.09282868407297237
0    7.576255
dtype: float32
Epoch 49, train loss: 0.10762248458455191 test loss: 0.11720970077364565
0    7.745481
dtype: float32
Epoch 50, train loss: 0.09826774843412754 test loss: 0.1208097641442154
0    7.529706
dtype: float32
Epoch 51, train loss: 0.08308481335690666 test loss: 0.11203205878122552
0    7.741823
dtype: float32
Epoch 52, train loss: 0.11869772608523319 test loss: 0.1341708562129697
0    7.743191
dtype: float32
Epoch 53, train loss: 0.10681807942168547 test loss: 0.13517559900633347
0    7.882691
dtype: float32
Epoch 54, train loss: 0.15063653372338923 test loss: 0.14638019698724067
0    7.452622
dtype: float32
Epoch 55, train loss: 0.08044020312584654 test loss: 0.10804034032193424
0    7.878291
dtype: float32
Epoch 56, train loss: 0.11376297946743495 test loss: 0.1405580193802033
0    7.603489
dtype: float32
Epoch 57, train loss: 0.10756899455753974 test loss: 0.12732125349324108
0    7.343421
dtype: float32
Epoch 58, train loss: 0.07773363970126523 test loss: 0.11257785423266031
0    7.061517
dtype: float32
Epoch 59, train loss: 0.0691488355831299 test loss: 0.09907589495833588
0    7.010422
dtype: float32
Epoch 60, train loss: 0.07040081835238614 test loss: 0.09632361964712276
0    6.7521
dtype: float32
Epoch 61, train loss: 0.09924376860386493 test loss: 0.0987795185493828
0    6.872332
dtype: float32
Epoch 62, train loss: 0.08328623653809414 test loss: 0.09670913629048507
0    6.316756
dtype: float32
Epoch 63, train loss: 0.16024170775931082 test loss: 0.12363961463460645
0    6.949612
dtype: float32
Epoch 64, train loss: 0.07935722730709074 test loss: 0.09672849032813871
0    7.188333
dtype: float32
Epoch 65, train loss: 0.06849646796749913 test loss: 0.09913623981904066
0    7.261967
dtype: float32
Epoch 66, train loss: 0.0698364269604129 test loss: 0.10077744052244197
0    7.7702
dtype: float32
Epoch 67, train loss: 0.09486795719639547 test loss: 0.12639927442350032
0    7.590287
dtype: float32
Epoch 68, train loss: 0.08803356660281751 test loss: 0.12185164934473962
0    7.279553
dtype: float32
Epoch 69, train loss: 0.0680669625373409 test loss: 0.09861868021088402
0    7.379991
dtype: float32
Epoch 70, train loss: 0.0710267138662743 test loss: 0.10773733444578049
0    7.264616
dtype: float32
Epoch 71, train loss: 0.06678623573811639 test loss: 0.10205428867465575
0    7.345478
dtype: float32
Epoch 72, train loss: 0.06893739622166252 test loss: 0.10437337009084231
0    7.891468
dtype: float32
Epoch 73, train loss: 0.11056125938189579 test loss: 0.1290096470600254
0    7.996252
dtype: float32
Epoch 74, train loss: 0.12843381712541865 test loss: 0.14369332966347118
0    7.720877
dtype: float32
Epoch 75, train loss: 0.10321051475805162 test loss: 0.12510946901303371
0    7.246517
dtype: float32
Epoch 76, train loss: 0.06617459497756195 test loss: 0.09698663441874575
0    7.540977
dtype: float32
Epoch 77, train loss: 0.08837798690206805 test loss: 0.11814121790441809
0    7.499018
dtype: float32
Epoch 78, train loss: 0.08700739869921498 test loss: 0.11571970136793489
0    8.037403
dtype: float32
Epoch 79, train loss: 0.14349343823069352 test loss: 0.16387241604774913
0    7.997591
dtype: float32
Epoch 80, train loss: 0.14319270106302284 test loss: 0.16385395304586312
0    7.218993
dtype: float32
Epoch 81, train loss: 0.07461130828749311 test loss: 0.10642864809689424
0    6.997128
dtype: float32
Epoch 82, train loss: 0.06541975235106168 test loss: 0.09829255014922691
0    7.029886
dtype: float32
Epoch 83, train loss: 0.0653733507631472 test loss: 0.09877736530151712
0    7.060003
dtype: float32
Epoch 84, train loss: 0.06620835854622291 test loss: 0.0964850194240129
0    6.500699
dtype: float32
Epoch 85, train loss: 0.09926417702419273 test loss: 0.09736962266807285
0    6.83811
dtype: float32
Epoch 86, train loss: 0.07928216949664714 test loss: 0.09399360328046166
0    6.386766
dtype: float32
Epoch 87, train loss: 0.12701269319846317 test loss: 0.105842851900281
0    6.384782
dtype: float32
Epoch 88, train loss: 0.1274724579028886 test loss: 0.11051930301331601
0    5.74606
dtype: float32
Epoch 89, train loss: 0.19351619220346802 test loss: 0.14432971083212356
0    6.601545
dtype: float32
Epoch 90, train loss: 0.10528803581589097 test loss: 0.10262442112105301
0    7.208782
dtype: float32
Epoch 91, train loss: 0.06867222379231896 test loss: 0.09996752525356715
0    7.14629
dtype: float32
Epoch 92, train loss: 0.06637542292527945 test loss: 0.09932644781495954
0    7.285562
dtype: float32
Epoch 93, train loss: 0.06636938010464238 test loss: 0.10555909211928756
0    7.420674
dtype: float32
Epoch 94, train loss: 0.07416136152866055 test loss: 0.11367622652795717
0    7.031841
dtype: float32
Epoch 95, train loss: 0.06443736295818409 test loss: 0.09743150086059646
0    6.872647
dtype: float32
Epoch 96, train loss: 0.0762072194167591 test loss: 0.09401423377061799
0    7.239007
dtype: float32
Epoch 97, train loss: 0.06258456131330137 test loss: 0.0996998693750381
0    7.099614
dtype: float32
Epoch 98, train loss: 0.06256034848738609 test loss: 0.09721449026117132
0    7.132793
dtype: float32
Epoch 99, train loss: 0.060939710013279955 test loss: 0.09700038030573639
0    6.698217
dtype: float32
Epoch 100, train loss: 0.0951248678703401 test loss: 0.09413239309155484
0    6.96122
dtype: float32
Epoch 101, train loss: 0.07720111469179756 test loss: 0.09396525316520939
0    6.939333
dtype: float32
Epoch 102, train loss: 0.07281781525531549 test loss: 0.09191563219608163
0    6.70225
dtype: float32
Epoch 103, train loss: 0.09632407234398958 test loss: 0.09318532708410716
0    7.225529
dtype: float32
Epoch 104, train loss: 0.06488533452444029 test loss: 0.0924809273690554
0    6.955472
dtype: float32
Epoch 105, train loss: 0.06908950163349221 test loss: 0.09066859614210798
0    7.049764
dtype: float32
Epoch 106, train loss: 0.06333727670890346 test loss: 0.0922571822376559
0    6.485237
dtype: float32
Epoch 107, train loss: 0.12768886608298413 test loss: 0.100439514967526
0    7.298211
dtype: float32
Epoch 108, train loss: 0.06409319288046943 test loss: 0.09910284640404832
0    7.883408
dtype: float32
Epoch 109, train loss: 0.12044457091857871 test loss: 0.14509384898240266
0    7.645977
dtype: float32
Epoch 110, train loss: 0.0918820250024709 test loss: 0.11865003821942434
0    7.655993
dtype: float32
Epoch 111, train loss: 0.08391703376988124 test loss: 0.1110771132065543
0    7.681055
dtype: float32
Epoch 112, train loss: 0.08957883418102758 test loss: 0.12092420434621223
0    7.538619
dtype: float32
Epoch 113, train loss: 0.0730086308350435 test loss: 0.11199875982752373
0    7.146433
dtype: float32
Epoch 114, train loss: 0.05922442281510885 test loss: 0.09617690869639325
0    7.335964
dtype: float32
Epoch 115, train loss: 0.05979486097464547 test loss: 0.0964385721544124
0    7.863088
dtype: float32
Epoch 116, train loss: 0.11214618592697133 test loss: 0.1371225917827796
0    8.069527
dtype: float32
Epoch 117, train loss: 0.13726629994481881 test loss: 0.16239730431631524
0    7.417933
dtype: float32
Epoch 118, train loss: 0.06428649145188785 test loss: 0.10899603449756257
0    7.442853
dtype: float32
Epoch 119, train loss: 0.06764916938072672 test loss: 0.11207775941275916
0    6.797262
dtype: float32
Epoch 120, train loss: 0.08464292629352031 test loss: 0.08806527614731126
0    7.168147
dtype: float32
Epoch 121, train loss: 0.05879824106970769 test loss: 0.10372729815656381
0    7.317985
dtype: float32
Epoch 122, train loss: 0.06100096184414081 test loss: 0.10700640043713802
0    7.117759
dtype: float32
Epoch 123, train loss: 0.05834718996167722 test loss: 0.09932049728691146
0    7.359262
dtype: float32
Epoch 124, train loss: 0.06452280564159565 test loss: 0.11073264854010939
0    7.511378
dtype: float32
Epoch 125, train loss: 0.07680411969505317 test loss: 0.11513016520614548
0    7.306948
dtype: float32
Epoch 126, train loss: 0.058500731401423 test loss: 0.09849266921925069
0    7.128128
dtype: float32
Epoch 127, train loss: 0.05660183334549049 test loss: 0.09318934323530215
0    6.960163
dtype: float32
Epoch 128, train loss: 0.06165336077806255 test loss: 0.09096093336582042
0    7.188155
dtype: float32
Epoch 129, train loss: 0.055898711078884465 test loss: 0.09577443941456933
0    7.401409
dtype: float32
Epoch 130, train loss: 0.0704994304572748 test loss: 0.11487182973200331
0    7.933703
dtype: float32
Epoch 131, train loss: 0.10801427423759355 test loss: 0.13722795468741397
0    8.045062
dtype: float32
Epoch 132, train loss: 0.12981063231975362 test loss: 0.15362001055175983
0    7.445734
dtype: float32
Epoch 133, train loss: 0.07030041462506881 test loss: 0.11122375837505503
0    7.540083
dtype: float32
Epoch 134, train loss: 0.08167977433090935 test loss: 0.11691334025503884
0    6.858798
dtype: float32
Epoch 135, train loss: 0.07087018773607384 test loss: 0.0900605055222682
0    6.643821
dtype: float32
Epoch 136, train loss: 0.09707217333374547 test loss: 0.09391765661170239
0    6.766722
dtype: float32
Epoch 137, train loss: 0.08422785266234133 test loss: 0.09056194625019554
0    6.851822
dtype: float32
Epoch 138, train loss: 0.07177984586370746 test loss: 0.08936479995362442
0    6.940511
dtype: float32
Epoch 139, train loss: 0.0707242676186749 test loss: 0.089540552206325
0    6.763141
dtype: float32
Epoch 140, train loss: 0.07629406969562229 test loss: 0.08934032541164949
0    7.019876
dtype: float32
Epoch 141, train loss: 0.059958260285298694 test loss: 0.09017668605444572
0    7.077747
dtype: float32
Epoch 142, train loss: 0.05840510468110497 test loss: 0.09242857854975904
0    7.623034
dtype: float32
Epoch 143, train loss: 0.08709795879060846 test loss: 0.12061475957382156
0    7.406319
dtype: float32
Epoch 144, train loss: 0.06520485918074093 test loss: 0.10924590099666386
0    8.157827
dtype: float32
Epoch 145, train loss: 0.13289089192349146 test loss: 0.15947595160686176
0    7.710236
dtype: float32
Epoch 146, train loss: 0.09644780029684448 test loss: 0.13531192069522574
0    7.524839
dtype: float32
Epoch 147, train loss: 0.08880247514507487 test loss: 0.128554726075845
0    7.286723
dtype: float32
Epoch 148, train loss: 0.05932931806993511 test loss: 0.10783318874670407
0    6.737985
dtype: float32
Epoch 149, train loss: 0.08244292708055695 test loss: 0.08821091855292197
0    7.529352
dtype: float32
Epoch 150, train loss: 0.07638353190075553 test loss: 0.11915523251895196
0    7.012937
dtype: float32
Epoch 151, train loss: 0.05640844816603978 test loss: 0.09065128782857378
0    7.236337
dtype: float32
Epoch 152, train loss: 0.05564591243078576 test loss: 0.10524892522561428
0    7.173526
dtype: float32
Epoch 153, train loss: 0.053819190634427826 test loss: 0.09840445987790644
0    7.309574
dtype: float32
Epoch 154, train loss: 0.06167986240033477 test loss: 0.1031361660547556
0    6.997519
dtype: float32
Epoch 155, train loss: 0.055682865816863325 test loss: 0.09029761579914256
0    6.67069
dtype: float32
Epoch 156, train loss: 0.09213923637994555 test loss: 0.09172045013595015
0    7.266362
dtype: float32
Epoch 157, train loss: 0.05924410035447256 test loss: 0.10352280107946663
0    7.514535
dtype: float32
Epoch 158, train loss: 0.07412784324279062 test loss: 0.11476158319482029
0    7.67552
dtype: float32
Epoch 159, train loss: 0.08240517123251946 test loss: 0.12134160580775193
0    7.715867
dtype: float32
Epoch 160, train loss: 0.09936640881927492 test loss: 0.1278898919794681
0    7.591264
dtype: float32
Epoch 161, train loss: 0.07526309647099555 test loss: 0.11904197999797164
0    7.432106
dtype: float32
Epoch 162, train loss: 0.06469225412333676 test loss: 0.11171013128782964
0    7.113885
dtype: float32
Epoch 163, train loss: 0.05322974953014875 test loss: 0.09393029193572397
0    6.641101
dtype: float32
Epoch 164, train loss: 0.09542325540301778 test loss: 0.08885821357280052
0    6.451764
dtype: float32
Epoch 165, train loss: 0.11818056924621231 test loss: 0.0938422970103635
0    6.465457
dtype: float32
Epoch 166, train loss: 0.1032115785785766 test loss: 0.08925135166360014
0    6.579555
dtype: float32
Epoch 167, train loss: 0.12398310676259804 test loss: 0.0970055514892919
0    6.622825
dtype: float32
Epoch 168, train loss: 0.09222092035452863 test loss: 0.09017008300817508
0    6.689851
dtype: float32
Epoch 169, train loss: 0.07700787165567972 test loss: 0.09019296547286211
0    6.780581
dtype: float32
Epoch 170, train loss: 0.08699626768521516 test loss: 0.08794781881893102
0    7.152947
dtype: float32
Epoch 171, train loss: 0.05149161289224292 test loss: 0.09553418844823426
0    7.114721
dtype: float32
Epoch 172, train loss: 0.05222922755133408 test loss: 0.09618259056271229
0    7.122657
dtype: float32
Epoch 173, train loss: 0.0511850618235633 test loss: 0.09483911096593761
0    7.246213
dtype: float32
Epoch 174, train loss: 0.05324453422729656 test loss: 0.09974542387255352
0    7.140626
dtype: float32
Epoch 175, train loss: 0.05110618172371147 test loss: 0.09235220767537407
0    7.461352
dtype: float32
Epoch 176, train loss: 0.0661835304443649 test loss: 0.10984194899802768
0    7.311741
dtype: float32
Epoch 177, train loss: 0.05981957697408131 test loss: 0.10749410582764243
0    6.342364
dtype: float32
Epoch 178, train loss: 0.14843058477551205 test loss: 0.10685401454516906
0    6.753365
dtype: float32
Epoch 179, train loss: 0.07593962027118177 test loss: 0.08754907823494927
0    7.282576
dtype: float32
Epoch 180, train loss: 0.05721832704019036 test loss: 0.10594442377205567
0    7.188231
dtype: float32
Epoch 181, train loss: 0.050863116602663364 test loss: 0.09678824706370379
0    7.03192
dtype: float32
Epoch 182, train loss: 0.05501344534695223 test loss: 0.08900644258859505
0    6.497604
dtype: float32
Epoch 183, train loss: 0.10965062454935284 test loss: 0.08921066808755926
0    6.828011
dtype: float32
Epoch 184, train loss: 0.0778838964718821 test loss: 0.08513714747849997
0    6.854645
dtype: float32
Epoch 185, train loss: 0.0689297507375149 test loss: 0.08519186677709782
0    7.1925
dtype: float32
Epoch 186, train loss: 0.052615597456853735 test loss: 0.09063400043856813
0    7.709088
dtype: float32
Epoch 187, train loss: 0.11514782066798028 test loss: 0.13434696068389346
0    7.44585
dtype: float32
Epoch 188, train loss: 0.08379923141375242 test loss: 0.11438904371871636
0    7.777065
dtype: float32
Epoch 189, train loss: 0.11199841250284077 test loss: 0.14096266601189242
0    7.657599
dtype: float32
Epoch 190, train loss: 0.09706974306094063 test loss: 0.13610899366222073
0    7.823267
dtype: float32
Epoch 191, train loss: 0.10241389922321191 test loss: 0.14327912014692634
0    7.382127
dtype: float32
Epoch 192, train loss: 0.06175906537513888 test loss: 0.11079674707023139
0    7.457145
dtype: float32
Epoch 193, train loss: 0.07437836451725671 test loss: 0.11700976898038364
0    7.748671
dtype: float32
Epoch 194, train loss: 0.10019179886229976 test loss: 0.13784889236924813
0    7.73827
dtype: float32
Epoch 195, train loss: 0.09060427018419537 test loss: 0.13578824378117696
0    7.940288
dtype: float32
Epoch 196, train loss: 0.1260897864938691 test loss: 0.14913289766253918
0    7.856119
dtype: float32
Epoch 197, train loss: 0.09999292812940362 test loss: 0.129281212016766
0    7.375264
dtype: float32
Epoch 198, train loss: 0.05866230217075909 test loss: 0.10084181622827484
0    7.190079
dtype: float32
Epoch 199, train loss: 0.052240800565956154 test loss: 0.09793072165686202
0    6.40872
dtype: float32
Epoch 200, train loss: 0.10942109936264863 test loss: 0.09296485659896578
0    7.0
dtype: float32
Epoch 201, train loss: 0.06320363292275327 test loss: 0.08982389392148597
0    7.66995
dtype: float32
Epoch 202, train loss: 0.07953714332522996 test loss: 0.125437938084499
0    7.027958
dtype: float32
Epoch 203, train loss: 0.05294605031098624 test loss: 0.09088506888864437
0    7.240825
dtype: float32
Epoch 204, train loss: 0.050286867983161836 test loss: 0.09692942737041609
0    7.471519
dtype: float32
Epoch 205, train loss: 0.06396181766866488 test loss: 0.11509135726826397
0    6.823448
dtype: float32
Epoch 206, train loss: 0.07073704559477957 test loss: 0.08808758712187253
0    6.614084
dtype: float32
Epoch 207, train loss: 0.0888443908221975 test loss: 0.09040807179672375
0    6.71134
dtype: float32
Epoch 208, train loss: 0.08343122362818602 test loss: 0.08833247609876352
0    7.020879
dtype: float32
Epoch 209, train loss: 0.05374439712233722 test loss: 0.09453030486627892
0    6.971084
dtype: float32
Epoch 210, train loss: 0.05865283597004226 test loss: 0.09072497922847281
0    6.747209
dtype: float32
Epoch 211, train loss: 0.07514833037305696 test loss: 0.08887259542448574
0    6.612846
dtype: float32
Epoch 212, train loss: 0.09814652258367838 test loss: 0.09188641904349666
0    6.640089
dtype: float32
Epoch 213, train loss: 0.08235012403509355 test loss: 0.09066336454931938
0    7.223938
dtype: float32
Epoch 214, train loss: 0.0494885452483875 test loss: 0.09924941713398913
0    7.263228
dtype: float32
Epoch 215, train loss: 0.0497273461698884 test loss: 0.10061002432204658
0    6.966467
dtype: float32
Epoch 216, train loss: 0.050650134685153156 test loss: 0.09350853659679093
0    6.983173
dtype: float32
Epoch 217, train loss: 0.052327069953365744 test loss: 0.09492906027259763
0    7.257753
dtype: float32
Epoch 218, train loss: 0.04946725901064461 test loss: 0.10215424725269598
0    7.102131
dtype: float32
Epoch 219, train loss: 0.047241611030261275 test loss: 0.09515299776912177
0    7.211857
dtype: float32
Epoch 220, train loss: 0.04735996112581013 test loss: 0.10037602512395959
0    6.452835
dtype: float32
Epoch 221, train loss: 0.11517431512874612 test loss: 0.09769963314737802
0    7.259368
dtype: float32
Epoch 222, train loss: 0.05364984131221362 test loss: 0.10260911733057752
0    6.665793
dtype: float32
Epoch 223, train loss: 0.08440352658497015 test loss: 0.08765946893125823
0    6.576913
dtype: float32
Epoch 224, train loss: 0.08835716235202193 test loss: 0.0882446262844458
0    7.296228
dtype: float32
Epoch 225, train loss: 0.05057184542061856 test loss: 0.10203477036955115
0    7.530274
dtype: float32
Epoch 226, train loss: 0.07064563291696578 test loss: 0.11729577132369451
0    7.163056
dtype: float32
Epoch 227, train loss: 0.050159001072461046 test loss: 0.09124608389682246
0    6.88813
dtype: float32
Epoch 228, train loss: 0.062835590466508 test loss: 0.08691005596037782
0    6.787052
dtype: float32
Epoch 229, train loss: 0.07300738902881053 test loss: 0.08624637345896048
0    6.640625
dtype: float32
Epoch 230, train loss: 0.07959782502185031 test loss: 0.08838591285789263
0    6.940956
dtype: float32
Epoch 231, train loss: 0.0582258756068077 test loss: 0.08606416776137843
0    7.427078
dtype: float32
Epoch 232, train loss: 0.06335565705017179 test loss: 0.11096593493810457
0    7.478291
dtype: float32
Epoch 233, train loss: 0.07342603878108599 test loss: 0.11776610367681815
0    7.786213
dtype: float32
Epoch 234, train loss: 0.10746907488577566 test loss: 0.1372841706240452
0    7.549184
dtype: float32
Epoch 235, train loss: 0.07874616930702566 test loss: 0.12273466421579714
0    7.729507
dtype: float32
Epoch 236, train loss: 0.09621952429650754 test loss: 0.13375388586851422
0    7.401759
dtype: float32
Epoch 237, train loss: 0.06313193727891518 test loss: 0.11277205715990174
0    7.120043
dtype: float32
Epoch 238, train loss: 0.04755863299770667 test loss: 0.09511401398832445
0    7.184264
dtype: float32
Epoch 239, train loss: 0.047371508524895044 test loss: 0.09920458670813667
0    7.765888
dtype: float32
Epoch 240, train loss: 0.10316055755630536 test loss: 0.13663994145449834
0    7.420992
dtype: float32
Epoch 241, train loss: 0.063774353076259 test loss: 0.10571870390243258
0    7.242579
dtype: float32
Epoch 242, train loss: 0.04930774638530075 test loss: 0.0975356214268627
0    7.226787
dtype: float32
Epoch 243, train loss: 0.04876885762398818 test loss: 0.10057607221298484
0    6.637601
dtype: float32
Epoch 244, train loss: 0.09179063799303622 test loss: 0.08864386912507445
0    6.215162
dtype: float32
Epoch 245, train loss: 0.15622249160350143 test loss: 0.10763989095287994
0    7.064541
dtype: float32
Epoch 246, train loss: 0.05133415107951379 test loss: 0.09329648666691737
0    7.11347
dtype: float32
Epoch 247, train loss: 0.047077282907859425 test loss: 0.09211634357746362
0    7.160507
dtype: float32
Epoch 248, train loss: 0.04670935022048467 test loss: 0.09474724198724069
0    7.177839
dtype: float32
Epoch 249, train loss: 0.045522147368765656 test loss: 0.0934527050150499
0    7.379901
dtype: float32
Epoch 250, train loss: 0.05718157044401285 test loss: 0.10681904857772763
0    6.96327
dtype: float32
Epoch 251, train loss: 0.050805560945259426 test loss: 0.08960059321465266
0    6.856477
dtype: float32
Epoch 252, train loss: 0.05851839272512414 test loss: 0.08807653563253909
0    6.810192
dtype: float32
Epoch 253, train loss: 0.0671870340170045 test loss: 0.08566145297917677
0    6.858581
dtype: float32
Epoch 254, train loss: 0.06857683971013148 test loss: 0.09020281865905205
0    6.962045
dtype: float32
Epoch 255, train loss: 0.05348374790905787 test loss: 0.0916764788722378
0    6.978924
dtype: float32
Epoch 256, train loss: 0.052123212437742795 test loss: 0.09063712937174094
0    6.993174
dtype: float32
Epoch 257, train loss: 0.04610365115565868 test loss: 0.09610244914006778
0    7.177244
dtype: float32
Epoch 258, train loss: 0.049523511583258885 test loss: 0.10537156057070633
0    7.310294
dtype: float32
Epoch 259, train loss: 0.05948000522842495 test loss: 0.11088334239851533
0    7.423892
dtype: float32
Epoch 260, train loss: 0.07314711225688575 test loss: 0.12168264924428346
0    7.347353
dtype: float32
Epoch 261, train loss: 0.059627207590901565 test loss: 0.11301162118413544
0    7.243548
dtype: float32
Epoch 262, train loss: 0.05059592216880708 test loss: 0.1038955519935169
0    7.240434
dtype: float32
Epoch 263, train loss: 0.05360245696408849 test loss: 0.10429862314387563
0    7.299038
dtype: float32
Epoch 264, train loss: 0.053628769221803256 test loss: 0.10800339989395057
0    7.858904
dtype: float32
Epoch 265, train loss: 0.1125555760041527 test loss: 0.15148466101556493
0    7.004679
dtype: float32
Epoch 266, train loss: 0.046295038219185916 test loss: 0.09374556279975281
0    7.160455
dtype: float32
Epoch 267, train loss: 0.04637144392019251 test loss: 0.10205943431879604
0    6.877836
dtype: float32
Epoch 268, train loss: 0.05547867298090652 test loss: 0.09004520552525791
0    7.417943
dtype: float32
Epoch 269, train loss: 0.066674673181069 test loss: 0.11742997097869973
0    7.293481
dtype: float32
Epoch 270, train loss: 0.05948594366628453 test loss: 0.10732957589010542
0    7.547448
dtype: float32
Epoch 271, train loss: 0.08078445544713633 test loss: 0.11961339667687601
0    7.072877
dtype: float32
Epoch 272, train loss: 0.044427187950425516 test loss: 0.09373055306564497
0    6.802839
dtype: float32
Epoch 273, train loss: 0.08811044075063436 test loss: 0.08910287169230051
0    6.703383
dtype: float32
Epoch 274, train loss: 0.0721234481694685 test loss: 0.08991124391672158
0    6.915224
dtype: float32
Epoch 275, train loss: 0.06061038716182341 test loss: 0.09014307088787837
0    7.211999
dtype: float32
Epoch 276, train loss: 0.045818877602271574 test loss: 0.10201684430244726
0    6.988719
dtype: float32
Epoch 277, train loss: 0.049865100229816016 test loss: 0.0912139599730433
0    7.166242
dtype: float32
Epoch 278, train loss: 0.04724708083835908 test loss: 0.09990717067677055
0    7.335791
dtype: float32
Epoch 279, train loss: 0.05206019573592078 test loss: 0.1069984201032239
0    7.228148
dtype: float32
Epoch 280, train loss: 0.050048090056436075 test loss: 0.10245930947466743
0    7.420387
dtype: float32
Epoch 281, train loss: 0.06307240428476318 test loss: 0.11469712941686727
0    7.416658
dtype: float32
Epoch 282, train loss: 0.06012016669156927 test loss: 0.10939609639634111
0    7.327433
dtype: float32
Epoch 283, train loss: 0.056548313026663306 test loss: 0.10754679885689229
0    7.095665
dtype: float32
Epoch 284, train loss: 0.04647486039735773 test loss: 0.099626556583838
0    6.657362
dtype: float32
Epoch 285, train loss: 0.08056794817603434 test loss: 0.0870050081933526
0    6.423616
dtype: float32
Epoch 286, train loss: 0.10274501682058053 test loss: 0.09227370996114014
0    6.893249
dtype: float32
Epoch 287, train loss: 0.07253806146671003 test loss: 0.0903305518082086
0    6.777264
dtype: float32
Epoch 288, train loss: 0.0808264189212362 test loss: 0.08959997000075319
0    6.927615
dtype: float32
Epoch 289, train loss: 0.05491843831204751 test loss: 0.08938774818254727
0    7.222683
dtype: float32
Epoch 290, train loss: 0.051005705256953714 test loss: 0.09936364001311246
0    7.55343
dtype: float32
Epoch 291, train loss: 0.07959147160029056 test loss: 0.12144546079206002
0    7.23175
dtype: float32
Epoch 292, train loss: 0.05077462249627784 test loss: 0.10476233840686625
0    7.276838
dtype: float32
Epoch 293, train loss: 0.053719376626565625 test loss: 0.11092948234208513
0    6.645318
dtype: float32
Epoch 294, train loss: 0.08207524011643688 test loss: 0.08474334712716144
0    6.633536
dtype: float32
Epoch 295, train loss: 0.08436195912257109 test loss: 0.08666253399873503
0    6.460781
dtype: float32
Epoch 296, train loss: 0.10632471817396377 test loss: 0.09012613851634414
0    6.542956
dtype: float32
Epoch 297, train loss: 0.0917641917929573 test loss: 0.08748957994986445
0    6.759284
dtype: float32
Epoch 298, train loss: 0.06427064705513406 test loss: 0.0868100166736042
0    6.702872
dtype: float32
Epoch 299, train loss: 0.07316491263433227 test loss: 0.0885127946609611
Final train loss is: 0.07316491263433227, Test loss is: 0.0885127946609611
0    6.702872
dtype: float32
round is 2
0    5.765244
dtype: float32
Epoch 9, train loss: 0.34120566820544207 test loss: 0.22817269220709277
0    5.384557
dtype: float32
Epoch 10, train loss: 0.3742868032758716 test loss: 0.3332584531233625
0    6.327497
dtype: float32
Epoch 11, train loss: 0.2293479761933645 test loss: 0.16969625329352925
0    6.88314
dtype: float32
Epoch 12, train loss: 0.15896393760381297 test loss: 0.08927388629153152
0    7.835271
dtype: float32
Epoch 13, train loss: 0.1796883449927393 test loss: 0.08315592964418644
0    7.342665
dtype: float32
Epoch 14, train loss: 0.1648299620855086 test loss: 0.11706149638611846
0    8.316021
dtype: float32
Epoch 15, train loss: 0.2246678158918692 test loss: 0.13503257447698805
0    7.779387
dtype: float32
Epoch 16, train loss: 0.15750354861641358 test loss: 0.068097127520198
0    7.064021
dtype: float32
Epoch 17, train loss: 0.12794429194523066 test loss: 0.056963490206740845
0    6.688134
dtype: float32
Epoch 18, train loss: 0.11817853589250757 test loss: 0.053890777741819815
0    7.212263
dtype: float32
Epoch 19, train loss: 0.14396642197663434 test loss: 0.08518245778169929
0    8.111097
dtype: float32
Epoch 20, train loss: 0.21628918809420158 test loss: 0.12553973872335364
0    6.973223
dtype: float32
Epoch 21, train loss: 0.12108251134146855 test loss: 0.055267036781087304
0    6.675194
dtype: float32
Epoch 22, train loss: 0.10933303601628931 test loss: 0.049846363247728974
0    5.464008
dtype: float32
Epoch 23, train loss: 0.19952546592761997 test loss: 0.1373988897738312
0    6.538208
dtype: float32
Epoch 24, train loss: 0.10556818567176059 test loss: 0.058746954079640715
0    6.406267
dtype: float32
Epoch 25, train loss: 0.10260210971942951 test loss: 0.05821204890186562
0    6.977694
dtype: float32
Epoch 26, train loss: 0.11790495643787875 test loss: 0.06023007528247297
0    7.588416
dtype: float32
Epoch 27, train loss: 0.1638789476693086 test loss: 0.11153602525541892
0    7.452789
dtype: float32
Epoch 28, train loss: 0.12871162774478484 test loss: 0.0629754802469469
0    7.819524
dtype: float32
Epoch 29, train loss: 0.16465136557623408 test loss: 0.08134169867357323
0    7.50374
dtype: float32
Epoch 30, train loss: 0.13785355301219643 test loss: 0.06692692854743144
0    5.892412
dtype: float32
Epoch 31, train loss: 0.14191312157911715 test loss: 0.11861459826950616
0    5.774542
dtype: float32
Epoch 32, train loss: 0.16127794656243427 test loss: 0.13803079538213767
0    5.534908
dtype: float32
Epoch 33, train loss: 0.18558096363844415 test loss: 0.11326582954254716
0    5.066679
dtype: float32
Epoch 34, train loss: 0.2271788367575826 test loss: 0.19093664070045785
0    6.156319
dtype: float32
Epoch 35, train loss: 0.10841218328527553 test loss: 0.0772452807017208
0    6.883523
dtype: float32
Epoch 36, train loss: 0.1010591613587577 test loss: 0.04547036911663221
0    7.192011
dtype: float32
Epoch 37, train loss: 0.1241919651846974 test loss: 0.06681230483656493
0    6.276115
dtype: float32
Epoch 38, train loss: 0.10230379960947061 test loss: 0.08205374884814644
0    6.305244
dtype: float32
Epoch 39, train loss: 0.09388640335249057 test loss: 0.06509336468947163
0    5.710654
dtype: float32
Epoch 40, train loss: 0.13893775420526125 test loss: 0.1182184002334
0    5.880642
dtype: float32
Epoch 41, train loss: 0.11247119981083033 test loss: 0.07858822870134707
0    6.470704
dtype: float32
Epoch 42, train loss: 0.0871408275643906 test loss: 0.05790503247218135
0    6.149543
dtype: float32
Epoch 43, train loss: 0.10161298354290102 test loss: 0.09212373677325932
0    7.004444
dtype: float32
Epoch 44, train loss: 0.10029141165797724 test loss: 0.04718949906378517
0    6.637017
dtype: float32
Epoch 45, train loss: 0.08356073706177718 test loss: 0.06015777690250755
0    6.400097
dtype: float32
Epoch 46, train loss: 0.0877364992334292 test loss: 0.08082218435146517
0    7.18126
dtype: float32
Epoch 47, train loss: 0.10986976863156081 test loss: 0.0491164981759532
0    7.284473
dtype: float32
Epoch 48, train loss: 0.12354348529364043 test loss: 0.06411437797532527
0    6.791252
dtype: float32
Epoch 49, train loss: 0.08678132608019695 test loss: 0.05542255114998938
0    6.117166
dtype: float32
Epoch 50, train loss: 0.09731965855106327 test loss: 0.08381607954839786
0    6.000218
dtype: float32
Epoch 51, train loss: 0.11122740242512891 test loss: 0.1051532868391225
0    6.406096
dtype: float32
Epoch 52, train loss: 0.08687778394774637 test loss: 0.05457768133706986
0    5.501321
dtype: float32
Epoch 53, train loss: 0.16407116553957446 test loss: 0.15285759675612134
0    6.278858
dtype: float32
Epoch 54, train loss: 0.09334317663041286 test loss: 0.10043696002741967
0    5.979548
dtype: float32
Epoch 55, train loss: 0.11801876312319497 test loss: 0.12430793517904372
0    6.336055
dtype: float32
Epoch 56, train loss: 0.08394718163694048 test loss: 0.08176749138733165
0    6.692939
dtype: float32
Epoch 57, train loss: 0.08124124348516962 test loss: 0.05151462492200362
0    6.628471
dtype: float32
Epoch 58, train loss: 0.07831436897714235 test loss: 0.05654038769348218
0    6.996688
dtype: float32
Epoch 59, train loss: 0.09560950726855875 test loss: 0.04978277238009055
0    7.200368
dtype: float32
Epoch 60, train loss: 0.11523028595311156 test loss: 0.058958812983863185
0    6.515395
dtype: float32
Epoch 61, train loss: 0.078794704868598 test loss: 0.0709169628823592
0    6.321093
dtype: float32
Epoch 62, train loss: 0.08586317069424969 test loss: 0.08983126625605924
0    6.584565
dtype: float32
Epoch 63, train loss: 0.07809559318829137 test loss: 0.05706206069084921
0    6.813006
dtype: float32
Epoch 64, train loss: 0.0851190018616557 test loss: 0.04887665755978168
0    6.927649
dtype: float32
Epoch 65, train loss: 0.08628764392375392 test loss: 0.048670347988534736
0    6.865336
dtype: float32
Epoch 66, train loss: 0.08332908602816205 test loss: 0.05012103883638029
0    6.450562
dtype: float32
Epoch 67, train loss: 0.07764579368872827 test loss: 0.05997884513366321
0    7.011151
dtype: float32
Epoch 68, train loss: 0.09497899713584523 test loss: 0.052765448563461215
0    6.452109
dtype: float32
Epoch 69, train loss: 0.07579858408827742 test loss: 0.0626440070653384
0    5.852352
dtype: float32
Epoch 70, train loss: 0.12776793157796695 test loss: 0.1261421923308325
0    5.550313
dtype: float32
Epoch 71, train loss: 0.17216093381117945 test loss: 0.16717177362590147
0    5.484124
dtype: float32
Epoch 72, train loss: 0.1774053065671171 test loss: 0.16591316769950396
0    5.189033
dtype: float32
Epoch 73, train loss: 0.19777909602400093 test loss: 0.18119953096722857
0    6.344152
dtype: float32
Epoch 74, train loss: 0.08201433738805998 test loss: 0.07179165378927048
0    7.073123
dtype: float32
Epoch 75, train loss: 0.09184227106081984 test loss: 0.04781944434431361
0    6.353806
dtype: float32
Epoch 76, train loss: 0.07904954852208258 test loss: 0.07870534075104049
0    7.133971
dtype: float32
Epoch 77, train loss: 0.09256495670781203 test loss: 0.050797327870955436
0    7.743847
dtype: float32
Epoch 78, train loss: 0.1451306434051843 test loss: 0.07594790252959392
0    6.988734
dtype: float32
Epoch 79, train loss: 0.08328532124133402 test loss: 0.0505253417055552
0    7.396399
dtype: float32
Epoch 80, train loss: 0.11561934781537506 test loss: 0.06134590149612194
0    6.193273
dtype: float32
Epoch 81, train loss: 0.09363049704067503 test loss: 0.09504956437128333
0    5.892992
dtype: float32
Epoch 82, train loss: 0.10928367875205762 test loss: 0.1019102744600727
0    6.277443
dtype: float32
Epoch 83, train loss: 0.07946349903583229 test loss: 0.07146372503700336
0    6.775129
dtype: float32
Epoch 84, train loss: 0.08254546569042558 test loss: 0.05034313477626271
0    6.938523
dtype: float32
Epoch 85, train loss: 0.09355932219417407 test loss: 0.053117392500167455
0    6.168985
dtype: float32
Epoch 86, train loss: 0.08705340404358351 test loss: 0.08303521899657657
0    7.02723
dtype: float32
Epoch 87, train loss: 0.09361887679758232 test loss: 0.052917774287389814
0    6.60749
dtype: float32
Epoch 88, train loss: 0.07183164297080757 test loss: 0.05250667020544159
0    6.935053
dtype: float32
Epoch 89, train loss: 0.08489853539835597 test loss: 0.05087967573478633
0    6.579302
dtype: float32
Epoch 90, train loss: 0.07121456464429939 test loss: 0.0537837740195232
0    6.700143
dtype: float32
Epoch 91, train loss: 0.07551637372132372 test loss: 0.048830808866926506
0    6.880234
dtype: float32
Epoch 92, train loss: 0.07889031452563587 test loss: 0.05109107449665753
0    7.056526
dtype: float32
Epoch 93, train loss: 0.0900720415060554 test loss: 0.049983434693666465
0    6.534081
dtype: float32
Epoch 94, train loss: 0.07226900225761021 test loss: 0.06243322469400441
0    7.042789
dtype: float32
Epoch 95, train loss: 0.09557796369937972 test loss: 0.058759504405930967
0    6.242941
dtype: float32
Epoch 96, train loss: 0.08130301471829539 test loss: 0.08196851200332747
0    6.898826
dtype: float32
Epoch 97, train loss: 0.0834701652810521 test loss: 0.051982301128604066
0    6.701178
dtype: float32
Epoch 98, train loss: 0.07287441071384584 test loss: 0.050120980940398525
0    5.698556
dtype: float32
Epoch 99, train loss: 0.1352566384821056 test loss: 0.13079449287995257
0    6.203332
dtype: float32
Epoch 100, train loss: 0.07902692876656589 test loss: 0.07258688654831098
0    5.859813
dtype: float32
Epoch 101, train loss: 0.1135812874159356 test loss: 0.11394934290970474
0    5.531332
dtype: float32
Epoch 102, train loss: 0.14200831651476264 test loss: 0.11137223290153883
0    6.459711
dtype: float32
Epoch 103, train loss: 0.07156458105324195 test loss: 0.06780249217163985
0    6.448042
dtype: float32
Epoch 104, train loss: 0.0701314927493583 test loss: 0.05674349379662129
0    6.219767
dtype: float32
Epoch 105, train loss: 0.08019374194069213 test loss: 0.07631206507690205
0    7.035933
dtype: float32
Epoch 106, train loss: 0.09184096282584402 test loss: 0.057305768968034604
0    6.686632
dtype: float32
Epoch 107, train loss: 0.07222268577487838 test loss: 0.054623194582329594
0    7.072734
dtype: float32
Epoch 108, train loss: 0.09254601328503775 test loss: 0.05779535139631075
0    6.778881
dtype: float32
Epoch 109, train loss: 0.0843087067908135 test loss: 0.059132709314246856
0    6.920919
dtype: float32
Epoch 110, train loss: 0.09169155114664329 test loss: 0.05585803668090059
0    6.998361
dtype: float32
Epoch 111, train loss: 0.09099004716538217 test loss: 0.059952209036170226
0    6.66549
dtype: float32
Epoch 112, train loss: 0.07133043734593017 test loss: 0.05215694779898878
0    6.230176
dtype: float32
Epoch 113, train loss: 0.07810721747147413 test loss: 0.07579434178777068
0    6.294881
dtype: float32
Epoch 114, train loss: 0.07842054180947726 test loss: 0.08163842241730648
0    6.169787
dtype: float32
Epoch 115, train loss: 0.07790614744870601 test loss: 0.07172968641629958
0    6.079746
dtype: float32
Epoch 116, train loss: 0.08852282777401414 test loss: 0.07841758550412879
0    6.187383
dtype: float32
Epoch 117, train loss: 0.07875827513186312 test loss: 0.07195926370849431
0    6.142899
dtype: float32
Epoch 118, train loss: 0.08298093378312509 test loss: 0.07891195971339225
0    5.940418
dtype: float32
Epoch 119, train loss: 0.09274787022178413 test loss: 0.08285419812148491
0    6.572961
dtype: float32
Epoch 120, train loss: 0.06881864761762042 test loss: 0.05310028906875953
0    6.945038
dtype: float32
Epoch 121, train loss: 0.08262565391895928 test loss: 0.051465356996232954
0    6.893253
dtype: float32
Epoch 122, train loss: 0.08066130043104879 test loss: 0.05503286714337427
0    6.582323
dtype: float32
Epoch 123, train loss: 0.06805990606188723 test loss: 0.050434731052368266
0    5.76626
dtype: float32
Epoch 124, train loss: 0.11486879834298111 test loss: 0.10424724942013645
0    5.734027
dtype: float32
Epoch 125, train loss: 0.1330570815155962 test loss: 0.12202661635692202
0    6.367557
dtype: float32
Epoch 126, train loss: 0.07061360230354286 test loss: 0.05992539881493181
0    6.538331
dtype: float32
Epoch 127, train loss: 0.07738972442802454 test loss: 0.05388832696353886
0    6.830243
dtype: float32
Epoch 128, train loss: 0.08501190669043178 test loss: 0.06461109472508597
0    6.612453
dtype: float32
Epoch 129, train loss: 0.06819394393947861 test loss: 0.05360907866469167
0    6.721293
dtype: float32
Epoch 130, train loss: 0.07152181308216078 test loss: 0.05245331641404603
0    6.752202
dtype: float32
Epoch 131, train loss: 0.07240826135241184 test loss: 0.053826263584376026
0    6.37954
dtype: float32
Epoch 132, train loss: 0.07102619047710472 test loss: 0.0613295966396054
0    6.60745
dtype: float32
Epoch 133, train loss: 0.0671387606533504 test loss: 0.05520241196416375
0    6.392311
dtype: float32
Epoch 134, train loss: 0.07291611644948388 test loss: 0.06744311999813984
0    6.800663
dtype: float32
Epoch 135, train loss: 0.07581817009089643 test loss: 0.05312329516908391
0    7.041384
dtype: float32
Epoch 136, train loss: 0.08919120569437419 test loss: 0.07069348188807854
0    6.878908
dtype: float32
Epoch 137, train loss: 0.07353540453685936 test loss: 0.05217047612350294
0    5.739493
dtype: float32
Epoch 138, train loss: 0.13143687986014757 test loss: 0.11595446339798915
0    6.213234
dtype: float32
Epoch 139, train loss: 0.07622514475967909 test loss: 0.07320706994592127
0    6.033968
dtype: float32
Epoch 140, train loss: 0.08250042204923834 test loss: 0.0753188249839935
0    6.763325
dtype: float32
Epoch 141, train loss: 0.07048399239642895 test loss: 0.05156142128724081
0    6.34754
dtype: float32
Epoch 142, train loss: 0.0673705461570406 test loss: 0.05998906431174258
0    6.259657
dtype: float32
Epoch 143, train loss: 0.07529881746490487 test loss: 0.06688126070783124
0    5.69003
dtype: float32
Epoch 144, train loss: 0.14184260018955835 test loss: 0.13796601606940093
0    6.584319
dtype: float32
Epoch 145, train loss: 0.0670857063431585 test loss: 0.05110208880156754
0    6.520383
dtype: float32
Epoch 146, train loss: 0.06552801542531056 test loss: 0.04981323263363507
0    6.428843
dtype: float32
Epoch 147, train loss: 0.06653563234088479 test loss: 0.05536037742561378
0    6.618279
dtype: float32
Epoch 148, train loss: 0.06445190574551393 test loss: 0.05143700496959633
0    6.374695
dtype: float32
Epoch 149, train loss: 0.06644481566566296 test loss: 0.05404166432590823
0    6.059881
dtype: float32
Epoch 150, train loss: 0.08559525892527428 test loss: 0.06859965380516458
0    6.584723
dtype: float32
Epoch 151, train loss: 0.06438283783882906 test loss: 0.04985450481324421
0    6.681217
dtype: float32
Epoch 152, train loss: 0.0666393358378106 test loss: 0.049212087691811124
0    6.896571
dtype: float32
Epoch 153, train loss: 0.07345898048164484 test loss: 0.05679384198475936
0    6.76166
dtype: float32
Epoch 154, train loss: 0.0669399674317141 test loss: 0.05099291684307365
0    6.024818
dtype: float32
Epoch 155, train loss: 0.08792724917099538 test loss: 0.06858207509068447
0    6.501795
dtype: float32
Epoch 156, train loss: 0.06422793093755327 test loss: 0.050018766921792204
0    6.773381
dtype: float32
Epoch 157, train loss: 0.07322381468434894 test loss: 0.0588314041990983
0    6.171247
dtype: float32
Epoch 158, train loss: 0.07431702592795711 test loss: 0.05988224436974077
0    6.335124
dtype: float32
Epoch 159, train loss: 0.06913513561080822 test loss: 0.06173501153106126
0    6.478931
dtype: float32
Epoch 160, train loss: 0.06637506136407888 test loss: 0.05559800614765285
0    6.330798
dtype: float32
Epoch 161, train loss: 0.06577054378820857 test loss: 0.05367030600929482
0    6.586695
dtype: float32
Epoch 162, train loss: 0.06324326612711527 test loss: 0.05216781523882134
0    6.568369
dtype: float32
Epoch 163, train loss: 0.06270311128515946 test loss: 0.05091093700410913
0    6.370803
dtype: float32
Epoch 164, train loss: 0.06851556130187478 test loss: 0.055885869139412014
0    6.201965
dtype: float32
Epoch 165, train loss: 0.06715841983044839 test loss: 0.05125273541751729
0    6.551115
dtype: float32
Epoch 166, train loss: 0.06393021182068608 test loss: 0.051185680839768585
0    6.524899
dtype: float32
Epoch 167, train loss: 0.0634808101082311 test loss: 0.0505417725375498
0    6.411582
dtype: float32
Epoch 168, train loss: 0.06357499494625425 test loss: 0.05159889226745418
0    6.666149
dtype: float32
Epoch 169, train loss: 0.0745805244660901 test loss: 0.06386140250409582
0    6.795535
dtype: float32
Epoch 170, train loss: 0.064678876094899 test loss: 0.051870102660285876
0    7.064815
dtype: float32
Epoch 171, train loss: 0.08139424049802137 test loss: 0.06600447483042242
0    6.734875
dtype: float32
Epoch 172, train loss: 0.06623784255804206 test loss: 0.05218036079806521
0    6.359953
dtype: float32
Epoch 173, train loss: 0.07008014008379569 test loss: 0.0575626084158657
0    7.15805
dtype: float32
Epoch 174, train loss: 0.08137150532548333 test loss: 0.06540208400572248
0    6.741581
dtype: float32
Epoch 175, train loss: 0.06209175392769909 test loss: 0.05071557620716412
0    6.370034
dtype: float32
Epoch 176, train loss: 0.07554303470045076 test loss: 0.05815554135419807
0    6.490094
dtype: float32
Epoch 177, train loss: 0.06989638131029813 test loss: 0.05391768822265565
0    6.625968
dtype: float32
Epoch 178, train loss: 0.0851474457172197 test loss: 0.06820423160510078
0    7.022086
dtype: float32
Epoch 179, train loss: 0.06358018579266639 test loss: 0.05568586857549105
0    6.319762
dtype: float32
Epoch 180, train loss: 0.08870737102540752 test loss: 0.07000636778098365
0    6.359646
dtype: float32
Epoch 181, train loss: 0.0940702389746699 test loss: 0.07678820472103089
0    6.970117
dtype: float32
Epoch 182, train loss: 0.06444206081987298 test loss: 0.0530635620203878
0    6.947216
dtype: float32
Epoch 183, train loss: 0.06703100012305725 test loss: 0.0629951862362051
0    7.370533
dtype: float32
Epoch 184, train loss: 0.09246857235398959 test loss: 0.08306411959248376
0    6.418714
dtype: float32
Epoch 185, train loss: 0.07418828957335026 test loss: 0.05275190928185067
0    6.464468
dtype: float32
Epoch 186, train loss: 0.07694459297645344 test loss: 0.061052993898389724
0    6.487539
dtype: float32
Epoch 187, train loss: 0.07735242211955658 test loss: 0.06035772287944002
0    6.754124
dtype: float32
Epoch 188, train loss: 0.0634645470741537 test loss: 0.05153330169379455
0    7.057272
dtype: float32
Epoch 189, train loss: 0.06597726159237867 test loss: 0.05518452788675967
0    7.20194
dtype: float32
Epoch 190, train loss: 0.08162442240845422 test loss: 0.07278703146351105
0    6.685997
dtype: float32
Epoch 191, train loss: 0.0644510953300712 test loss: 0.05645389133912197
0    6.998119
dtype: float32
Epoch 192, train loss: 0.0613020173481157 test loss: 0.052215639349203286
0    6.893726
dtype: float32
Epoch 193, train loss: 0.059834993074784494 test loss: 0.053043708964039434
0    6.583483
dtype: float32
Epoch 194, train loss: 0.0648431684798131 test loss: 0.05260372224626302
0    7.043815
dtype: float32
Epoch 195, train loss: 0.06590022214433629 test loss: 0.055787719999213115
0    7.119308
dtype: float32
Epoch 196, train loss: 0.06638758724847944 test loss: 0.05491976925359571
0    6.658543
dtype: float32
Epoch 197, train loss: 0.0658873345947871 test loss: 0.0548819105120995
0    6.248862
dtype: float32
Epoch 198, train loss: 0.08347614081625061 test loss: 0.056896477875039826
0    6.687387
dtype: float32
Epoch 199, train loss: 0.06726773675937932 test loss: 0.05582293296452542
0    6.985585
dtype: float32
Epoch 200, train loss: 0.061744688557103314 test loss: 0.05407645084692106
0    7.131281
dtype: float32
Epoch 201, train loss: 0.07284376711751421 test loss: 0.059416807994269426
0    7.024607
dtype: float32
Epoch 202, train loss: 0.07361265271586726 test loss: 0.06822660933601606
0    6.511118
dtype: float32
Epoch 203, train loss: 0.06997544329357527 test loss: 0.05161840459375354
0    6.611307
dtype: float32
Epoch 204, train loss: 0.06876788157764137 test loss: 0.05444982695996123
0    6.846443
dtype: float32
Epoch 205, train loss: 0.05797068144175122 test loss: 0.052003105344984556
0    6.562213
dtype: float32
Epoch 206, train loss: 0.07183016026508406 test loss: 0.05664073577150012
0    6.916049
dtype: float32
Epoch 207, train loss: 0.061114622405099704 test loss: 0.051396217715917875
0    6.766127
dtype: float32
Epoch 208, train loss: 0.060003566384983914 test loss: 0.05081504747281604
0    6.438147
dtype: float32
Epoch 209, train loss: 0.08334814073948735 test loss: 0.06624370795091897
0    7.15064
dtype: float32
Epoch 210, train loss: 0.06551810476304201 test loss: 0.05483801071102901
0    7.400236
dtype: float32
Epoch 211, train loss: 0.09399985097251776 test loss: 0.08042311975479843
0    7.047159
dtype: float32
Epoch 212, train loss: 0.06660645483588554 test loss: 0.057166226269770595
0    7.011292
dtype: float32
Epoch 213, train loss: 0.06363006933940869 test loss: 0.05798496876119792
0    6.836506
dtype: float32
Epoch 214, train loss: 0.060909361011730584 test loss: 0.05216868116873315
0    6.868725
dtype: float32
Epoch 215, train loss: 0.06857357797347748 test loss: 0.06302591209085331
0    7.264206
dtype: float32
Epoch 216, train loss: 0.07408560859770065 test loss: 0.0682505333399558
0    7.075355
dtype: float32
Epoch 217, train loss: 0.06581247555023989 test loss: 0.06260415984726996
0    6.981857
dtype: float32
Epoch 218, train loss: 0.05914367672151202 test loss: 0.056247918609123926
0    7.127498
dtype: float32
Epoch 219, train loss: 0.08453650085547042 test loss: 0.0808763320876452
0    7.894042
dtype: float32
Epoch 220, train loss: 0.1378819094466216 test loss: 0.11159612041912555
0    6.87257
dtype: float32
Epoch 221, train loss: 0.06305407570624835 test loss: 0.055871280865741293
0    6.893489
dtype: float32
Epoch 222, train loss: 0.05970155413303996 test loss: 0.055079319945583766
0    7.18996
dtype: float32
Epoch 223, train loss: 0.06674629520201465 test loss: 0.06906352671736499
0    7.68231
dtype: float32
Epoch 224, train loss: 0.0997781683536036 test loss: 0.08631911170531627
0    7.307443
dtype: float32
Epoch 225, train loss: 0.07114288150323188 test loss: 0.06354101453330736
0    6.61593
dtype: float32
Epoch 226, train loss: 0.07476053490489079 test loss: 0.06747465879352885
0    6.546833
dtype: float32
Epoch 227, train loss: 0.07157739309400125 test loss: 0.06158535676981879
0    6.509855
dtype: float32
Epoch 228, train loss: 0.07785375791007852 test loss: 0.07141360492691602
0    6.261124
dtype: float32
Epoch 229, train loss: 0.09717279203803518 test loss: 0.08412387426328222
0    6.979394
dtype: float32
Epoch 230, train loss: 0.06500723385423178 test loss: 0.060603513278636736
0    6.629557
dtype: float32
Epoch 231, train loss: 0.06591173644468826 test loss: 0.05271216328144396
0    6.69818
dtype: float32
Epoch 232, train loss: 0.06247179750288793 test loss: 0.05463557826009937
0    6.492641
dtype: float32
Epoch 233, train loss: 0.0724514781217922 test loss: 0.05551885967049543
0    6.944023
dtype: float32
Epoch 234, train loss: 0.06137260744590027 test loss: 0.058355267722267096
0    6.537602
dtype: float32
Epoch 235, train loss: 0.07064918308360517 test loss: 0.05464121645440579
0    7.010945
dtype: float32
Epoch 236, train loss: 0.06259240797878401 test loss: 0.06309719622357791
0    7.03972
dtype: float32
Epoch 237, train loss: 0.07088871917334705 test loss: 0.06954062797337911
0    6.546672
dtype: float32
Epoch 238, train loss: 0.07458342676213885 test loss: 0.06111082891209457
0    6.134007
dtype: float32
Epoch 239, train loss: 0.08984464387427187 test loss: 0.06924339322569943
0    6.115582
dtype: float32
Epoch 240, train loss: 0.10745044967027734 test loss: 0.08526518451532783
0    7.028297
dtype: float32
Epoch 241, train loss: 0.06463385496508796 test loss: 0.06344800793331029
0    6.592061
dtype: float32
Epoch 242, train loss: 0.06512734920612688 test loss: 0.053759256193919476
0    6.769522
dtype: float32
Epoch 243, train loss: 0.060258970346368824 test loss: 0.053643379616634596
0    6.974276
dtype: float32
Epoch 244, train loss: 0.06513353856397291 test loss: 0.06165985560663055
0    6.641483
dtype: float32
Epoch 245, train loss: 0.058517736016621205 test loss: 0.052898041463858146
0    6.806005
dtype: float32
Epoch 246, train loss: 0.05641356996190244 test loss: 0.05296856372446924
0    6.819997
dtype: float32
Epoch 247, train loss: 0.0559301748305357 test loss: 0.05544989783705933
0    6.614525
dtype: float32
Epoch 248, train loss: 0.06058372839674565 test loss: 0.05454799670511768
0    7.065173
dtype: float32
Epoch 249, train loss: 0.06276718800689833 test loss: 0.05421279295903311
0    6.844081
dtype: float32
Epoch 250, train loss: 0.055218199587333525 test loss: 0.05150051619788066
0    6.376325
dtype: float32
Epoch 251, train loss: 0.08328404432904872 test loss: 0.0671141879324624
0    6.655133
dtype: float32
Epoch 252, train loss: 0.06644418772429417 test loss: 0.05651967449841614
0    6.917079
dtype: float32
Epoch 253, train loss: 0.05861003983915429 test loss: 0.056807246273776535
0    6.958768
dtype: float32
Epoch 254, train loss: 0.05807637731117365 test loss: 0.055346098424236136
0    7.215666
dtype: float32
Epoch 255, train loss: 0.08111745161676588 test loss: 0.07877055034659987
0    7.055715
dtype: float32
Epoch 256, train loss: 0.060683505908443104 test loss: 0.06335424089125638
0    6.884002
dtype: float32
Epoch 257, train loss: 0.055888970446172574 test loss: 0.05606111636180927
0    6.817592
dtype: float32
Epoch 258, train loss: 0.05624824208864494 test loss: 0.052359748307319834
0    6.661669
dtype: float32
Epoch 259, train loss: 0.057258706292884744 test loss: 0.0526360977265844
0    7.164194
dtype: float32
Epoch 260, train loss: 0.07338971401986405 test loss: 0.06974723427381754
0    6.733518
dtype: float32
Epoch 261, train loss: 0.060931449723630106 test loss: 0.05249972123475984
0    6.540483
dtype: float32
Epoch 262, train loss: 0.06482943205634777 test loss: 0.054731274058080245
0    6.619916
dtype: float32
Epoch 263, train loss: 0.06298979030188201 test loss: 0.059426490352204896
0    6.446212
dtype: float32
Epoch 264, train loss: 0.07536952189166195 test loss: 0.07291637028607627
0    6.483137
dtype: float32
Epoch 265, train loss: 0.06848642803703232 test loss: 0.062157321418511144
0    6.644449
dtype: float32
Epoch 266, train loss: 0.058675191396427996 test loss: 0.051275091419502136
0    6.462373
dtype: float32
Epoch 267, train loss: 0.06195214481227773 test loss: 0.052560199627289764
0    7.128797
dtype: float32
Epoch 268, train loss: 0.07511579124747733 test loss: 0.06910987916771112
0    6.79748
dtype: float32
Epoch 269, train loss: 0.05745155831993504 test loss: 0.05243321135732208
0    6.77403
dtype: float32
Epoch 270, train loss: 0.0555136214208965 test loss: 0.0521516936894974
0    6.21102
dtype: float32
Epoch 271, train loss: 0.08552804898810887 test loss: 0.06918796729983447
0    6.544011
dtype: float32
Epoch 272, train loss: 0.06329623287270571 test loss: 0.05724765723872303
0    6.457815
dtype: float32
Epoch 273, train loss: 0.06583752934966194 test loss: 0.056696932682413506
0    7.12803
dtype: float32
Epoch 274, train loss: 0.0739308232787561 test loss: 0.06890451689736286
0    6.376336
dtype: float32
Epoch 275, train loss: 0.08348155225261347 test loss: 0.07375930217026949
0    7.318546
dtype: float32
Epoch 276, train loss: 0.08180379285358114 test loss: 0.07854826459270224
0    6.808389
dtype: float32
Epoch 277, train loss: 0.05535811071361665 test loss: 0.056206877391481856
0    6.469571
dtype: float32
Epoch 278, train loss: 0.0686465731102782 test loss: 0.05633939198597947
0    6.402059
dtype: float32
Epoch 279, train loss: 0.07478606010614727 test loss: 0.05968184081911049
0    5.91644
dtype: float32
Epoch 280, train loss: 0.1125397773602476 test loss: 0.06658813086771273
0    6.554456
dtype: float32
Epoch 281, train loss: 0.06378679949493443 test loss: 0.054853422816575056
0    6.909389
dtype: float32
Epoch 282, train loss: 0.056032438775471705 test loss: 0.056170735086187154
0    6.877722
dtype: float32
Epoch 283, train loss: 0.054113855692152095 test loss: 0.056624272750132466
0    6.98156
dtype: float32
Epoch 284, train loss: 0.05913340163395489 test loss: 0.059580849216772834
0    7.251571
dtype: float32
Epoch 285, train loss: 0.08694901623567539 test loss: 0.0847086942626212
0    6.996897
dtype: float32
Epoch 286, train loss: 0.07074952418071731 test loss: 0.06936128575739989
0    6.697216
dtype: float32
Epoch 287, train loss: 0.061142501717488605 test loss: 0.05492623785565192
0    6.413069
dtype: float32
Epoch 288, train loss: 0.0740970025121268 test loss: 0.06523587633599993
0    6.861812
dtype: float32
Epoch 289, train loss: 0.05458714735581953 test loss: 0.054997008575419885
0    6.719204
dtype: float32
Epoch 290, train loss: 0.05666877061128788 test loss: 0.05271133603697636
0    6.752546
dtype: float32
Epoch 291, train loss: 0.05559868323685423 test loss: 0.053151603509578975
0    6.857118
dtype: float32
Epoch 292, train loss: 0.055529515468490116 test loss: 0.055112222025732266
0    7.496113
dtype: float32
Epoch 293, train loss: 0.09633255920221845 test loss: 0.08842740160692023
0    6.759419
dtype: float32
Epoch 294, train loss: 0.054532371720012414 test loss: 0.052914235016628744
0    6.815611
dtype: float32
Epoch 295, train loss: 0.0529019613394081 test loss: 0.054133582854798225
0    6.086189
dtype: float32
Epoch 296, train loss: 0.10997763944896048 test loss: 0.0829116576157381
0    6.738678
dtype: float32
Epoch 297, train loss: 0.05339709126927111 test loss: 0.053688189055977935
0    6.155725
dtype: float32
Epoch 298, train loss: 0.11032373924211519 test loss: 0.08538619253995146
0    6.957342
dtype: float32
Epoch 299, train loss: 0.057514992293588064 test loss: 0.0573507554854461
Final train loss is: 0.057514992293588064, Test loss is: 0.0573507554854461
0    6.957342
dtype: float32
round is 3
0    5.78239
dtype: float32
Epoch 8, train loss: 0.1618450014363707 test loss: 0.3553459242098673
0    9.211845
dtype: float32
Epoch 12, train loss: 0.2187604973360919 test loss: 0.21756338793932808
0    4.821862
dtype: float32
Epoch 15, train loss: 0.18776736688544604 test loss: 0.3895863942409798
0    6.562277
dtype: float32
Epoch 16, train loss: 0.12045908802521114 test loss: 0.23453942671502417
0    4.995592
dtype: float32
Epoch 18, train loss: 0.16613650240949857 test loss: 0.5095649165651801
0    3.281543
dtype: float32
Epoch 19, train loss: 0.33583761759082775 test loss: 0.8307885649789816
0    4.958162
dtype: float32
Epoch 20, train loss: 0.1996324210575741 test loss: 0.5114427741150422
0    4.665663
dtype: float32
Epoch 21, train loss: 0.18476058428442071 test loss: 0.5653316321582573
0    9.113307
dtype: float32
Epoch 22, train loss: 0.15285361525482136 test loss: 0.15637530472354327
0    8.355797
dtype: float32
Epoch 23, train loss: 0.1430824124191301 test loss: 0.14692458867375327
0    9.439413
dtype: float32
Epoch 24, train loss: 0.17224737831704132 test loss: 0.17528495104721434
0    8.612121
dtype: float32
Epoch 25, train loss: 0.1457185384252666 test loss: 0.13636426819041989
0    5.47518
dtype: float32
Epoch 26, train loss: 0.16080533908471664 test loss: 0.4277701878332451
0    9.217407
dtype: float32
Epoch 27, train loss: 0.1609070013637223 test loss: 0.15900439623829088
0    11.25039
dtype: float32
Epoch 28, train loss: 0.23443050329644044 test loss: 0.2905137164746877
0    10.159849
dtype: float32
Epoch 29, train loss: 0.24281280569238042 test loss: 0.2052954846511015
0    9.95743
dtype: float32
Epoch 30, train loss: 0.1879660452822398 test loss: 0.17418452114123908
0    9.298317
dtype: float32
Epoch 31, train loss: 0.15617162244496163 test loss: 0.13757385387738055
0    7.622566
dtype: float32
Epoch 32, train loss: 0.09822441180549349 test loss: 0.18892422564696748
0    7.807823
dtype: float32
Epoch 33, train loss: 0.10903277672540336 test loss: 0.15298854266907558
0    8.42414
dtype: float32
Epoch 34, train loss: 0.12797945739574842 test loss: 0.12189556262391349
0    8.142736
dtype: float32
Epoch 35, train loss: 0.10097616732097797 test loss: 0.12579925398281017
0    7.688566
dtype: float32
Epoch 36, train loss: 0.09172133598146887 test loss: 0.14423201556574597
0    6.651374
dtype: float32
Epoch 37, train loss: 0.0851650548460168 test loss: 0.24592472093983023
0    7.032231
dtype: float32
Epoch 38, train loss: 0.1143373364501917 test loss: 0.2066004402726982
0    8.235269
dtype: float32
Epoch 39, train loss: 0.1409623188376221 test loss: 0.13931522426331666
0    8.68001
dtype: float32
Epoch 40, train loss: 0.14401123786320114 test loss: 0.13607103235966486
0    5.618742
dtype: float32
Epoch 41, train loss: 0.15523416476459903 test loss: 0.3591694608520583
0    9.538369
dtype: float32
Epoch 42, train loss: 0.1531000922214097 test loss: 0.16372579571185478
0    8.337345
dtype: float32
Epoch 43, train loss: 0.15716654145347805 test loss: 0.13899935885494205
0    12.251612
dtype: float32
Epoch 44, train loss: 0.25513489264394773 test loss: 0.35242274993893624
0    10.29685
dtype: float32
Epoch 45, train loss: 0.19512092912725165 test loss: 0.21383152274497827
0    9.008281
dtype: float32
Epoch 46, train loss: 0.15562404331517155 test loss: 0.1377560881893409
0    8.895315
dtype: float32
Epoch 47, train loss: 0.14180737722430353 test loss: 0.12702692396530307
0    9.49303
dtype: float32
Epoch 48, train loss: 0.14908027436043303 test loss: 0.16068201306705346
0    7.94829
dtype: float32
Epoch 49, train loss: 0.09714502741257058 test loss: 0.12785853932082303
0    8.245461
dtype: float32
Epoch 50, train loss: 0.10948317491699254 test loss: 0.11775616185068781
0    6.90215
dtype: float32
Epoch 51, train loss: 0.07795044924715806 test loss: 0.18670328425251626
0    5.729472
dtype: float32
Epoch 52, train loss: 0.1370549890188373 test loss: 0.343436533538027
0    5.77985
dtype: float32
Epoch 53, train loss: 0.12183462547550682 test loss: 0.34509834976922243
0    5.366616
dtype: float32
Epoch 54, train loss: 0.1478842020757288 test loss: 0.39550677184723393
0    4.783227
dtype: float32
Epoch 55, train loss: 0.21490486991334498 test loss: 0.5047613016923072
0    5.786195
dtype: float32
Epoch 56, train loss: 0.11187435990071644 test loss: 0.33049206055220876
0    5.667161
dtype: float32
Epoch 57, train loss: 0.1500412633256677 test loss: 0.3678015893297805
0    5.327705
dtype: float32
Epoch 58, train loss: 0.14906956733046248 test loss: 0.384680887196686
0    3.755908
dtype: float32
Epoch 59, train loss: 0.31637317268928894 test loss: 0.6853806239596517
0    4.17827
dtype: float32
Epoch 60, train loss: 0.26858649632195186 test loss: 0.6162614781774907
0    5.455397
dtype: float32
Epoch 61, train loss: 0.21500943306781686 test loss: 0.38437575477718605
0    5.635998
dtype: float32
Epoch 62, train loss: 0.13979484063988415 test loss: 0.36011258690402714
0    6.916092
dtype: float32
Epoch 63, train loss: 0.0775336239255344 test loss: 0.18754536264027122
0    7.365241
dtype: float32
Epoch 64, train loss: 0.07378380469456071 test loss: 0.1373770241448258
0    7.382297
dtype: float32
Epoch 65, train loss: 0.07345654624016859 test loss: 0.13183053107822862
0    7.331445
dtype: float32
Epoch 66, train loss: 0.07255391641343611 test loss: 0.12841067901312847
0    7.81404
dtype: float32
Epoch 67, train loss: 0.0942688787475295 test loss: 0.1088504748045379
0    7.355147
dtype: float32
Epoch 68, train loss: 0.08764535332478315 test loss: 0.1292218107333094
0    7.218952
dtype: float32
Epoch 69, train loss: 0.06983472894522187 test loss: 0.13847939697427544
0    5.552921
dtype: float32
Epoch 70, train loss: 0.1297025576251661 test loss: 0.3281991975115095
0    7.107224
dtype: float32
Epoch 71, train loss: 0.07120901397760104 test loss: 0.1443351663536683
0    6.009964
dtype: float32
Epoch 72, train loss: 0.10229113748730917 test loss: 0.24788792525253603
0    4.437612
dtype: float32
Epoch 73, train loss: 0.23616324335730624 test loss: 0.4953141335465654
0    5.724553
dtype: float32
Epoch 74, train loss: 0.12304409090874444 test loss: 0.3130876176306004
0    6.509029
dtype: float32
Epoch 75, train loss: 0.07878273206399986 test loss: 0.20563446379531825
0    6.697481
dtype: float32
Epoch 76, train loss: 0.07507513615998535 test loss: 0.18125443911784747
0    7.577053
dtype: float32
Epoch 77, train loss: 0.08041536863618094 test loss: 0.10626902218066119
0    8.637794
dtype: float32
Epoch 78, train loss: 0.11776643399103986 test loss: 0.13065325617511278
0    8.120785
dtype: float32
Epoch 79, train loss: 0.10828462488977794 test loss: 0.1140513254424911
0    7.880239
dtype: float32
Epoch 80, train loss: 0.09334875540786143 test loss: 0.10708526877797912
0    9.726768
dtype: float32
Epoch 81, train loss: 0.1714093924193488 test loss: 0.2121659644398859
0    8.397872
dtype: float32
Epoch 82, train loss: 0.12838731682008836 test loss: 0.12367092073984755
0    7.785603
dtype: float32
Epoch 83, train loss: 0.10199781401135168 test loss: 0.11352580236113083
0    7.481116
dtype: float32
Epoch 84, train loss: 0.07737956538555986 test loss: 0.11898499692967957
0    7.280253
dtype: float32
Epoch 85, train loss: 0.097412566674662 test loss: 0.1353246759918143
0    8.000464
dtype: float32
Epoch 86, train loss: 0.08022118693798184 test loss: 0.09702639836230814
0    8.899014
dtype: float32
Epoch 87, train loss: 0.13211141437800425 test loss: 0.14950440165401058
0    8.922965
dtype: float32
Epoch 88, train loss: 0.12839899600471927 test loss: 0.1499384938007912
0    8.813508
dtype: float32
Epoch 89, train loss: 0.11889564268976234 test loss: 0.14262913545688807
0    8.801605
dtype: float32
Epoch 90, train loss: 0.1281745501428599 test loss: 0.15288365866219156
0    7.356221
dtype: float32
Epoch 91, train loss: 0.08223733660900615 test loss: 0.11248392358320174
0    7.061659
dtype: float32
Epoch 92, train loss: 0.06336535639271652 test loss: 0.11644610467520515
0    8.340193
dtype: float32
Epoch 93, train loss: 0.0996026602766131 test loss: 0.12645574458286293
0    7.973761
dtype: float32
Epoch 94, train loss: 0.08324659082683322 test loss: 0.09992028560185133
0    8.135757
dtype: float32
Epoch 95, train loss: 0.08295140667715559 test loss: 0.10006353342686444
0    7.439224
dtype: float32
Epoch 96, train loss: 0.06472393618825739 test loss: 0.09854117903336378
0    6.615877
dtype: float32
Epoch 97, train loss: 0.07861856453417715 test loss: 0.15514596494251248
0    6.642403
dtype: float32
Epoch 98, train loss: 0.09034347353184242 test loss: 0.15500277201014767
0    6.194004
dtype: float32
Epoch 99, train loss: 0.0894089677696861 test loss: 0.20613849065211132
0    5.489387
dtype: float32
Epoch 100, train loss: 0.13390926862543853 test loss: 0.2914607054613845
0    4.403196
dtype: float32
Epoch 101, train loss: 0.23626804326459228 test loss: 0.4330194018231915
0    5.380414
dtype: float32
Epoch 102, train loss: 0.14654541457142817 test loss: 0.3167658635508445
0    6.945334
dtype: float32
Epoch 103, train loss: 0.0660290661923735 test loss: 0.14741994953619095
0    6.458378
dtype: float32
Epoch 104, train loss: 0.08226806188564269 test loss: 0.18842824082934675
0    6.197268
dtype: float32
Epoch 105, train loss: 0.10854649351492149 test loss: 0.1989326051860818
0    5.963703
dtype: float32
Epoch 106, train loss: 0.10235101805060902 test loss: 0.22134320526224957
0    6.070378
dtype: float32
Epoch 107, train loss: 0.11923858854329127 test loss: 0.21496252837650864
0    5.500995
dtype: float32
Epoch 108, train loss: 0.13136813743540746 test loss: 0.28299700593845517
0    6.934721
dtype: float32
Epoch 109, train loss: 0.06301123684426446 test loss: 0.13157937350957027
0    7.379189
dtype: float32
Epoch 110, train loss: 0.06542676033610262 test loss: 0.09706222563513575
0    6.338307
dtype: float32
Epoch 111, train loss: 0.0796619890160474 test loss: 0.1796280262725022
0    7.201886
dtype: float32
Epoch 112, train loss: 0.059386430839385 test loss: 0.10730947061871175
0    7.150456
dtype: float32
Epoch 113, train loss: 0.06746780308024335 test loss: 0.10245761016838487
0    7.281889
dtype: float32
Epoch 114, train loss: 0.06076208703118996 test loss: 0.09968334242825903
0    9.044084
dtype: float32
Epoch 115, train loss: 0.13251794328009275 test loss: 0.1934510585047667
0    7.48602
dtype: float32
Epoch 116, train loss: 0.06477520306416355 test loss: 0.10129414986999641
0    6.568593
dtype: float32
Epoch 117, train loss: 0.06821658947179492 test loss: 0.15442248066393882
0    7.093312
dtype: float32
Epoch 118, train loss: 0.06237204403406752 test loss: 0.1140925768614698
0    6.60587
dtype: float32
Epoch 119, train loss: 0.07746014838205656 test loss: 0.14154144506372746
0    7.47138
dtype: float32
Epoch 120, train loss: 0.06593267741447918 test loss: 0.09594763508847273
0    7.268214
dtype: float32
Epoch 121, train loss: 0.0611147250674024 test loss: 0.09775292038877971
0    7.539845
dtype: float32
Epoch 122, train loss: 0.06724114675058696 test loss: 0.09322913182104757
0    8.395119
dtype: float32
Epoch 123, train loss: 0.10897130249123803 test loss: 0.1309370818536946
0    8.135165
dtype: float32
Epoch 124, train loss: 0.08197590196436917 test loss: 0.11203180676576524
0    8.330993
dtype: float32
Epoch 125, train loss: 0.08870112190861222 test loss: 0.1246301600623385
0    7.629063
dtype: float32
Epoch 126, train loss: 0.08114533806980395 test loss: 0.10549086548941158
0    9.486551
dtype: float32
Epoch 127, train loss: 0.1525047038869346 test loss: 0.22586049398435237
0    7.880054
dtype: float32
Epoch 128, train loss: 0.08410884080686228 test loss: 0.10904799027586456
0    7.011688
dtype: float32
Epoch 129, train loss: 0.059869670027528375 test loss: 0.1144639380287545
0    7.036678
dtype: float32
Epoch 130, train loss: 0.05769216132692414 test loss: 0.1068640840778802
0    8.0369
dtype: float32
Epoch 131, train loss: 0.09904333322833278 test loss: 0.12705566712907834
0    8.232278
dtype: float32
Epoch 132, train loss: 0.09858751713047453 test loss: 0.14047449992931232
0    7.955007
dtype: float32
Epoch 133, train loss: 0.08501033835237026 test loss: 0.11694432241338576
0    8.283391
dtype: float32
Epoch 134, train loss: 0.10670947824553033 test loss: 0.1429489319488659
0    8.500073
dtype: float32
Epoch 135, train loss: 0.0979484795482779 test loss: 0.14017631381332257
0    7.431795
dtype: float32
Epoch 136, train loss: 0.05984383456596511 test loss: 0.09814832210086909
0    7.373417
dtype: float32
Epoch 137, train loss: 0.06344149837300725 test loss: 0.10231848067984298
0    7.1919
dtype: float32
Epoch 138, train loss: 0.05908343565251921 test loss: 0.10562363938815833
0    8.032433
dtype: float32
Epoch 139, train loss: 0.10226043092869738 test loss: 0.1265933132524161
0    8.21513
dtype: float32
Epoch 140, train loss: 0.08971188293358055 test loss: 0.1317418502973655
0    8.637249
dtype: float32
Epoch 141, train loss: 0.11778384343587407 test loss: 0.16583784380932065
0    7.360857
dtype: float32
Epoch 142, train loss: 0.058261841451243544 test loss: 0.09744837752115416
0    6.774013
dtype: float32
Epoch 143, train loss: 0.059263599323498416 test loss: 0.1264339912484066
0    6.122044
dtype: float32
Epoch 144, train loss: 0.10172324182481847 test loss: 0.1934062635242661
0    6.657934
dtype: float32
Epoch 145, train loss: 0.06865907981448349 test loss: 0.1478575305255387
0    6.712151
dtype: float32
Epoch 146, train loss: 0.06299531571302992 test loss: 0.14281723775520808
0    6.196926
dtype: float32
Epoch 147, train loss: 0.09434074197576751 test loss: 0.19240496194795945
0    6.647508
dtype: float32
Epoch 148, train loss: 0.06396006914636111 test loss: 0.13768123200159013
0    7.705076
dtype: float32
Epoch 149, train loss: 0.06856405720678552 test loss: 0.0976171732570485
0    7.704516
dtype: float32
Epoch 150, train loss: 0.06700654004144668 test loss: 0.1100512201437184
0    7.280535
dtype: float32
Epoch 151, train loss: 0.05480754268581652 test loss: 0.10407319208271971
0    6.649688
dtype: float32
Epoch 152, train loss: 0.06927106465023151 test loss: 0.13789708418283145
0    6.511786
dtype: float32
Epoch 153, train loss: 0.06374437185270547 test loss: 0.14228205892959594
0    6.548445
dtype: float32
Epoch 154, train loss: 0.06392183248605375 test loss: 0.15142590250235716
0    6.700238
dtype: float32
Epoch 155, train loss: 0.06659376755576418 test loss: 0.13933586714650215
0    7.019073
dtype: float32
Epoch 156, train loss: 0.0536083120757317 test loss: 0.10802481061814999
0    6.489829
dtype: float32
Epoch 157, train loss: 0.08801567239123949 test loss: 0.13978271318860877
0    4.529192
dtype: float32
Epoch 158, train loss: 0.22138066403865267 test loss: 0.3627592956000627
0    5.742617
dtype: float32
Epoch 159, train loss: 0.11045301559464069 test loss: 0.2234462541164713
0    4.109631
dtype: float32
Epoch 160, train loss: 0.27882334216309246 test loss: 0.5195713427780384
0    5.073706
dtype: float32
Epoch 161, train loss: 0.1723491862574101 test loss: 0.35333256087207676
0    4.722043
dtype: float32
Epoch 162, train loss: 0.20742034563689332 test loss: 0.38254306378891767
0    4.624801
dtype: float32
Epoch 163, train loss: 0.22062957490472182 test loss: 0.3939744097924243
0    6.852128
dtype: float32
Epoch 164, train loss: 0.06732779554831216 test loss: 0.12415292732799353
0    6.219409
dtype: float32
Epoch 165, train loss: 0.08855348710875725 test loss: 0.1739563850576658
0    6.256838
dtype: float32
Epoch 166, train loss: 0.09196590568629966 test loss: 0.1786794780154462
0    6.044002
dtype: float32
Epoch 167, train loss: 0.09406531663050355 test loss: 0.1941737400337974
0    6.600336
dtype: float32
Epoch 168, train loss: 0.06637872178487987 test loss: 0.13226497447789887
0    6.86699
dtype: float32
Epoch 169, train loss: 0.05704620044354912 test loss: 0.11284128033588561
0    7.072686
dtype: float32
Epoch 170, train loss: 0.05425544090937677 test loss: 0.1018373053446939
0    7.602418
dtype: float32
Epoch 171, train loss: 0.07724698638755612 test loss: 0.11304755778892686
0    8.332294
dtype: float32
Epoch 172, train loss: 0.09647116433463235 test loss: 0.14737958874729326
0    8.720628
dtype: float32
Epoch 173, train loss: 0.11548133270233502 test loss: 0.18121310376040933
0    8.082662
dtype: float32
Epoch 174, train loss: 0.07520000993262949 test loss: 0.11883951337492808
0    7.88013
dtype: float32
Epoch 175, train loss: 0.08899265343693685 test loss: 0.11916771120866232
0    7.236248
dtype: float32
Epoch 176, train loss: 0.05281456692909057 test loss: 0.09665404998406221
0    6.452852
dtype: float32
Epoch 177, train loss: 0.07557604157003221 test loss: 0.13398195211559163
0    5.365691
dtype: float32
Epoch 178, train loss: 0.1472637998134181 test loss: 0.2610337708262726
0    4.471986
dtype: float32
Epoch 179, train loss: 0.213186335509815 test loss: 0.39194709703164105
0    5.673597
dtype: float32
Epoch 180, train loss: 0.10838394321363184 test loss: 0.1991838706143265
0    6.212299
dtype: float32
Epoch 181, train loss: 0.08974774291798242 test loss: 0.15663474648076098
0    6.030555
dtype: float32
Epoch 182, train loss: 0.09754673649773977 test loss: 0.20948217485236015
0    5.309682
dtype: float32
Epoch 183, train loss: 0.15955944588263302 test loss: 0.2934327123907927
0    6.747574
dtype: float32
Epoch 184, train loss: 0.06959192346006919 test loss: 0.14358585946609081
0    7.157397
dtype: float32
Epoch 185, train loss: 0.05707084804750731 test loss: 0.10209702284901918
0    7.187191
dtype: float32
Epoch 186, train loss: 0.05394916470221851 test loss: 0.10577005102424304
0    8.218444
dtype: float32
Epoch 187, train loss: 0.09888818390774994 test loss: 0.1414057690300822
0    7.885036
dtype: float32
Epoch 188, train loss: 0.09835483008371448 test loss: 0.1363809321354243
0    7.636941
dtype: float32
Epoch 189, train loss: 0.066135838535107 test loss: 0.12293866720914488
0    7.466876
dtype: float32
Epoch 190, train loss: 0.05953845142197943 test loss: 0.11313261329831023
0    7.140084
dtype: float32
Epoch 191, train loss: 0.05359014187851636 test loss: 0.10400799026181194
0    7.119418
dtype: float32
Epoch 192, train loss: 0.051965186315769664 test loss: 0.10224300773549234
0    6.998441
dtype: float32
Epoch 193, train loss: 0.05343606657510839 test loss: 0.10034596428049589
0    7.147935
dtype: float32
Epoch 194, train loss: 0.050736657150346524 test loss: 0.09418689251459574
0    7.570913
dtype: float32
Epoch 195, train loss: 0.07245217956443623 test loss: 0.10897136006760294
0    7.274571
dtype: float32
Epoch 196, train loss: 0.06876576256637035 test loss: 0.10517424574065126
0    7.410142
dtype: float32
Epoch 197, train loss: 0.06976367626884833 test loss: 0.09799440963526024
0    7.843594
dtype: float32
Epoch 198, train loss: 0.07884955265139919 test loss: 0.1277414852553643
0    8.463496
dtype: float32
Epoch 199, train loss: 0.09505462386392474 test loss: 0.1642194489578761
0    7.813274
dtype: float32
Epoch 200, train loss: 0.0805202516195519 test loss: 0.11932357946230475
0    7.223437
dtype: float32
Epoch 201, train loss: 0.052846053402423765 test loss: 0.0980923937935669
0    7.280308
dtype: float32
Epoch 202, train loss: 0.05538097191852729 test loss: 0.09968551701743401
0    7.1197
dtype: float32
Epoch 203, train loss: 0.05179123164182672 test loss: 0.10589137776188139
0    7.073657
dtype: float32
Epoch 204, train loss: 0.050697104047283725 test loss: 0.10330458098013012
0    7.114247
dtype: float32
Epoch 205, train loss: 0.04954155065094491 test loss: 0.100899329673662
0    7.843442
dtype: float32
Epoch 206, train loss: 0.06909793757654904 test loss: 0.11218166710298494
0    6.574726
dtype: float32
Epoch 207, train loss: 0.06117576833403334 test loss: 0.13645792698343073
0    6.51802
dtype: float32
Epoch 208, train loss: 0.07409237063788172 test loss: 0.15190189340761612
0    6.391443
dtype: float32
Epoch 209, train loss: 0.07260462119887182 test loss: 0.16670218306792645
0    5.433496
dtype: float32
Epoch 210, train loss: 0.13342227374491913 test loss: 0.28822628961512287
0    5.933659
dtype: float32
Epoch 211, train loss: 0.11668620722717563 test loss: 0.21701661753584262
0    5.881757
dtype: float32
Epoch 212, train loss: 0.12254725903957907 test loss: 0.23366388961051027
0    5.609877
dtype: float32
Epoch 213, train loss: 0.12267054322021963 test loss: 0.2471819307076925
0    6.214441
dtype: float32
Epoch 214, train loss: 0.09463931457355332 test loss: 0.2105462623231919
0    6.791162
dtype: float32
Epoch 215, train loss: 0.05455622009725131 test loss: 0.12284472694432932
0    6.989052
dtype: float32
Epoch 216, train loss: 0.04985804106364323 test loss: 0.11366743388532558
0    7.517776
dtype: float32
Epoch 217, train loss: 0.06199678825420865 test loss: 0.11659826075424269
0    7.455101
dtype: float32
Epoch 218, train loss: 0.05563861691533233 test loss: 0.12409953483372378
0    7.372184
dtype: float32
Epoch 219, train loss: 0.0532441807152946 test loss: 0.0994764766152455
0    6.624623
dtype: float32
Epoch 220, train loss: 0.05909909951334824 test loss: 0.11355060325486538
0    6.227956
dtype: float32
Epoch 221, train loss: 0.100628073184923 test loss: 0.19158491243118453
0    6.842664
dtype: float32
Epoch 222, train loss: 0.05161271578011635 test loss: 0.11391792072879785
0    6.5781
dtype: float32
Epoch 223, train loss: 0.06423116670658613 test loss: 0.13970208511736637
0    6.345495
dtype: float32
Epoch 224, train loss: 0.08170623640491032 test loss: 0.1734251507214792
0    6.340009
dtype: float32
Epoch 225, train loss: 0.07025093149231026 test loss: 0.16413785117112983
0    6.576775
dtype: float32
Epoch 226, train loss: 0.060267242124686524 test loss: 0.12757515309404868
0    6.527097
dtype: float32
Epoch 227, train loss: 0.07395405579062571 test loss: 0.14836886607680774
0    6.254667
dtype: float32
Epoch 228, train loss: 0.07625206807107447 test loss: 0.1852319300549744
0    7.379367
dtype: float32
Epoch 229, train loss: 0.05297643124007169 test loss: 0.1329562422063358
0    7.260623
dtype: float32
Epoch 230, train loss: 0.05404147856748659 test loss: 0.1138157194350317
0    7.38482
dtype: float32
Epoch 231, train loss: 0.05507957624607406 test loss: 0.11226366214694014
0    7.590289
dtype: float32
Epoch 232, train loss: 0.06012496969362299 test loss: 0.1265411537417003
0    7.753829
dtype: float32
Epoch 233, train loss: 0.07216281659207258 test loss: 0.13330753060016998
0    6.88411
dtype: float32
Epoch 234, train loss: 0.05864333614469798 test loss: 0.1335785025516078
0    7.197889
dtype: float32
Epoch 235, train loss: 0.04961053030389604 test loss: 0.12568310253247156
0    8.082184
dtype: float32
Epoch 236, train loss: 0.08733971765590041 test loss: 0.17131501741595398
0    7.25211
dtype: float32
Epoch 237, train loss: 0.05235289668306789 test loss: 0.11803847944954134
0    6.883054
dtype: float32
Epoch 238, train loss: 0.05884704451989593 test loss: 0.1500333180149374
0    7.301279
dtype: float32
Epoch 239, train loss: 0.05903079419192439 test loss: 0.13357237283488624
0    7.776309
dtype: float32
Epoch 240, train loss: 0.06340607841864093 test loss: 0.14654773506362867
0    8.242451
dtype: float32
Epoch 241, train loss: 0.08731281436279649 test loss: 0.17559614105530436
0    7.637045
dtype: float32
Epoch 242, train loss: 0.06651646823937388 test loss: 0.15589576319564044
0    7.173554
dtype: float32
Epoch 243, train loss: 0.04829149764149638 test loss: 0.11857805775044841
0    7.173954
dtype: float32
Epoch 244, train loss: 0.0477341667471089 test loss: 0.11644924047747869
0    5.252975
dtype: float32
Epoch 245, train loss: 0.15509330253464113 test loss: 0.32329446640067006
0    5.949759
dtype: float32
Epoch 246, train loss: 0.1045613958006622 test loss: 0.2641429929318792
0    6.607514
dtype: float32
Epoch 247, train loss: 0.05612681771070259 test loss: 0.1644423673830797
0    7.48087
dtype: float32
Epoch 248, train loss: 0.06981012105867587 test loss: 0.12475392564757531
0    7.324266
dtype: float32
Epoch 249, train loss: 0.04735207303458092 test loss: 0.13056102222456792
0    7.087044
dtype: float32
Epoch 250, train loss: 0.0510745593344953 test loss: 0.11349523034655434
0    7.380824
dtype: float32
Epoch 251, train loss: 0.05530462904914469 test loss: 0.12121081563046447
0    7.690907
dtype: float32
Epoch 252, train loss: 0.06860707544042466 test loss: 0.12904565990299238
0    8.241103
dtype: float32
Epoch 253, train loss: 0.10905012483647882 test loss: 0.17327419386668955
0    7.854064
dtype: float32
Epoch 254, train loss: 0.06141576946318491 test loss: 0.12208431765876329
0    7.211277
dtype: float32
Epoch 255, train loss: 0.046338132314245814 test loss: 0.13477476832422217
0    6.736591
dtype: float32
Epoch 256, train loss: 0.05484114267338011 test loss: 0.1513425144364965
0    7.62253
dtype: float32
Epoch 257, train loss: 0.06354214512028022 test loss: 0.1580900327151988
0    7.265925
dtype: float32
Epoch 258, train loss: 0.054777361244312234 test loss: 0.13202469963045874
0    8.01823
dtype: float32
Epoch 259, train loss: 0.07386443292485231 test loss: 0.17102755930391017
0    7.468057
dtype: float32
Epoch 260, train loss: 0.05557341657987073 test loss: 0.1398924637576172
0    8.227974
dtype: float32
Epoch 261, train loss: 0.09586879269161536 test loss: 0.1833442727312869
0    7.640076
dtype: float32
Epoch 262, train loss: 0.07377915315767856 test loss: 0.15039710802040293
0    7.639449
dtype: float32
Epoch 263, train loss: 0.0593519683929935 test loss: 0.11510702918329259
0    7.580418
dtype: float32
Epoch 264, train loss: 0.06006729526515827 test loss: 0.12688888098038803
0    7.918058
dtype: float32
Epoch 265, train loss: 0.08374014071965187 test loss: 0.15816452418028867
0    8.612341
dtype: float32
Epoch 266, train loss: 0.11195804267523626 test loss: 0.19519873588504869
0    7.290487
dtype: float32
Epoch 267, train loss: 0.04689397260621259 test loss: 0.11891399482585648
0    7.647705
dtype: float32
Epoch 268, train loss: 0.06843704973405952 test loss: 0.1458118987046403
0    7.575171
dtype: float32
Epoch 269, train loss: 0.05656196407631049 test loss: 0.13967838801564333
0    7.502682
dtype: float32
Epoch 270, train loss: 0.05315468434180656 test loss: 0.13663461032142243
0    7.415915
dtype: float32
Epoch 271, train loss: 0.05707037531830954 test loss: 0.15356175858638738
0    7.188981
dtype: float32
Epoch 272, train loss: 0.047816634824446105 test loss: 0.12612501134678875
0    7.036973
dtype: float32
Epoch 273, train loss: 0.04974666242696367 test loss: 0.14600027944899743
0    6.554451
dtype: float32
Epoch 274, train loss: 0.07847485958611347 test loss: 0.19075421355380806
0    7.207298
dtype: float32
Epoch 275, train loss: 0.0480744935012548 test loss: 0.13277475393468477
0    7.107858
dtype: float32
Epoch 276, train loss: 0.045175459025113114 test loss: 0.15778544056316954
0    6.562241
dtype: float32
Epoch 277, train loss: 0.0765132938509307 test loss: 0.17547899103250136
0    6.70513
dtype: float32
Epoch 278, train loss: 0.058503318737958505 test loss: 0.12505099109820533
0    6.428167
dtype: float32
Epoch 279, train loss: 0.0664876692653696 test loss: 0.1699258479619099
0    6.019027
dtype: float32
Epoch 280, train loss: 0.1130423739422491 test loss: 0.19724292713996977
0    5.898406
dtype: float32
Epoch 281, train loss: 0.09782289441115272 test loss: 0.2043097474414462
0    5.972655
dtype: float32
Epoch 282, train loss: 0.10866276874311417 test loss: 0.20205560177587276
0    6.418433
dtype: float32
Epoch 283, train loss: 0.06672727857820235 test loss: 0.1877614323571175
0    7.803972
dtype: float32
Epoch 284, train loss: 0.07480600766611545 test loss: 0.15749633032683363
0    6.935986
dtype: float32
Epoch 285, train loss: 0.04896274360251794 test loss: 0.1331026150542285
0    6.901206
dtype: float32
Epoch 286, train loss: 0.04618897958546446 test loss: 0.1587006971597026
0    7.837189
dtype: float32
Epoch 287, train loss: 0.06971387965739 test loss: 0.15770064898134792
0    7.291956
dtype: float32
Epoch 288, train loss: 0.0535798351843231 test loss: 0.14170278929154304
0    7.507806
dtype: float32
Epoch 289, train loss: 0.057619542287302254 test loss: 0.15980581942099267
0    7.615486
dtype: float32
Epoch 290, train loss: 0.06283554553370957 test loss: 0.16394604826042217
0    8.276381
dtype: float32
Epoch 291, train loss: 0.0823546495370094 test loss: 0.18082459611777715
0    7.26299
dtype: float32
Epoch 292, train loss: 0.04609282745336486 test loss: 0.21917824952305495
0    6.811043
dtype: float32
Epoch 293, train loss: 0.048887030155747725 test loss: 0.21802881431886706
0    7.872605
dtype: float32
Epoch 294, train loss: 0.09014599762084646 test loss: 0.15258350939433807
0    8.86167
dtype: float32
Epoch 295, train loss: 0.14155318692157626 test loss: 0.22942175045872937
0    7.639724
dtype: float32
Epoch 296, train loss: 0.08724003082743961 test loss: 0.13561931278981063
0    8.284391
dtype: float32
Epoch 297, train loss: 0.09063478960446605 test loss: 0.1558836486939037
0    7.849837
dtype: float32
Epoch 298, train loss: 0.06301344482110541 test loss: 0.15189122831096022
0    7.351621
dtype: float32
Epoch 299, train loss: 0.045753369360062274 test loss: 0.1568534521756984
Final train loss is: 0.045753369360062274, Test loss is: 0.1568534521756984
0    7.351621
dtype: float32
round is 4
0    13.876121
dtype: float32
Epoch 4, train loss: 0.31127932207010994 test loss: 0.6173262915958939
0    13.55642
dtype: float32
Epoch 8, train loss: 0.24774228621479205 test loss: 0.626573305028077
0    11.830347
dtype: float32
Epoch 9, train loss: 0.19067625816344827 test loss: 0.49180682382630647
0    11.508493
dtype: float32
Epoch 10, train loss: 0.17123469034787037 test loss: 0.49674569208562136
0    10.681935
dtype: float32
Epoch 11, train loss: 0.16689241997775328 test loss: 0.3960277330096429
0    10.236686
dtype: float32
Epoch 12, train loss: 0.17863262963397852 test loss: 0.3957419405296415
0    9.850841
dtype: float32
Epoch 13, train loss: 0.19041344371298285 test loss: 0.3898294994049867
0    9.633789
dtype: float32
Epoch 15, train loss: 0.15965658061602836 test loss: 0.40407570367089873
0    10.075861
dtype: float32
Epoch 16, train loss: 0.13791011901718028 test loss: 0.39942332409076187
0    10.212461
dtype: float32
Epoch 17, train loss: 0.13215130598922176 test loss: 0.4297345967012357
0    10.269383
dtype: float32
Epoch 18, train loss: 0.12837084198810347 test loss: 0.43298812686346105
0    10.365768
dtype: float32
Epoch 19, train loss: 0.13175212731830255 test loss: 0.4437481087657762
0    9.414074
dtype: float32
Epoch 20, train loss: 0.1325951371246894 test loss: 0.3517375666314824
0    9.684183
dtype: float32
Epoch 21, train loss: 0.11029282576017942 test loss: 0.3841385276788383
0    9.091136
dtype: float32
Epoch 22, train loss: 0.15028982271702127 test loss: 0.34153413009735334
0    8.767461
dtype: float32
Epoch 23, train loss: 0.17533063988496336 test loss: 0.3212872815300183
0    10.018119
dtype: float32
Epoch 24, train loss: 0.11809698709112529 test loss: 0.44140984329871846
0    9.336429
dtype: float32
Epoch 25, train loss: 0.1107162214272333 test loss: 0.3433833306732907
0    8.949709
dtype: float32
Epoch 26, train loss: 0.14558475983640745 test loss: 0.35077395518199517
0    8.619999
dtype: float32
Epoch 27, train loss: 0.17807144670310418 test loss: 0.33743440462796515
0    9.609263
dtype: float32
Epoch 28, train loss: 0.10343687363318312 test loss: 0.40021397739972314
0    9.400407
dtype: float32
Epoch 29, train loss: 0.0974129112582003 test loss: 0.35914436114860504
0    9.452834
dtype: float32
Epoch 30, train loss: 0.09203844568780577 test loss: 0.38005918966446767
0    9.630925
dtype: float32
Epoch 31, train loss: 0.10335042550910462 test loss: 0.40675196967769284
0    9.584435
dtype: float32
Epoch 32, train loss: 0.10631282118430067 test loss: 0.4094900923496811
0    9.105477
dtype: float32
Epoch 33, train loss: 0.1012154398352234 test loss: 0.3754073089313389
0    8.886402
dtype: float32
Epoch 34, train loss: 0.09757480156101295 test loss: 0.3437784721592946
0    8.366347
dtype: float32
Epoch 35, train loss: 0.1474151742420086 test loss: 0.26257914447122066
0    9.103473
dtype: float32
Epoch 36, train loss: 0.08552837176303506 test loss: 0.358546256870277
0    9.271586
dtype: float32
Epoch 37, train loss: 0.08718782394282795 test loss: 0.3915941283009397
0    8.863003
dtype: float32
Epoch 38, train loss: 0.0967500356681651 test loss: 0.2904722476160153
0    8.335811
dtype: float32
Epoch 39, train loss: 0.14738942244038178 test loss: 0.2243527298766715
0    9.182173
dtype: float32
Epoch 40, train loss: 0.08791591347403242 test loss: 0.33810323601188963
0    8.969044
dtype: float32
Epoch 41, train loss: 0.08213901945716041 test loss: 0.3297212327964024
0    9.219205
dtype: float32
Epoch 42, train loss: 0.08240261675968516 test loss: 0.3862704577231975
0    9.027602
dtype: float32
Epoch 43, train loss: 0.07829152880219008 test loss: 0.3630165642732147
0    8.91274
dtype: float32
Epoch 44, train loss: 0.08045097782478747 test loss: 0.3562657543865786
0    8.99187
dtype: float32
Epoch 45, train loss: 0.07813870761477971 test loss: 0.36670887200724367
0    8.217222
dtype: float32
Epoch 46, train loss: 0.1553383987746306 test loss: 0.3008419035681554
0    8.917306
dtype: float32
Epoch 47, train loss: 0.0847153008385462 test loss: 0.3454630244541866
0    8.879107
dtype: float32
Epoch 48, train loss: 0.07883213253697757 test loss: 0.35206233314114505
0    9.149632
dtype: float32
Epoch 49, train loss: 0.08152564315846349 test loss: 0.38668396391260246
0    8.815886
dtype: float32
Epoch 50, train loss: 0.08097445835821195 test loss: 0.352167747576792
0    9.256182
dtype: float32
Epoch 51, train loss: 0.08346975186342462 test loss: 0.36081568447784934
0    9.014074
dtype: float32
Epoch 52, train loss: 0.0743401504049925 test loss: 0.3668355966342172
0    8.46248
dtype: float32
Epoch 53, train loss: 0.11036005649293552 test loss: 0.31191133971226986
0    7.957017
dtype: float32
Epoch 54, train loss: 0.17298541414834925 test loss: 0.3189005808052271
0    7.955273
dtype: float32
Epoch 55, train loss: 0.2190804072826272 test loss: 0.30024275745570495
0    8.435768
dtype: float32
Epoch 56, train loss: 0.12618157938571456 test loss: 0.3099877008870658
0    8.600815
dtype: float32
Epoch 57, train loss: 0.10220345014543245 test loss: 0.3276127614914973
0    8.725571
dtype: float32
Epoch 58, train loss: 0.07877707749645786 test loss: 0.33836716163425173
0    8.870068
dtype: float32
Epoch 59, train loss: 0.07103723383326649 test loss: 0.3513131454190813
0    8.987951
dtype: float32
Epoch 60, train loss: 0.07091099961162171 test loss: 0.36379700573458607
0    8.679368
dtype: float32
Epoch 61, train loss: 0.07956342298641278 test loss: 0.3266464690299338
0    8.693665
dtype: float32
Epoch 62, train loss: 0.08098798969650743 test loss: 0.3236784347260446
0    8.734321
dtype: float32
Epoch 63, train loss: 0.07287138438728163 test loss: 0.3358484979063474
0    8.744863
dtype: float32
Epoch 64, train loss: 0.07217676986452913 test loss: 0.3425237659557744
0    9.015285
dtype: float32
Epoch 65, train loss: 0.0748897201820381 test loss: 0.37452887672024343
0    8.75129
dtype: float32
Epoch 66, train loss: 0.07165763643812022 test loss: 0.34449306649313294
0    8.654281
dtype: float32
Epoch 67, train loss: 0.07083609750785 test loss: 0.33841683705416076
0    8.680129
dtype: float32
Epoch 68, train loss: 0.06978278252132163 test loss: 0.33351778481777605
0    8.606008
dtype: float32
Epoch 69, train loss: 0.0753372115518501 test loss: 0.2737160822422438
0    8.818238
dtype: float32
Epoch 70, train loss: 0.07191548505752536 test loss: 0.34206833968346206
0    8.971045
dtype: float32
Epoch 71, train loss: 0.07943549606712925 test loss: 0.3562960157325166
0    8.532363
dtype: float32
Epoch 72, train loss: 0.07767321812370978 test loss: 0.31936903799961114
0    8.648694
dtype: float32
Epoch 73, train loss: 0.07307560981210166 test loss: 0.3332071349860128
0    9.018017
dtype: float32
Epoch 74, train loss: 0.08475633228408411 test loss: 0.3679247453111141
0    8.919497
dtype: float32
Epoch 75, train loss: 0.08210814273407578 test loss: 0.33949820322167884
0    8.552724
dtype: float32
Epoch 76, train loss: 0.07234097889047077 test loss: 0.3259090082077939
0    8.779177
dtype: float32
Epoch 77, train loss: 0.067899927372188 test loss: 0.3447416612495954
0    8.482168
dtype: float32
Epoch 78, train loss: 0.08356519324849611 test loss: 0.2675969202604628
0    9.172608
dtype: float32
Epoch 79, train loss: 0.09749420213127512 test loss: 0.3265698130703045
0    8.536139
dtype: float32
Epoch 80, train loss: 0.10203351288025833 test loss: 0.2420220371680952
0    8.769596
dtype: float32
Epoch 81, train loss: 0.06734836608665981 test loss: 0.28701704475329326
0    8.375499
dtype: float32
Epoch 82, train loss: 0.0857389611594296 test loss: 0.24465848653921118
0    8.704288
dtype: float32
Epoch 83, train loss: 0.0662822735316299 test loss: 0.2830546343925314
0    8.61262
dtype: float32
Epoch 84, train loss: 0.0661574364466088 test loss: 0.2647141467452159
0    8.116855
dtype: float32
Epoch 85, train loss: 0.13211703725543855 test loss: 0.19154241289371562
0    8.831389
dtype: float32
Epoch 86, train loss: 0.07217813027293171 test loss: 0.2910789860046462
0    8.774005
dtype: float32
Epoch 87, train loss: 0.06908532187322655 test loss: 0.305587727720272
0    9.000915
dtype: float32
Epoch 88, train loss: 0.08413094066319156 test loss: 0.3134775872564821
0    8.772376
dtype: float32
Epoch 89, train loss: 0.0715054704435848 test loss: 0.28219910145720795
0    8.715695
dtype: float32
Epoch 90, train loss: 0.06708126844753351 test loss: 0.2835542040366816
0    8.763398
dtype: float32
Epoch 91, train loss: 0.07343908566667169 test loss: 0.2918088332248123
0    8.646784
dtype: float32
Epoch 92, train loss: 0.06518130206832617 test loss: 0.26654536705013415
0    8.561217
dtype: float32
Epoch 93, train loss: 0.06536266553127355 test loss: 0.27950751848940075
0    8.563767
dtype: float32
Epoch 94, train loss: 0.06595703157342554 test loss: 0.27584898915713774
0    8.269973
dtype: float32
Epoch 95, train loss: 0.07898755598317975 test loss: 0.23711712691497727
0    8.480604
dtype: float32
Epoch 96, train loss: 0.0644743669906012 test loss: 0.25729733334938043
0    8.584967
dtype: float32
Epoch 97, train loss: 0.06457405973648017 test loss: 0.26363244786239415
0    9.142272
dtype: float32
Epoch 98, train loss: 0.11210538800032074 test loss: 0.36917446728136616
0    8.940087
dtype: float32
Epoch 99, train loss: 0.0926122898442084 test loss: 0.32863361453549994
0    8.660748
dtype: float32
Epoch 100, train loss: 0.07309020432504054 test loss: 0.27026225227357104
0    8.700877
dtype: float32
Epoch 101, train loss: 0.07103915923369894 test loss: 0.2910957121123521
0    8.379402
dtype: float32
Epoch 102, train loss: 0.06431330553430008 test loss: 0.2411716678760214
0    8.219475
dtype: float32
Epoch 103, train loss: 0.0768173115909065 test loss: 0.20729480018994934
0    8.530498
dtype: float32
Epoch 104, train loss: 0.06838559214424875 test loss: 0.2618665447195023
0    8.309721
dtype: float32
Epoch 105, train loss: 0.06501144659745235 test loss: 0.23436281406780082
0    8.195895
dtype: float32
Epoch 106, train loss: 0.07222693589221411 test loss: 0.22659136524236814
0    8.586773
dtype: float32
Epoch 107, train loss: 0.07107761436021487 test loss: 0.27926912587583824
0    8.891221
dtype: float32
Epoch 108, train loss: 0.09012062828376254 test loss: 0.3041266134670139
0    8.591878
dtype: float32
Epoch 109, train loss: 0.06685819573281525 test loss: 0.25627360792209164
0    8.194226
dtype: float32
Epoch 110, train loss: 0.08657239535201379 test loss: 0.1935848432410374
0    8.6734
dtype: float32
Epoch 111, train loss: 0.07121109332564778 test loss: 0.2689948825786042
0    8.417041
dtype: float32
Epoch 112, train loss: 0.061707265193219174 test loss: 0.2247112875738414
0    8.326893
dtype: float32
Epoch 113, train loss: 0.06945052691921028 test loss: 0.20862741828390943
0    8.529237
dtype: float32
Epoch 114, train loss: 0.06270559026209621 test loss: 0.24079767212667189
0    8.620509
dtype: float32
Epoch 115, train loss: 0.0655940315009255 test loss: 0.25905806409225096
0    8.500198
dtype: float32
Epoch 116, train loss: 0.060444533895766976 test loss: 0.2415000082404443
0    8.339108
dtype: float32
Epoch 117, train loss: 0.06276808013858452 test loss: 0.22298432446274355
0    8.367553
dtype: float32
Epoch 118, train loss: 0.06047538591213907 test loss: 0.23146229274403476
0    8.462858
dtype: float32
Epoch 119, train loss: 0.06449192953649464 test loss: 0.23502840748265572
0    8.582912
dtype: float32
Epoch 120, train loss: 0.07316029035566768 test loss: 0.26994963296986224
0    8.485312
dtype: float32
Epoch 121, train loss: 0.06378988305728805 test loss: 0.24447352919774357
0    8.717243
dtype: float32
Epoch 122, train loss: 0.08491864545094248 test loss: 0.29181234216211166
0    8.91464
dtype: float32
Epoch 123, train loss: 0.09968434003873379 test loss: 0.3018189682908756
0    8.713181
dtype: float32
Epoch 124, train loss: 0.08595257129566941 test loss: 0.3017791028407436
0    8.6328
dtype: float32
Epoch 125, train loss: 0.06648319380880698 test loss: 0.26686811534418287
0    8.672864
dtype: float32
Epoch 126, train loss: 0.0743930323731867 test loss: 0.26171316903539876
0    8.484624
dtype: float32
Epoch 127, train loss: 0.06294305517026072 test loss: 0.24270325230215345
0    8.64949
dtype: float32
Epoch 128, train loss: 0.07050620495856953 test loss: 0.25996979395119274
0    8.860104
dtype: float32
Epoch 129, train loss: 0.08150286381056164 test loss: 0.28719273609124274
0    8.719889
dtype: float32
Epoch 130, train loss: 0.06716130421838012 test loss: 0.2627394556832212
0    8.15329
dtype: float32
Epoch 131, train loss: 0.07028670479165847 test loss: 0.21615923846211163
0    8.14899
dtype: float32
Epoch 132, train loss: 0.07866629751670674 test loss: 0.1817645183109234
0    8.209661
dtype: float32
Epoch 133, train loss: 0.06917451770219539 test loss: 0.20656961988414332
0    8.465153
dtype: float32
Epoch 134, train loss: 0.060694342979701534 test loss: 0.2540785528413498
0    8.491143
dtype: float32
Epoch 135, train loss: 0.0638355092448426 test loss: 0.24636451147945723
0    8.600392
dtype: float32
Epoch 136, train loss: 0.06385251301367467 test loss: 0.2596803598438883
0    8.613065
dtype: float32
Epoch 137, train loss: 0.0626693739478913 test loss: 0.25823417383948505
0    8.154849
dtype: float32
Epoch 138, train loss: 0.08116293037253013 test loss: 0.1947953744641535
0    8.607312
dtype: float32
Epoch 139, train loss: 0.06517491027328041 test loss: 0.25998471813619745
0    8.413859
dtype: float32
Epoch 140, train loss: 0.060082091736467495 test loss: 0.22966852434105559
0    8.603078
dtype: float32
Epoch 141, train loss: 0.06484245729579002 test loss: 0.26021114980167787
0    8.429924
dtype: float32
Epoch 142, train loss: 0.05983370592992768 test loss: 0.23001231477010872
0    8.609349
dtype: float32
Epoch 143, train loss: 0.07183179800896115 test loss: 0.2615052844228885
0    8.236842
dtype: float32
Epoch 144, train loss: 0.06464107433282454 test loss: 0.2099730694743112
0    8.122556
dtype: float32
Epoch 145, train loss: 0.07228057836850349 test loss: 0.1944757402103661
0    8.233812
dtype: float32
Epoch 146, train loss: 0.06640808528100149 test loss: 0.21624525352215224
0    8.634111
dtype: float32
Epoch 147, train loss: 0.06315838720522837 test loss: 0.26256954830173423
0    8.259907
dtype: float32
Epoch 148, train loss: 0.06998973851890634 test loss: 0.20928384215364745
0    8.394262
dtype: float32
Epoch 149, train loss: 0.057560987057099264 test loss: 0.23616795100097945
0    8.446962
dtype: float32
Epoch 150, train loss: 0.057418942265612824 test loss: 0.24298694314594238
0    8.170517
dtype: float32
Epoch 151, train loss: 0.07840613927087368 test loss: 0.19532792522352796
0    8.390339
dtype: float32
Epoch 152, train loss: 0.06235912659207778 test loss: 0.25075846610935504
0    7.824185
dtype: float32
Epoch 153, train loss: 0.1288301964500422 test loss: 0.15936630587489334
0    8.558253
dtype: float32
Epoch 154, train loss: 0.06621743869001873 test loss: 0.2546527369531521
0    8.802505
dtype: float32
Epoch 155, train loss: 0.07211265381187094 test loss: 0.2803041313653257
0    8.308113
dtype: float32
Epoch 156, train loss: 0.0665756262224082 test loss: 0.20194648142242927
0    8.585386
dtype: float32
Epoch 157, train loss: 0.06214663345478117 test loss: 0.24827045682679857
0    8.416881
dtype: float32
Epoch 158, train loss: 0.05762810854557771 test loss: 0.22866904273522257
0    8.315725
dtype: float32
Epoch 159, train loss: 0.0611781528023694 test loss: 0.21912117351107277
0    8.21835
dtype: float32
Epoch 160, train loss: 0.06703617372238137 test loss: 0.20222623963634342
0    8.679721
dtype: float32
Epoch 161, train loss: 0.06843126231441254 test loss: 0.26958273622119877
0    8.661345
dtype: float32
Epoch 162, train loss: 0.06834385975464505 test loss: 0.2648018569161793
0    8.721704
dtype: float32
Epoch 163, train loss: 0.07107260694668054 test loss: 0.2709968762953969
0    8.647127
dtype: float32
Epoch 164, train loss: 0.06754463138702213 test loss: 0.26386711521557116
0    8.329004
dtype: float32
Epoch 165, train loss: 0.05694909810605854 test loss: 0.22490756495220604
0    8.568645
dtype: float32
Epoch 166, train loss: 0.06000016798029357 test loss: 0.2568272700439886
0    8.46865
dtype: float32
Epoch 167, train loss: 0.05502843776419381 test loss: 0.23448901164042596
0    8.82739
dtype: float32
Epoch 168, train loss: 0.07930228759079938 test loss: 0.2722034019431996
0    8.496097
dtype: float32
Epoch 169, train loss: 0.05914425752627674 test loss: 0.24930063100610092
0    8.600029
dtype: float32
Epoch 170, train loss: 0.06135828323377664 test loss: 0.25749882989694567
0    8.724733
dtype: float32
Epoch 171, train loss: 0.07603165336675348 test loss: 0.2854321432979652
0    8.397087
dtype: float32
Epoch 172, train loss: 0.05688761671016129 test loss: 0.23379203171549723
0    8.514173
dtype: float32
Epoch 173, train loss: 0.061064718375392915 test loss: 0.2541019417626321
0    8.549045
dtype: float32
Epoch 174, train loss: 0.06570570770388072 test loss: 0.2597351998376054
0    8.149663
dtype: float32
Epoch 175, train loss: 0.07015348154207851 test loss: 0.1893220212937276
0    8.422742
dtype: float32
Epoch 176, train loss: 0.05817394919971105 test loss: 0.24760738665351426
0    8.476148
dtype: float32
Epoch 177, train loss: 0.05726887129287515 test loss: 0.25214522659588245
0    8.75458
dtype: float32
Epoch 178, train loss: 0.08051061618109658 test loss: 0.27053873304719295
0    8.735119
dtype: float32
Epoch 179, train loss: 0.07958195628473361 test loss: 0.2777142560283641
0    8.427356
dtype: float32
Epoch 180, train loss: 0.05438705460717498 test loss: 0.23415001494128942
0    8.520921
dtype: float32
Epoch 181, train loss: 0.05809772613648296 test loss: 0.24211355223530898
0    8.356524
dtype: float32
Epoch 182, train loss: 0.057146750000239915 test loss: 0.22626037946554467
0    8.534248
dtype: float32
Epoch 183, train loss: 0.0635792729844168 test loss: 0.25945556395721064
0    8.082145
dtype: float32
Epoch 184, train loss: 0.07541300095928877 test loss: 0.18545406482497184
0    8.189562
dtype: float32
Epoch 185, train loss: 0.06850768328460109 test loss: 0.1865121686132475
0    8.672138
dtype: float32
Epoch 186, train loss: 0.06955337984366375 test loss: 0.268216565329462
0    8.492328
dtype: float32
Epoch 187, train loss: 0.06469780627179142 test loss: 0.23502035601751325
0    8.922582
dtype: float32
Epoch 188, train loss: 0.10075746004111441 test loss: 0.3110171986974574
0    8.635144
dtype: float32
Epoch 189, train loss: 0.06957721961464393 test loss: 0.2772378208797852
0    8.440025
dtype: float32
Epoch 190, train loss: 0.05392513802620574 test loss: 0.24412288175655894
0    8.283232
dtype: float32
Epoch 191, train loss: 0.0562237444051079 test loss: 0.218210469935899
0    7.979111
dtype: float32
Epoch 192, train loss: 0.08164044363116502 test loss: 0.18994883833847984
0    8.177982
dtype: float32
Epoch 193, train loss: 0.06649513319432493 test loss: 0.18708537251363475
0    8.142213
dtype: float32
Epoch 194, train loss: 0.0671007387606363 test loss: 0.2023481145681453
0    8.419931
dtype: float32
Epoch 195, train loss: 0.06101881205918285 test loss: 0.25362041492656223
0    8.711681
dtype: float32
Epoch 196, train loss: 0.07423260419462534 test loss: 0.28368256405930975
0    8.279022
dtype: float32
Epoch 197, train loss: 0.05661905643050583 test loss: 0.21671051142904654
0    8.473989
dtype: float32
Epoch 198, train loss: 0.05440338446242841 test loss: 0.2414056199990981
0    8.81327
dtype: float32
Epoch 199, train loss: 0.08848020311862892 test loss: 0.3010932477552451
0    8.469918
dtype: float32
Epoch 200, train loss: 0.06011091963647442 test loss: 0.24671819842271722
0    8.220608
dtype: float32
Epoch 201, train loss: 0.06197987516263418 test loss: 0.2062557602949537
0    8.400911
dtype: float32
Epoch 202, train loss: 0.05402921419644656 test loss: 0.2351449306356434
0    8.434546
dtype: float32
Epoch 203, train loss: 0.05424526929803704 test loss: 0.2355046084775034
0    8.468947
dtype: float32
Epoch 204, train loss: 0.05262282621861165 test loss: 0.24285687362642477
0    8.367328
dtype: float32
Epoch 205, train loss: 0.053742847363595976 test loss: 0.234073892551615
0    8.472688
dtype: float32
Epoch 206, train loss: 0.05341443149494433 test loss: 0.2315309383511286
0    8.521303
dtype: float32
Epoch 207, train loss: 0.05521909437770113 test loss: 0.24523580428341601
0    8.387132
dtype: float32
Epoch 208, train loss: 0.05541048772279739 test loss: 0.2221299817961768
0    8.280712
dtype: float32
Epoch 209, train loss: 0.06355136433090618 test loss: 0.20250788548752402
0    8.634295
dtype: float32
Epoch 210, train loss: 0.06461342281736683 test loss: 0.2713105459503528
0    8.766895
dtype: float32
Epoch 211, train loss: 0.07561913638884775 test loss: 0.27486592907744384
0    8.737946
dtype: float32
Epoch 212, train loss: 0.0726020070793986 test loss: 0.27479899420548676
0    8.37414
dtype: float32
Epoch 213, train loss: 0.05364738829861824 test loss: 0.22751552407474113
0    9.367716
dtype: float32
Epoch 214, train loss: 0.1190124770451863 test loss: 0.30888643356638373
0    8.096808
dtype: float32
Epoch 215, train loss: 0.07122016333091676 test loss: 0.19230967381649555
0    8.304705
dtype: float32
Epoch 216, train loss: 0.05368934891062792 test loss: 0.21754580735963008
0    8.539121
dtype: float32
Epoch 217, train loss: 0.06420714486605435 test loss: 0.2530918865592508
0    8.137597
dtype: float32
Epoch 218, train loss: 0.06562736717295314 test loss: 0.1905883951399339
0    8.263176
dtype: float32
Epoch 219, train loss: 0.05443373291823117 test loss: 0.21554331799995324
0    7.870131
dtype: float32
Epoch 220, train loss: 0.09856584829171054 test loss: 0.15901991080633956
0    8.34673
dtype: float32
Epoch 221, train loss: 0.052633931239164655 test loss: 0.22794790510408733
0    8.29062
dtype: float32
Epoch 222, train loss: 0.05549818633594844 test loss: 0.21549062491830817
0    8.263374
dtype: float32
Epoch 223, train loss: 0.056208328516355696 test loss: 0.21708380792395526
0    8.465127
dtype: float32
Epoch 224, train loss: 0.05402489995938564 test loss: 0.24677514605254358
0    8.708029
dtype: float32
Epoch 225, train loss: 0.07448705220332269 test loss: 0.2751209175717164
0    8.546315
dtype: float32
Epoch 226, train loss: 0.0649800881686696 test loss: 0.2647671952968024
0    8.101123
dtype: float32
Epoch 227, train loss: 0.06363211040744851 test loss: 0.19550511549704971
0    8.046792
dtype: float32
Epoch 228, train loss: 0.07667745202638297 test loss: 0.17712357401414633
0    8.488803
dtype: float32
Epoch 229, train loss: 0.05839263666958677 test loss: 0.242253707359273
0    8.570461
dtype: float32
Epoch 230, train loss: 0.06448412428079334 test loss: 0.2509197682545815
0    8.463671
dtype: float32
Epoch 231, train loss: 0.0630700491530069 test loss: 0.25475566421137646
0    8.572759
dtype: float32
Epoch 232, train loss: 0.06862478489184264 test loss: 0.2637681906353551
0    8.253614
dtype: float32
Epoch 233, train loss: 0.0522214667300727 test loss: 0.2230447551588937
0    8.466089
dtype: float32
Epoch 234, train loss: 0.060707043642277525 test loss: 0.23757822962141165
0    8.523386
dtype: float32
Epoch 235, train loss: 0.05853471157477915 test loss: 0.24657297790669122
0    8.605892
dtype: float32
Epoch 236, train loss: 0.06697943183917418 test loss: 0.26832268874092907
0    8.514557
dtype: float32
Epoch 237, train loss: 0.05803866150026289 test loss: 0.23919435374534634
0    8.4837
dtype: float32
Epoch 238, train loss: 0.054863827614337425 test loss: 0.23712494842924145
0    8.262592
dtype: float32
Epoch 239, train loss: 0.05472701229966931 test loss: 0.20514755565172077
0    8.341605
dtype: float32
Epoch 240, train loss: 0.05117871647577998 test loss: 0.22259242163522458
0    8.237913
dtype: float32
Epoch 241, train loss: 0.0569260786068915 test loss: 0.20482822728632052
0    8.338581
dtype: float32
Epoch 242, train loss: 0.0524462257899171 test loss: 0.22226315896502194
0    8.303884
dtype: float32
Epoch 243, train loss: 0.05246098313821275 test loss: 0.21290996911225474
0    8.374899
dtype: float32
Epoch 244, train loss: 0.05131838199306083 test loss: 0.2233880216749777
0    7.713651
dtype: float32
Epoch 245, train loss: 0.12310855756709406 test loss: 0.1488057058126599
0    8.477951
dtype: float32
Epoch 246, train loss: 0.053460254374329726 test loss: 0.23590330592120112
0    8.645546
dtype: float32
Epoch 247, train loss: 0.06545348592397623 test loss: 0.2567687497326447
0    8.156826
dtype: float32
Epoch 248, train loss: 0.0660252557249987 test loss: 0.1834716459180019
0    8.352843
dtype: float32
Epoch 249, train loss: 0.05355626079165754 test loss: 0.23541744298974246
0    8.243107
dtype: float32
Epoch 250, train loss: 0.05260511771504108 test loss: 0.21343516026699172
0    8.182549
dtype: float32
Epoch 251, train loss: 0.055390467733777676 test loss: 0.20428833591903656
0    8.281761
dtype: float32
Epoch 252, train loss: 0.05277312344228739 test loss: 0.21904751615635148
0    8.203184
dtype: float32
Epoch 253, train loss: 0.056385591836567016 test loss: 0.19595823814960436
0    8.446607
dtype: float32
Epoch 254, train loss: 0.05533826735421644 test loss: 0.24006967771204255
0    8.055829
dtype: float32
Epoch 255, train loss: 0.0722929228751571 test loss: 0.1775018162277426
0    8.497589
dtype: float32
Epoch 256, train loss: 0.05745578724635269 test loss: 0.2476707265525221
0    8.459842
dtype: float32
Epoch 257, train loss: 0.05623053163622663 test loss: 0.24786669387627872
0    8.477435
dtype: float32
Epoch 258, train loss: 0.05448395271593062 test loss: 0.22618103591346322
0    8.237757
dtype: float32
Epoch 259, train loss: 0.053698588872784406 test loss: 0.20498873414018653
0    8.351598
dtype: float32
Epoch 260, train loss: 0.0519965898384025 test loss: 0.2182864562415698
0    8.031968
dtype: float32
Epoch 261, train loss: 0.07064974478843439 test loss: 0.17820234935229667
0    8.096656
dtype: float32
Epoch 262, train loss: 0.056801952868845804 test loss: 0.19410016422867307
0    8.206239
dtype: float32
Epoch 263, train loss: 0.05297293142069645 test loss: 0.19876338854296965
0    8.139605
dtype: float32
Epoch 264, train loss: 0.05376932429459928 test loss: 0.20137698828183517
0    7.983428
dtype: float32
Epoch 265, train loss: 0.07482745081241093 test loss: 0.1655306792815226
0    8.285364
dtype: float32
Epoch 266, train loss: 0.04991425075426842 test loss: 0.2165534079952104
0    8.520967
dtype: float32
Epoch 267, train loss: 0.0634496593220806 test loss: 0.24606947751278477
0    8.33611
dtype: float32
Epoch 268, train loss: 0.05444845572327212 test loss: 0.21980237864139926
0    8.432222
dtype: float32
Epoch 269, train loss: 0.060216357121943676 test loss: 0.2293754733655305
0    8.339614
dtype: float32
Epoch 270, train loss: 0.05510469929719168 test loss: 0.23549156448545902
0    8.033907
dtype: float32
Epoch 271, train loss: 0.06305527223819732 test loss: 0.1812775260391827
0    8.162687
dtype: float32
Epoch 272, train loss: 0.05119996975928044 test loss: 0.19832425543958848
0    8.362433
dtype: float32
Epoch 273, train loss: 0.05477692885588527 test loss: 0.21626045640455072
0    8.435253
dtype: float32
Epoch 274, train loss: 0.05720189863113948 test loss: 0.23472318786044413
0    8.347274
dtype: float32
Epoch 275, train loss: 0.05740837214299808 test loss: 0.2363463790899066
0    7.89326
dtype: float32
Epoch 276, train loss: 0.07425005984130698 test loss: 0.1654124163761319
0    8.292706
dtype: float32
Epoch 277, train loss: 0.056318568660921685 test loss: 0.22505869183577215
0    8.176834
dtype: float32
Epoch 278, train loss: 0.04956581457625982 test loss: 0.2141393768925205
0    8.12581
dtype: float32
Epoch 279, train loss: 0.06157548657884162 test loss: 0.1816906690067866
0    8.151474
dtype: float32
Epoch 280, train loss: 0.054228958356146766 test loss: 0.18959682601179784
0    8.340816
dtype: float32
Epoch 281, train loss: 0.05221046625284252 test loss: 0.22388243616791575
0    8.520011
dtype: float32
Epoch 282, train loss: 0.06127235467661889 test loss: 0.2545644579316975
0    8.183842
dtype: float32
Epoch 283, train loss: 0.05164098044995339 test loss: 0.1992513938904931
0    8.367362
dtype: float32
Epoch 284, train loss: 0.052195764290619534 test loss: 0.23034949096806132
0    8.224399
dtype: float32
Epoch 285, train loss: 0.050323757596919504 test loss: 0.20746617323890254
0    8.245506
dtype: float32
Epoch 286, train loss: 0.05065235041109181 test loss: 0.20263094722678013
0    8.362987
dtype: float32
Epoch 287, train loss: 0.052485082366499715 test loss: 0.21599740023842395
0    8.4172
dtype: float32
Epoch 288, train loss: 0.05284085000202596 test loss: 0.23351771925813153
0    8.143209
dtype: float32
Epoch 289, train loss: 0.054749744529283946 test loss: 0.18634999616264497
0    8.258987
dtype: float32
Epoch 290, train loss: 0.048854844662934646 test loss: 0.21127470847929822
0    8.281994
dtype: float32
Epoch 291, train loss: 0.04764235642058418 test loss: 0.2046052380450613
0    8.271312
dtype: float32
Epoch 292, train loss: 0.05187303281741825 test loss: 0.19961947204279928
0    8.241589
dtype: float32
Epoch 293, train loss: 0.04887568516648314 test loss: 0.2096331207691716
0    8.068717
dtype: float32
Epoch 294, train loss: 0.05889385533412121 test loss: 0.17504136736685988
0    7.734767
dtype: float32
Epoch 295, train loss: 0.09382595532342455 test loss: 0.1454043932744874
0    8.156604
dtype: float32
Epoch 296, train loss: 0.05176963633215564 test loss: 0.19025363377325433
0    8.048816
dtype: float32
Epoch 297, train loss: 0.05564304000621719 test loss: 0.19144978258691317
0    8.340792
dtype: float32
Epoch 298, train loss: 0.049725579737718045 test loss: 0.22450828808997494
0    8.326227
dtype: float32
Epoch 299, train loss: 0.04812867168205602 test loss: 0.2256461608280384
Final train loss is: 0.04812867168205602, Test loss is: 0.2256461608280384
0    8.326227
dtype: float32
Close
round is 0
0    8.466339
dtype: float32
Epoch 11, train loss: 0.28195645132563146 test loss: 0.4801790368654218
0    8.528004
dtype: float32
Epoch 12, train loss: 0.2623009043789724 test loss: 0.414239785237515
0    8.396073
dtype: float32
Epoch 13, train loss: 0.23633758671998348 test loss: 0.5198368624334608
0    8.192448
dtype: float32
Epoch 14, train loss: 0.24320431063548764 test loss: 0.29939756304425047
0    8.292878
dtype: float32
Epoch 15, train loss: 0.19349005185840412 test loss: 0.38446207427297213
0    8.651513
dtype: float32
Epoch 16, train loss: 0.22244539571016322 test loss: 0.475363079590006
0    8.340332
dtype: float32
Epoch 17, train loss: 0.20905801251615908 test loss: 0.37528775869532083
0    8.739693
dtype: float32
Epoch 18, train loss: 0.2306819749523627 test loss: 0.4370780344007027
0    7.923033
dtype: float32
Epoch 19, train loss: 0.1692843478389622 test loss: 0.3785964237273424
0    8.096628
dtype: float32
Epoch 20, train loss: 0.1861503412061166 test loss: 0.44431990780441055
0    7.768836
dtype: float32
Epoch 21, train loss: 0.14200240929456412 test loss: 0.3292010034200305
0    8.012432
dtype: float32
Epoch 22, train loss: 0.15895174116539892 test loss: 0.32969555063521166
0    8.094627
dtype: float32
Epoch 23, train loss: 0.16481334989253335 test loss: 0.302914993471883
0    7.421111
dtype: float32
Epoch 24, train loss: 0.12248802401045139 test loss: 0.22147807933216757
0    7.913455
dtype: float32
Epoch 25, train loss: 0.14424573498918666 test loss: 0.3567184200663933
0    7.952846
dtype: float32
Epoch 26, train loss: 0.15840198493810995 test loss: 0.3349326598994968
0    7.740214
dtype: float32
Epoch 27, train loss: 0.13815000387234966 test loss: 0.2835749494513529
0    7.83652
dtype: float32
Epoch 28, train loss: 0.13724247027662825 test loss: 0.3329029198901178
0    7.51302
dtype: float32
Epoch 29, train loss: 0.10062944176090223 test loss: 0.22595194608024205
0    7.037533
dtype: float32
Epoch 30, train loss: 0.13619132048831573 test loss: 0.22103210009686808
0    7.059928
dtype: float32
Epoch 31, train loss: 0.1346818350670733 test loss: 0.2041832173840631
0    7.647754
dtype: float32
Epoch 32, train loss: 0.10295557465937306 test loss: 0.21789599767689205
0    7.369944
dtype: float32
Epoch 33, train loss: 0.11295337339922831 test loss: 0.20820311776763217
0    7.609696
dtype: float32
Epoch 34, train loss: 0.09276337714345552 test loss: 0.22022632538228284
0    7.827163
dtype: float32
Epoch 35, train loss: 0.12203156251736867 test loss: 0.2340665587962662
0    7.61771
dtype: float32
Epoch 36, train loss: 0.10035349518422663 test loss: 0.20403342414893974
0    7.497642
dtype: float32
Epoch 37, train loss: 0.0877474040672627 test loss: 0.2104401016636241
0    7.61522
dtype: float32
Epoch 38, train loss: 0.09241803258637443 test loss: 0.2138803065025189
0    7.452158
dtype: float32
Epoch 39, train loss: 0.08740806123449628 test loss: 0.21210405528489476
0    7.550417
dtype: float32
Epoch 40, train loss: 0.09498579761827153 test loss: 0.21743972847861714
0    7.484189
dtype: float32
Epoch 41, train loss: 0.08497757007514328 test loss: 0.19264935621538354
0    7.422928
dtype: float32
Epoch 42, train loss: 0.08176915645212064 test loss: 0.18787284054807357
0    7.501538
dtype: float32
Epoch 43, train loss: 0.08681162838579419 test loss: 0.19842536342166114
0    7.455245
dtype: float32
Epoch 44, train loss: 0.08350166919769875 test loss: 0.19348551860374352
0    7.481118
dtype: float32
Epoch 45, train loss: 0.08835720850800254 test loss: 0.18950638997689007
0    7.260894
dtype: float32
Epoch 46, train loss: 0.07789525029839364 test loss: 0.19276995625472743
0    7.365233
dtype: float32
Epoch 47, train loss: 0.07748409195405534 test loss: 0.1828969001280979
0    7.396704
dtype: float32
Epoch 48, train loss: 0.07720467019426565 test loss: 0.18668715985341963
0    7.366676
dtype: float32
Epoch 49, train loss: 0.07539691716742791 test loss: 0.1831956535034161
0    7.476323
dtype: float32
Epoch 50, train loss: 0.07862645687591761 test loss: 0.18647442129231342
0    7.266015
dtype: float32
Epoch 51, train loss: 0.07526114574665801 test loss: 0.17854218523171636
0    7.557645
dtype: float32
Epoch 52, train loss: 0.09593053365076998 test loss: 0.20556344565353052
0    7.524536
dtype: float32
Epoch 53, train loss: 0.0914002499346428 test loss: 0.20793515485333905
0    7.505508
dtype: float32
Epoch 54, train loss: 0.0859684208632992 test loss: 0.19888783973158652
0    7.421682
dtype: float32
Epoch 55, train loss: 0.07814513900585333 test loss: 0.18945282032073305
0    7.061752
dtype: float32
Epoch 56, train loss: 0.08410812095352392 test loss: 0.2065281624284984
0    7.331207
dtype: float32
Epoch 57, train loss: 0.07695236348359599 test loss: 0.18658714268222826
0    6.995318
dtype: float32
Epoch 58, train loss: 0.08242389146484336 test loss: 0.18635988778154886
0    6.715005
dtype: float32
Epoch 59, train loss: 0.16158370551355022 test loss: 0.24040902301876776
0    6.850367
dtype: float32
Epoch 60, train loss: 0.103224477289836 test loss: 0.20712292184360592
0    7.0235
dtype: float32
Epoch 61, train loss: 0.0743560999493764 test loss: 0.1892090921450245
0    7.038823
dtype: float32
Epoch 62, train loss: 0.07813339589831209 test loss: 0.18376791490087802
0    6.804153
dtype: float32
Epoch 63, train loss: 0.11972161753882425 test loss: 0.21338674518714013
0    6.890502
dtype: float32
Epoch 64, train loss: 0.0950465146839858 test loss: 0.2009042026308557
0    6.895915
dtype: float32
Epoch 65, train loss: 0.0994054764373047 test loss: 0.1937146554518176
0    7.238096
dtype: float32
Epoch 66, train loss: 0.06869914578753017 test loss: 0.18197254365645685
0    7.309654
dtype: float32
Epoch 67, train loss: 0.07170563915550937 test loss: 0.1825860711774844
0    7.350638
dtype: float32
Epoch 68, train loss: 0.07457405067710687 test loss: 0.1799500666062387
0    7.376857
dtype: float32
Epoch 69, train loss: 0.07803588201315416 test loss: 0.18214597152438675
0    7.155746
dtype: float32
Epoch 70, train loss: 0.06512124838015118 test loss: 0.17773779208868162
0    7.117095
dtype: float32
Epoch 71, train loss: 0.06710911617693095 test loss: 0.1865840288916866
0    7.169284
dtype: float32
Epoch 72, train loss: 0.06724867166316764 test loss: 0.19074300383532683
0    7.052848
dtype: float32
Epoch 73, train loss: 0.0736084676926853 test loss: 0.18984850372913073
0    7.17782
dtype: float32
Epoch 74, train loss: 0.06377951540083843 test loss: 0.1835088484422503
0    7.047053
dtype: float32
Epoch 75, train loss: 0.07096013297811361 test loss: 0.19417978877610872
0    7.24636
dtype: float32
Epoch 76, train loss: 0.06410649249617614 test loss: 0.17640870658320298
0    7.462291
dtype: float32
Epoch 77, train loss: 0.08897621786877413 test loss: 0.17760747965431914
0    7.363682
dtype: float32
Epoch 78, train loss: 0.07738882857247104 test loss: 0.18736252680710866
0    7.375084
dtype: float32
Epoch 79, train loss: 0.07931476734352633 test loss: 0.18641112860191958
0    7.328378
dtype: float32
Epoch 80, train loss: 0.06886277782068788 test loss: 0.17795094786123988
0    7.301653
dtype: float32
Epoch 81, train loss: 0.0674425339122278 test loss: 0.1746009579391267
0    7.081278
dtype: float32
Epoch 82, train loss: 0.06383967891631995 test loss: 0.18114707225847204
0    7.000247
dtype: float32
Epoch 83, train loss: 0.07984950051289276 test loss: 0.19140274913302846
0    7.081016
dtype: float32
Epoch 84, train loss: 0.06343836573355453 test loss: 0.18006211257647864
0    7.073476
dtype: float32
Epoch 85, train loss: 0.06614157068413948 test loss: 0.19541375356500712
0    6.949125
dtype: float32
Epoch 86, train loss: 0.07696907597663181 test loss: 0.21810787864916037
0    6.978096
dtype: float32
Epoch 87, train loss: 0.07169024861374206 test loss: 0.21388521125385815
0    7.080374
dtype: float32
Epoch 88, train loss: 0.06111570548370564 test loss: 0.17966186899308634
0    7.224953
dtype: float32
Epoch 89, train loss: 0.06383891969765702 test loss: 0.17349054096160973
0    7.377716
dtype: float32
Epoch 90, train loss: 0.08108285863093624 test loss: 0.17448525409412577
0    7.080326
dtype: float32
Epoch 91, train loss: 0.06272356054001059 test loss: 0.1886528777906481
0    7.53414
dtype: float32
Epoch 92, train loss: 0.09634915624174117 test loss: 0.19645212596748562
0    7.29702
dtype: float32
Epoch 93, train loss: 0.07007570604221895 test loss: 0.17736316612653402
0    7.288336
dtype: float32
Epoch 94, train loss: 0.07072810435869223 test loss: 0.17738115679896968
0    7.40782
dtype: float32
Epoch 95, train loss: 0.07553764013168117 test loss: 0.17645795167198114
0    7.410169
dtype: float32
Epoch 96, train loss: 0.08159327789983922 test loss: 0.17593945617244458
0    7.257716
dtype: float32
Epoch 97, train loss: 0.060888356561512105 test loss: 0.17503203335473105
0    7.111074
dtype: float32
Epoch 98, train loss: 0.06130637724168438 test loss: 0.1987457107742785
0    7.074986
dtype: float32
Epoch 99, train loss: 0.06263856335024355 test loss: 0.18090407771006053
0    7.29006
dtype: float32
Epoch 100, train loss: 0.062387113516874114 test loss: 0.17147500982484223
0    6.843354
dtype: float32
Epoch 101, train loss: 0.10374593258699837 test loss: 0.254072142241654
0    6.714695
dtype: float32
Epoch 102, train loss: 0.09873734699998188 test loss: 0.23323717693484983
0    6.652569
dtype: float32
Epoch 103, train loss: 0.1247896231082407 test loss: 0.25129468865529375
0    6.988855
dtype: float32
Epoch 104, train loss: 0.07029748499761798 test loss: 0.19707828310805695
0    6.8612
dtype: float32
Epoch 105, train loss: 0.09585423979853537 test loss: 0.29441977221503024
0    6.915606
dtype: float32
Epoch 106, train loss: 0.08762758031844152 test loss: 0.19566081579857414
0    7.055232
dtype: float32
Epoch 107, train loss: 0.07231567299359357 test loss: 0.1758244475887409
0    6.90677
dtype: float32
Epoch 108, train loss: 0.09598929032915965 test loss: 0.2709189718452307
0    7.096814
dtype: float32
Epoch 109, train loss: 0.06222890989037885 test loss: 0.2037596513866037
0    6.933609
dtype: float32
Epoch 110, train loss: 0.08528122804777583 test loss: 0.2476601575162847
0    6.973501
dtype: float32
Epoch 111, train loss: 0.0730475758788146 test loss: 0.23138504751633593
0    6.930153
dtype: float32
Epoch 112, train loss: 0.07664566440163186 test loss: 0.18882970627481757
0    7.126989
dtype: float32
Epoch 113, train loss: 0.056811592185355655 test loss: 0.17408611478769417
0    7.128417
dtype: float32
Epoch 114, train loss: 0.05729739268525417 test loss: 0.18093893701963853
0    7.090257
dtype: float32
Epoch 115, train loss: 0.060090244296093595 test loss: 0.19676055896401068
0    7.245356
dtype: float32
Epoch 116, train loss: 0.06025471688805358 test loss: 0.168807662719433
0    7.109776
dtype: float32
Epoch 117, train loss: 0.05826722835618597 test loss: 0.18617953407582533
0    7.273688
dtype: float32
Epoch 118, train loss: 0.06155434503743585 test loss: 0.16730246655770084
0    7.199577
dtype: float32
Epoch 119, train loss: 0.056230924952496375 test loss: 0.16909464986439057
0    7.193562
dtype: float32
Epoch 120, train loss: 0.05823721040886909 test loss: 0.16974398606891358
0    7.213426
dtype: float32
Epoch 121, train loss: 0.0608886553880607 test loss: 0.18186426907593958
0    7.087241
dtype: float32
Epoch 122, train loss: 0.059952761077728664 test loss: 0.20361371881066515
0    7.084425
dtype: float32
Epoch 123, train loss: 0.06076560544654354 test loss: 0.205468403111887
0    7.228268
dtype: float32
Epoch 124, train loss: 0.0570229753295954 test loss: 0.1819987869354647
0    7.312581
dtype: float32
Epoch 125, train loss: 0.06303182005332707 test loss: 0.17430981940369253
0    7.15088
dtype: float32
Epoch 126, train loss: 0.05502193271426526 test loss: 0.18290995592656298
0    7.14114
dtype: float32
Epoch 127, train loss: 0.05583191253780182 test loss: 0.18083502590495443
0    7.222911
dtype: float32
Epoch 128, train loss: 0.058365690547685624 test loss: 0.17484353320032653
0    7.252593
dtype: float32
Epoch 129, train loss: 0.06031346822002578 test loss: 0.17594188110226006
0    7.068206
dtype: float32
Epoch 130, train loss: 0.059253204730894106 test loss: 0.20684159654427287
0    7.101341
dtype: float32
Epoch 131, train loss: 0.06021083199040326 test loss: 0.19604738774861258
0    7.05466
dtype: float32
Epoch 132, train loss: 0.06603993336869218 test loss: 0.22059506034724985
0    7.198176
dtype: float32
Epoch 133, train loss: 0.05504617593845308 test loss: 0.17910517910214144
0    7.019818
dtype: float32
Epoch 134, train loss: 0.06426651754870849 test loss: 0.21055159040619748
0    7.142425
dtype: float32
Epoch 135, train loss: 0.05453096228903191 test loss: 0.18542403363091023
0    7.399579
dtype: float32
Epoch 136, train loss: 0.07745009983864198 test loss: 0.1706127119815176
0    7.31386
dtype: float32
Epoch 137, train loss: 0.06225603574052676 test loss: 0.1702907502319105
0    7.376823
dtype: float32
Epoch 138, train loss: 0.06895374925010925 test loss: 0.17496464451038504
0    7.303935
dtype: float32
Epoch 139, train loss: 0.06571126731641458 test loss: 0.17189084942762306
0    7.264472
dtype: float32
Epoch 140, train loss: 0.06060970136135055 test loss: 0.1701643803929916
0    7.140427
dtype: float32
Epoch 141, train loss: 0.05612529181575694 test loss: 0.17980705840397054
0    7.063108
dtype: float32
Epoch 142, train loss: 0.05633402399136516 test loss: 0.17754185289897217
0    6.941048
dtype: float32
Epoch 143, train loss: 0.08470287234599268 test loss: 0.1993353503449232
0    7.207159
dtype: float32
Epoch 144, train loss: 0.05707104043617602 test loss: 0.16877421601306716
0    7.105051
dtype: float32
Epoch 145, train loss: 0.05509988284549033 test loss: 0.1822728740594734
0    7.180627
dtype: float32
Epoch 146, train loss: 0.0535645661583707 test loss: 0.1768151361413328
0    6.802348
dtype: float32
Epoch 147, train loss: 0.10867980066722942 test loss: 0.34678332228330505
0    6.773911
dtype: float32
Epoch 148, train loss: 0.11363697727165453 test loss: 0.32969378462767795
0    6.849548
dtype: float32
Epoch 149, train loss: 0.09181846373334639 test loss: 0.2472701557797672
0    7.122679
dtype: float32
Epoch 150, train loss: 0.05461171283863476 test loss: 0.19749871219873386
0    7.083346
dtype: float32
Epoch 151, train loss: 0.05953656508675318 test loss: 0.19603909870577169
0    7.267849
dtype: float32
Epoch 152, train loss: 0.05907318991555411 test loss: 0.1723642786309111
0    7.398993
dtype: float32
Epoch 153, train loss: 0.07141553775107733 test loss: 0.17878182041970467
0    7.155167
dtype: float32
Epoch 154, train loss: 0.055423377548656755 test loss: 0.20828839402962637
0    7.115211
dtype: float32
Epoch 155, train loss: 0.053999678294764666 test loss: 0.18461165064827142
0    7.282261
dtype: float32
Epoch 156, train loss: 0.057841576092156795 test loss: 0.1768595995591467
0    7.014416
dtype: float32
Epoch 157, train loss: 0.07000104173802944 test loss: 0.1992587432242899
0    7.118678
dtype: float32
Epoch 158, train loss: 0.05440993751828341 test loss: 0.19089458844632176
0    6.964852
dtype: float32
Epoch 159, train loss: 0.07188120101611348 test loss: 0.23620150751213972
0    6.964166
dtype: float32
Epoch 160, train loss: 0.06977433720928349 test loss: 0.2288835166467897
0    6.88167
dtype: float32
Epoch 161, train loss: 0.08186847723622535 test loss: 0.24535920187405177
0    6.968379
dtype: float32
Epoch 162, train loss: 0.0915470906977611 test loss: 0.22836147777272608
0    7.04803
dtype: float32
Epoch 163, train loss: 0.06589641850843977 test loss: 0.19971220240256796
0    7.2451
dtype: float32
Epoch 164, train loss: 0.058989389072813106 test loss: 0.1776449425264107
0    7.368148
dtype: float32
Epoch 165, train loss: 0.06853154807655698 test loss: 0.17151231966816366
0    7.135648
dtype: float32
Epoch 166, train loss: 0.054312523259228446 test loss: 0.1947347604930639
0    7.117816
dtype: float32
Epoch 167, train loss: 0.05607654474888845 test loss: 0.20413380668124784
0    7.092087
dtype: float32
Epoch 168, train loss: 0.05976723484092812 test loss: 0.2122938662138004
0    6.953393
dtype: float32
Epoch 169, train loss: 0.07932560395103522 test loss: 0.27759857799918575
0    6.970231
dtype: float32
Epoch 170, train loss: 0.07339092798455707 test loss: 0.22818115027395422
0    7.175201
dtype: float32
Epoch 171, train loss: 0.05526358836109135 test loss: 0.18310641447124193
0    7.258638
dtype: float32
Epoch 172, train loss: 0.05526389489602661 test loss: 0.17339391183256567
0    7.252627
dtype: float32
Epoch 173, train loss: 0.05897540625605497 test loss: 0.164622097715296
0    7.283879
dtype: float32
Epoch 174, train loss: 0.058614797994524286 test loss: 0.1687532554743738
0    7.279162
dtype: float32
Epoch 175, train loss: 0.05657375147247638 test loss: 0.17028942384681808
0    7.16624
dtype: float32
Epoch 176, train loss: 0.05368010151395625 test loss: 0.1799298430798905
0    7.176264
dtype: float32
Epoch 177, train loss: 0.05328984387463142 test loss: 0.19959274790094061
0    7.152807
dtype: float32
Epoch 178, train loss: 0.05200245684734874 test loss: 0.18892938641015167
0    7.277273
dtype: float32
Epoch 179, train loss: 0.05473750703447352 test loss: 0.18236795688563417
0    7.257657
dtype: float32
Epoch 180, train loss: 0.0548146569356973 test loss: 0.16833523348845225
0    7.218387
dtype: float32
Epoch 181, train loss: 0.05231649643728263 test loss: 0.18013631605830174
0    7.203141
dtype: float32
Epoch 182, train loss: 0.05316980851998063 test loss: 0.18684578920921963
0    6.829023
dtype: float32
Epoch 183, train loss: 0.11351662222522013 test loss: 0.3006663167394023
0    7.270631
dtype: float32
Epoch 184, train loss: 0.0540032364682206 test loss: 0.2009138211407832
0    7.392047
dtype: float32
Epoch 185, train loss: 0.07239842374713035 test loss: 0.1739809092337245
0    7.302618
dtype: float32
Epoch 186, train loss: 0.05876972209197961 test loss: 0.17642461103488333
0    7.314258
dtype: float32
Epoch 187, train loss: 0.061194346780519784 test loss: 0.17345308511455287
0    7.272724
dtype: float32
Epoch 188, train loss: 0.054556202846677185 test loss: 0.1792833475145756
0    7.16381
dtype: float32
Epoch 189, train loss: 0.05261937740337094 test loss: 0.1818901416411212
0    7.191566
dtype: float32
Epoch 190, train loss: 0.051171072206066114 test loss: 0.1826639482200876
0    7.244155
dtype: float32
Epoch 191, train loss: 0.05533184125114552 test loss: 0.17122014333910146
0    7.309737
dtype: float32
Epoch 192, train loss: 0.059180913597394316 test loss: 0.17143842380817226
0    7.412235
dtype: float32
Epoch 193, train loss: 0.07337660705180138 test loss: 0.17232338127995378
0    7.357953
dtype: float32
Epoch 194, train loss: 0.06110310773343613 test loss: 0.17882641234174984
0    7.329483
dtype: float32
Epoch 195, train loss: 0.06282329016155622 test loss: 0.16899652450537608
0    7.342103
dtype: float32
Epoch 196, train loss: 0.061460353342844096 test loss: 0.17924264272020152
0    7.282985
dtype: float32
Epoch 197, train loss: 0.05847244287346335 test loss: 0.17096824379069595
0    7.152354
dtype: float32
Epoch 198, train loss: 0.05104629138491661 test loss: 0.19506255208351853
0    7.04804
dtype: float32
Epoch 199, train loss: 0.06336800748601237 test loss: 0.2242858819799699
0    7.249654
dtype: float32
Epoch 200, train loss: 0.05456752667518089 test loss: 0.1727821975445121
0    7.078532
dtype: float32
Epoch 201, train loss: 0.0568994083175474 test loss: 0.21633190724170387
0    7.097577
dtype: float32
Epoch 202, train loss: 0.05515273829642417 test loss: 0.2086820247568844
0    7.06195
dtype: float32
Epoch 203, train loss: 0.059608256488796654 test loss: 0.22351398190990382
0    7.128443
dtype: float32
Epoch 204, train loss: 0.05275250099192728 test loss: 0.20967506548360015
0    7.014729
dtype: float32
Epoch 205, train loss: 0.0656948329926828 test loss: 0.25562810687556775
0    6.907263
dtype: float32
Epoch 206, train loss: 0.09158573623943594 test loss: 0.22181917680219035
0    7.012506
dtype: float32
Epoch 207, train loss: 0.06838643162417449 test loss: 0.24423389460176345
0    7.176321
dtype: float32
Epoch 208, train loss: 0.05070667582641344 test loss: 0.19133818796102645
0    7.115351
dtype: float32
Epoch 209, train loss: 0.05514650674273934 test loss: 0.2009745070679316
0    7.106639
dtype: float32
Epoch 210, train loss: 0.057404412968563495 test loss: 0.1829105665007377
0    7.147348
dtype: float32
Epoch 211, train loss: 0.05258369557697674 test loss: 0.19031357822668282
0    7.184756
dtype: float32
Epoch 212, train loss: 0.050421531845432466 test loss: 0.19028569882111235
0    7.051807
dtype: float32
Epoch 213, train loss: 0.06102258299771714 test loss: 0.23070423302251877
0    7.024193
dtype: float32
Epoch 214, train loss: 0.06701301226449836 test loss: 0.22148863999798005
0    7.262357
dtype: float32
Epoch 215, train loss: 0.0526525237733862 test loss: 0.17866734216247224
0    7.173303
dtype: float32
Epoch 216, train loss: 0.0510700323541398 test loss: 0.19337850554120678
0    7.040193
dtype: float32
Epoch 217, train loss: 0.05942811360294536 test loss: 0.223022902968528
0    6.945604
dtype: float32
Epoch 218, train loss: 0.07031722917324196 test loss: 0.21961554898456073
0    7.186435
dtype: float32
Epoch 219, train loss: 0.050448156888533366 test loss: 0.18929203364917108
0    7.186628
dtype: float32
Epoch 220, train loss: 0.05221934311555243 test loss: 0.19106189469985255
0    7.188263
dtype: float32
Epoch 221, train loss: 0.05075399462749026 test loss: 0.1773216525665071
0    7.126083
dtype: float32
Epoch 222, train loss: 0.051708752015600705 test loss: 0.18327511329936308
0    7.283227
dtype: float32
Epoch 223, train loss: 0.05333054464404894 test loss: 0.17511099830239021
0    7.261894
dtype: float32
Epoch 224, train loss: 0.05207275818660728 test loss: 0.17724861407607143
0    7.236942
dtype: float32
Epoch 225, train loss: 0.05098273579718172 test loss: 0.1900241403751097
0    7.094317
dtype: float32
Epoch 226, train loss: 0.05439088447469803 test loss: 0.20231232332218457
0    7.181385
dtype: float32
Epoch 227, train loss: 0.04968093756758521 test loss: 0.18095730030584709
0    7.18942
dtype: float32
Epoch 228, train loss: 0.05056645297771284 test loss: 0.19613115462257846
0    7.229855
dtype: float32
Epoch 229, train loss: 0.05046212778067669 test loss: 0.17740677779999717
0    7.333404
dtype: float32
Epoch 230, train loss: 0.056575428848633876 test loss: 0.1751602930202081
0    7.255942
dtype: float32
Epoch 231, train loss: 0.05195508559965323 test loss: 0.19575620344819436
0    7.35315
dtype: float32
Epoch 232, train loss: 0.06059002464023076 test loss: 0.16871456197990814
0    7.190131
dtype: float32
Epoch 233, train loss: 0.049295475241731855 test loss: 0.1866815606846266
0    7.140436
dtype: float32
Epoch 234, train loss: 0.04994511132582649 test loss: 0.19628139739591655
0    6.906075
dtype: float32
Epoch 235, train loss: 0.09047552614102741 test loss: 0.2862560535124859
0    7.160434
dtype: float32
Epoch 236, train loss: 0.05075477960395567 test loss: 0.17850306184558967
0    7.221016
dtype: float32
Epoch 237, train loss: 0.05103531267639796 test loss: 0.17065531343522522
0    7.320847
dtype: float32
Epoch 238, train loss: 0.057183298566079 test loss: 0.17320331736575847
0    7.299546
dtype: float32
Epoch 239, train loss: 0.05681324045240881 test loss: 0.1706582693300121
0    7.044708
dtype: float32
Epoch 240, train loss: 0.058337901170809225 test loss: 0.21015127493698513
0    7.097203
dtype: float32
Epoch 241, train loss: 0.054064510645787225 test loss: 0.19737760020544323
0    7.055917
dtype: float32
Epoch 242, train loss: 0.062443906307184084 test loss: 0.19075237162651681
0    7.200289
dtype: float32
Epoch 243, train loss: 0.04925316139080665 test loss: 0.1897393071316422
0    7.294126
dtype: float32
Epoch 244, train loss: 0.05499198873480568 test loss: 0.1718996751220825
0    7.242656
dtype: float32
Epoch 245, train loss: 0.052576926836684565 test loss: 0.17977107219243255
0    7.168453
dtype: float32
Epoch 246, train loss: 0.04906139028523774 test loss: 0.18883041732317393
0    7.146821
dtype: float32
Epoch 247, train loss: 0.04952560827155907 test loss: 0.18647045098739776
0    7.151786
dtype: float32
Epoch 248, train loss: 0.04926095521735394 test loss: 0.17248959693994037
0    7.020188
dtype: float32
Epoch 249, train loss: 0.05897721745438614 test loss: 0.22860256777088533
0    7.075737
dtype: float32
Epoch 250, train loss: 0.05372459420522738 test loss: 0.2084755756594113
0    7.218699
dtype: float32
Epoch 251, train loss: 0.04905855277408403 test loss: 0.1848593835931277
0    7.24647
dtype: float32
Epoch 252, train loss: 0.05166898679840092 test loss: 0.17909115227549421
0    7.310703
dtype: float32
Epoch 253, train loss: 0.05628290775367802 test loss: 0.17291703902458266
0    7.079032
dtype: float32
Epoch 254, train loss: 0.05442994641039437 test loss: 0.19647623723640872
0    7.099839
dtype: float32
Epoch 255, train loss: 0.052713493391912086 test loss: 0.19610194586857785
0    7.186381
dtype: float32
Epoch 256, train loss: 0.04853281445495676 test loss: 0.18322904273110058
0    7.256528
dtype: float32
Epoch 257, train loss: 0.051577520540253864 test loss: 0.17294667349868617
0    7.18644
dtype: float32
Epoch 258, train loss: 0.049468389413466034 test loss: 0.1907619428762061
0    7.094463
dtype: float32
Epoch 259, train loss: 0.056175613295681014 test loss: 0.1904634622334219
0    7.072423
dtype: float32
Epoch 260, train loss: 0.050224843616236636 test loss: 0.18333265100622892
0    7.276576
dtype: float32
Epoch 261, train loss: 0.055750065212648275 test loss: 0.16962483608112316
0    7.238746
dtype: float32
Epoch 262, train loss: 0.05361012612348718 test loss: 0.17494777531183614
0    7.123592
dtype: float32
Epoch 263, train loss: 0.048873498013173054 test loss: 0.18244539743558738
0    7.096664
dtype: float32
Epoch 264, train loss: 0.04926198050336194 test loss: 0.19176065350512078
0    7.073734
dtype: float32
Epoch 265, train loss: 0.05211747940795897 test loss: 0.20012220112755108
0    7.059343
dtype: float32
Epoch 266, train loss: 0.05171091783165121 test loss: 0.20277752519106076
0    7.035602
dtype: float32
Epoch 267, train loss: 0.05595289761512167 test loss: 0.22286619536652014
0    7.202991
dtype: float32
Epoch 268, train loss: 0.04975415984425766 test loss: 0.17577506071203486
0    7.03497
dtype: float32
Epoch 269, train loss: 0.0560429773318612 test loss: 0.23848167067665368
0    7.111552
dtype: float32
Epoch 270, train loss: 0.04836516135593603 test loss: 0.178779342764585
0    7.129455
dtype: float32
Epoch 271, train loss: 0.04821926330663768 test loss: 0.18542209138309576
0    7.327647
dtype: float32
Epoch 272, train loss: 0.05718805748945079 test loss: 0.1705894322239813
0    7.276295
dtype: float32
Epoch 273, train loss: 0.05652143118310621 test loss: 0.1709092894815796
0    7.376099
dtype: float32
Epoch 274, train loss: 0.06832007863343724 test loss: 0.16960072524446967
0    7.198725
dtype: float32
Epoch 275, train loss: 0.04898261756277234 test loss: 0.1898440157149192
0    7.263348
dtype: float32
Epoch 276, train loss: 0.05521019127809038 test loss: 0.17298434780839456
0    7.121202
dtype: float32
Epoch 277, train loss: 0.048201713759373196 test loss: 0.2036325638410675
0    7.217564
dtype: float32
Epoch 278, train loss: 0.05247765529257503 test loss: 0.17126437413740717
0    7.164165
dtype: float32
Epoch 279, train loss: 0.047517944761009 test loss: 0.1891907935732429
0    7.087737
dtype: float32
Epoch 280, train loss: 0.04855903442891429 test loss: 0.19116225542936124
0    7.169873
dtype: float32
Epoch 281, train loss: 0.047842470282501236 test loss: 0.17685021960254485
0    7.126232
dtype: float32
Epoch 282, train loss: 0.0482489762568206 test loss: 0.19070529777022596
0    7.171257
dtype: float32
Epoch 283, train loss: 0.0493892574882859 test loss: 0.1923462629441541
0    7.146223
dtype: float32
Epoch 284, train loss: 0.048722925196755036 test loss: 0.20698771468853513
0    7.072436
dtype: float32
Epoch 285, train loss: 0.05406251165182732 test loss: 0.20260313385879247
0    7.090472
dtype: float32
Epoch 286, train loss: 0.05096158582469396 test loss: 0.19181117772092446
0    7.313264
dtype: float32
Epoch 287, train loss: 0.058229401807086086 test loss: 0.1749037800764402
0    7.276284
dtype: float32
Epoch 288, train loss: 0.05488584874070043 test loss: 0.17313162183410497
0    7.209118
dtype: float32
Epoch 289, train loss: 0.052653712399611745 test loss: 0.1847455808557788
0    7.185904
dtype: float32
Epoch 290, train loss: 0.048746523482189 test loss: 0.1744538525809332
0    7.235202
dtype: float32
Epoch 291, train loss: 0.04972698342554465 test loss: 0.18043758864688592
0    7.21868
dtype: float32
Epoch 292, train loss: 0.048999817001746784 test loss: 0.17937052897637318
0    7.178952
dtype: float32
Epoch 293, train loss: 0.04807811336935771 test loss: 0.17871510827477793
0    7.123089
dtype: float32
Epoch 294, train loss: 0.04887973507311544 test loss: 0.20486878535634787
0    7.285736
dtype: float32
Epoch 295, train loss: 0.058043663766734026 test loss: 0.17605266475309544
0    7.278114
dtype: float32
Epoch 296, train loss: 0.05597940241101917 test loss: 0.17678463824635582
0    7.251468
dtype: float32
Epoch 297, train loss: 0.05439822910618134 test loss: 0.17635648779116816
0    7.313571
dtype: float32
Epoch 298, train loss: 0.059304321045870044 test loss: 0.1707335171113037
0    7.19332
dtype: float32
Epoch 299, train loss: 0.049959067480027694 test loss: 0.17124626844387555
Final train loss is: 0.049959067480027694, Test loss is: 0.17124626844387555
0    7.19332
dtype: float32
round is 1
0    9.379208
dtype: float32
Epoch 5, train loss: 0.32497360801873915 test loss: 0.29401219062921463
0    7.234266
dtype: float32
Epoch 6, train loss: 0.2732748962161461 test loss: 0.27606108166915855
0    9.392645
dtype: float32
Epoch 7, train loss: 0.3205559369840731 test loss: 0.1910456915301904
0    5.271524
dtype: float32
Epoch 10, train loss: 0.3036225398623326 test loss: 0.23956898777988223
0    7.586205
dtype: float32
Epoch 11, train loss: 0.19230506705990305 test loss: 0.13935692117789789
0    6.787125
dtype: float32
Epoch 12, train loss: 0.15634573964726503 test loss: 0.1517410278340502
0    6.525699
dtype: float32
Epoch 13, train loss: 0.13112334352246732 test loss: 0.13578290231228565
0    5.980762
dtype: float32
Epoch 14, train loss: 0.12586992124331345 test loss: 0.14444584934831542
0    7.553267
dtype: float32
Epoch 16, train loss: 0.19846518142059288 test loss: 0.13966894578345962
0    7.055396
dtype: float32
Epoch 17, train loss: 0.1628668254821469 test loss: 0.14873266909571714
0    5.812637
dtype: float32
Epoch 18, train loss: 0.1290155121104137 test loss: 0.12190668515314916
0    4.706924
dtype: float32
Epoch 19, train loss: 0.3014743914440264 test loss: 0.17099197099738941
0    4.671817
dtype: float32
Epoch 20, train loss: 0.2743096461094504 test loss: 0.14323636610320034
0    4.897699
dtype: float32
Epoch 21, train loss: 0.297487914334667 test loss: 0.22579438145816458
0    4.674326
dtype: float32
Epoch 22, train loss: 0.21792717396632222 test loss: 0.1381256453082715
0    6.900633
dtype: float32
Epoch 23, train loss: 0.14249481649648824 test loss: 0.13946857234674906
0    6.140112
dtype: float32
Epoch 24, train loss: 0.10826905489047907 test loss: 0.11335743524810342
0    7.195124
dtype: float32
Epoch 25, train loss: 0.14644580426956746 test loss: 0.13922494325951845
0    7.115613
dtype: float32
Epoch 26, train loss: 0.14013326232441986 test loss: 0.13823697926704273
0    6.649504
dtype: float32
Epoch 27, train loss: 0.11743134944039427 test loss: 0.11181606958119851
0    5.991185
dtype: float32
Epoch 28, train loss: 0.09951459313932547 test loss: 0.10997459866673502
0    6.144787
dtype: float32
Epoch 29, train loss: 0.09488261507551074 test loss: 0.10933545193539523
0    5.661553
dtype: float32
Epoch 30, train loss: 0.12658257278783666 test loss: 0.11122453119441099
0    5.204529
dtype: float32
Epoch 31, train loss: 0.15653336378984414 test loss: 0.12298983954633634
0    6.162546
dtype: float32
Epoch 32, train loss: 0.09588746245124191 test loss: 0.1104481133006217
0    5.518766
dtype: float32
Epoch 33, train loss: 0.11492249397592397 test loss: 0.11321570963398525
0    6.658076
dtype: float32
Epoch 34, train loss: 0.11363301847179401 test loss: 0.1159986782050591
0    6.4594
dtype: float32
Epoch 35, train loss: 0.10700612485874661 test loss: 0.10902119251938043
0    5.858286
dtype: float32
Epoch 36, train loss: 0.1246437869871539 test loss: 0.12950529507759379
0    5.119798
dtype: float32
Epoch 37, train loss: 0.18884279710982804 test loss: 0.12457360271997969
0    5.366147
dtype: float32
Epoch 38, train loss: 0.17623965806510802 test loss: 0.14363277727480495
0    4.747252
dtype: float32
Epoch 39, train loss: 0.2595022505014734 test loss: 0.144989939754304
0    4.828782
dtype: float32
Epoch 40, train loss: 0.25155254941666305 test loss: 0.12224987307656794
0    6.404281
dtype: float32
Epoch 41, train loss: 0.09017971953637566 test loss: 0.10863411444615857
0    6.773036
dtype: float32
Epoch 42, train loss: 0.09896921712633802 test loss: 0.12426560650530456
0    6.404249
dtype: float32
Epoch 43, train loss: 0.0878343618458384 test loss: 0.11055220196832982
0    6.877396
dtype: float32
Epoch 44, train loss: 0.11322178881077845 test loss: 0.11453784666431226
0    6.617141
dtype: float32
Epoch 45, train loss: 0.09464883746192265 test loss: 0.10748665786366478
0    6.464869
dtype: float32
Epoch 46, train loss: 0.08610523409272909 test loss: 0.10889205433366599
0    5.718209
dtype: float32
Epoch 47, train loss: 0.10473612145441055 test loss: 0.10705559446708827
0    6.299793
dtype: float32
Epoch 48, train loss: 0.08642661247114586 test loss: 0.10521793397874993
0    6.306101
dtype: float32
Epoch 49, train loss: 0.08065936747100821 test loss: 0.10647807959269337
0    6.604052
dtype: float32
Epoch 50, train loss: 0.09812065447380716 test loss: 0.10916800738633112
0    6.656411
dtype: float32
Epoch 51, train loss: 0.0994484971268852 test loss: 0.11874283745211683
0    6.366182
dtype: float32
Epoch 52, train loss: 0.08189357974356665 test loss: 0.10937463287062445
0    6.3522
dtype: float32
Epoch 53, train loss: 0.0819144236886006 test loss: 0.11426448416440158
0    5.917965
dtype: float32
Epoch 54, train loss: 0.08224688799885256 test loss: 0.10784812937925282
0    6.75431
dtype: float32
Epoch 55, train loss: 0.09735423720029489 test loss: 0.1192419403039619
0    6.423879
dtype: float32
Epoch 56, train loss: 0.09404885692210796 test loss: 0.1114293533780939
0    6.387136
dtype: float32
Epoch 57, train loss: 0.0857711203512027 test loss: 0.11665217684871837
0    6.313886
dtype: float32
Epoch 58, train loss: 0.07898912475799917 test loss: 0.10942355920817756
0    5.927969
dtype: float32
Epoch 59, train loss: 0.08265285313034465 test loss: 0.10743583332982436
0    5.269005
dtype: float32
Epoch 60, train loss: 0.16248566104776668 test loss: 0.12361686834003054
0    5.497253
dtype: float32
Epoch 61, train loss: 0.1366626871220896 test loss: 0.11873441472372129
0    5.412087
dtype: float32
Epoch 62, train loss: 0.16619957337631236 test loss: 0.14656023597616752
0    5.160407
dtype: float32
Epoch 63, train loss: 0.2328778120385655 test loss: 0.1684097831337494
0    5.091197
dtype: float32
Epoch 64, train loss: 0.2149257609247004 test loss: 0.13679533914144568
0    5.436063
dtype: float32
Epoch 65, train loss: 0.16804006456377252 test loss: 0.12340137784208673
0    6.112093
dtype: float32
Epoch 66, train loss: 0.09407767536116335 test loss: 0.11744017014361362
0    5.95058
dtype: float32
Epoch 67, train loss: 0.10211119293829968 test loss: 0.11727421814580073
0    6.396274
dtype: float32
Epoch 68, train loss: 0.08778477055354202 test loss: 0.11656807471813355
0    6.103144
dtype: float32
Epoch 69, train loss: 0.08980972728271204 test loss: 0.10893377350194804
0    5.66698
dtype: float32
Epoch 70, train loss: 0.1264424320262088 test loss: 0.11630581774874188
0    5.790609
dtype: float32
Epoch 71, train loss: 0.10627092326682641 test loss: 0.11042618948801028
0    6.274652
dtype: float32
Epoch 72, train loss: 0.07816146401173561 test loss: 0.11319059701332351
0    5.464179
dtype: float32
Epoch 73, train loss: 0.14351087448607416 test loss: 0.127993090479164
0    6.832819
dtype: float32
Epoch 74, train loss: 0.09914723556722342 test loss: 0.10929513180678953
0    6.819067
dtype: float32
Epoch 75, train loss: 0.1070446344566109 test loss: 0.13484881849907168
0    6.580398
dtype: float32
Epoch 76, train loss: 0.08534523601532507 test loss: 0.11437451318347054
0    6.752051
dtype: float32
Epoch 77, train loss: 0.08793125217466183 test loss: 0.11898435361227702
0    6.870477
dtype: float32
Epoch 78, train loss: 0.0949526163002678 test loss: 0.12841042493976929
0    7.056805
dtype: float32
Epoch 79, train loss: 0.11194709745073243 test loss: 0.1325799565531391
0    7.007248
dtype: float32
Epoch 80, train loss: 0.11313875794117395 test loss: 0.13330688580253974
0    6.90163
dtype: float32
Epoch 81, train loss: 0.09425061064355512 test loss: 0.1253317696540375
0    7.071793
dtype: float32
Epoch 82, train loss: 0.09785651623128687 test loss: 0.11413415969451592
0    7.260659
dtype: float32
Epoch 83, train loss: 0.1305547556390448 test loss: 0.12239688019911753
0    6.801994
dtype: float32
Epoch 84, train loss: 0.09868310994655527 test loss: 0.11737099720097366
0    6.867255
dtype: float32
Epoch 85, train loss: 0.09626709398396906 test loss: 0.11437401398921361
0    6.788417
dtype: float32
Epoch 86, train loss: 0.0866403340027956 test loss: 0.12265936207827544
0    6.704855
dtype: float32
Epoch 87, train loss: 0.0975848834623783 test loss: 0.1208653522399865
0    7.468638
dtype: float32
Epoch 88, train loss: 0.14775991728486979 test loss: 0.1511366493026702
0    6.638605
dtype: float32
Epoch 89, train loss: 0.09657984784859569 test loss: 0.1290951405029077
0    7.238991
dtype: float32
Epoch 90, train loss: 0.12466845965936942 test loss: 0.1502039409715267
0    6.897961
dtype: float32
Epoch 91, train loss: 0.09220247444815634 test loss: 0.12283925168815889
0    6.969095
dtype: float32
Epoch 92, train loss: 0.087386747077382 test loss: 0.11509217498616144
0    6.707382
dtype: float32
Epoch 93, train loss: 0.07700724022618952 test loss: 0.11398673425596088
0    6.77941
dtype: float32
Epoch 94, train loss: 0.08144026575385549 test loss: 0.11985864461781708
0    6.097463
dtype: float32
Epoch 95, train loss: 0.08512295265840195 test loss: 0.10981579063107895
0    5.853204
dtype: float32
Epoch 96, train loss: 0.11784466572908489 test loss: 0.11437259319363392
0    6.162091
dtype: float32
Epoch 97, train loss: 0.10445295311247998 test loss: 0.1276680108852719
0    6.361237
dtype: float32
Epoch 98, train loss: 0.07217405549063297 test loss: 0.11068956680678661
0    5.784674
dtype: float32
Epoch 99, train loss: 0.1428546492997148 test loss: 0.11571361244641046
0    6.18867
dtype: float32
Epoch 100, train loss: 0.08263194488830562 test loss: 0.1093902519892554
0    6.802962
dtype: float32
Epoch 101, train loss: 0.0756049553654909 test loss: 0.11334596090662649
0    6.398749
dtype: float32
Epoch 102, train loss: 0.07886521871335958 test loss: 0.11394557667004329
0    6.407778
dtype: float32
Epoch 103, train loss: 0.08179862709184323 test loss: 0.11119040356415065
0    7.362431
dtype: float32
Epoch 104, train loss: 0.13336044985275364 test loss: 0.1404824365232974
0    7.14024
dtype: float32
Epoch 105, train loss: 0.10568351666718062 test loss: 0.12845872892879803
0    6.789759
dtype: float32
Epoch 106, train loss: 0.07500258575131366 test loss: 0.1141067419081325
0    6.932023
dtype: float32
Epoch 107, train loss: 0.08917446548324008 test loss: 0.12297120281082752
0    6.933473
dtype: float32
Epoch 108, train loss: 0.09549709477950057 test loss: 0.12496582869206697
0    7.03209
dtype: float32
Epoch 109, train loss: 0.0990660249633004 test loss: 0.12838475605350222
0    7.142246
dtype: float32
Epoch 110, train loss: 0.10616749492037363 test loss: 0.1296147492586037
0    6.948462
dtype: float32
Epoch 111, train loss: 0.08075560529205532 test loss: 0.11505842566585466
0    7.422903
dtype: float32
Epoch 112, train loss: 0.12372192713358962 test loss: 0.1460829975907214
0    6.915932
dtype: float32
Epoch 113, train loss: 0.08861856536352668 test loss: 0.1255222503477712
0    6.706733
dtype: float32
Epoch 114, train loss: 0.07702335024347264 test loss: 0.12166493648608907
0    6.52459
dtype: float32
Epoch 115, train loss: 0.08498902084611948 test loss: 0.1202742666429579
0    6.846889
dtype: float32
Epoch 116, train loss: 0.07304131840777188 test loss: 0.11458094897063306
0    7.03942
dtype: float32
Epoch 117, train loss: 0.09613409799029478 test loss: 0.1274505827319828
0    6.886128
dtype: float32
Epoch 118, train loss: 0.07709435709252278 test loss: 0.12053686825001493
0    7.215961
dtype: float32
Epoch 119, train loss: 0.08910830403912524 test loss: 0.12979993572504203
0    6.72513
dtype: float32
Epoch 120, train loss: 0.07046922761682026 test loss: 0.11403438603935633
0    6.394822
dtype: float32
Epoch 121, train loss: 0.09246308296813321 test loss: 0.12394480799486683
0    6.079628
dtype: float32
Epoch 122, train loss: 0.10685599916955098 test loss: 0.11551470861606655
0    6.080102
dtype: float32
Epoch 123, train loss: 0.1417988643586889 test loss: 0.14127402195060018
0    6.385487
dtype: float32
Epoch 124, train loss: 0.10532299179535336 test loss: 0.13085456593585068
0    5.939753
dtype: float32
Epoch 125, train loss: 0.12849370964539292 test loss: 0.11581087217000356
0    5.935589
dtype: float32
Epoch 126, train loss: 0.11094386462143392 test loss: 0.11215834241647372
0    6.635075
dtype: float32
Epoch 127, train loss: 0.06691369724821557 test loss: 0.11202033666208103
0    6.608428
dtype: float32
Epoch 128, train loss: 0.07536600884991308 test loss: 0.11293728596520344
0    5.879062
dtype: float32
Epoch 129, train loss: 0.14244269641002688 test loss: 0.12693869813807707
0    6.369581
dtype: float32
Epoch 130, train loss: 0.07743857136686862 test loss: 0.10932699311550256
0    6.584099
dtype: float32
Epoch 131, train loss: 0.07052121778148736 test loss: 0.10939851092284328
0    6.863863
dtype: float32
Epoch 132, train loss: 0.07791509034938379 test loss: 0.11815059098902378
0    6.919143
dtype: float32
Epoch 133, train loss: 0.07599889390674174 test loss: 0.11576616831831911
0    6.815367
dtype: float32
Epoch 134, train loss: 0.06947259803524451 test loss: 0.11546002226442226
0    6.677737
dtype: float32
Epoch 135, train loss: 0.0699151955397475 test loss: 0.11494444991610282
0    6.530229
dtype: float32
Epoch 136, train loss: 0.0821030075841934 test loss: 0.11722299673980632
0    6.343967
dtype: float32
Epoch 137, train loss: 0.08726738793564562 test loss: 0.11163001722386268
0    6.834493
dtype: float32
Epoch 138, train loss: 0.0770646384166356 test loss: 0.12235207510570911
0    6.859869
dtype: float32
Epoch 139, train loss: 0.06938754706694424 test loss: 0.1169413554786213
0    6.57435
dtype: float32
Epoch 140, train loss: 0.10531957237687711 test loss: 0.13386268304786939
0    5.978771
dtype: float32
Epoch 141, train loss: 0.12452923819760828 test loss: 0.1220516741527567
0    5.943186
dtype: float32
Epoch 142, train loss: 0.14867842715866114 test loss: 0.1392247359603289
0    6.654705
dtype: float32
Epoch 143, train loss: 0.0696646261050055 test loss: 0.11083091100177443
0    6.738684
dtype: float32
Epoch 144, train loss: 0.0660531853406462 test loss: 0.11155483448407619
0    6.458423
dtype: float32
Epoch 145, train loss: 0.0929237496391857 test loss: 0.12103950049545244
0    6.322326
dtype: float32
Epoch 146, train loss: 0.12494425785580576 test loss: 0.1420493465784732
0    6.962845
dtype: float32
Epoch 147, train loss: 0.06520638428918299 test loss: 0.11277516716295549
0    6.979368
dtype: float32
Epoch 148, train loss: 0.07216384687919836 test loss: 0.11578484849955173
0    7.186491
dtype: float32
Epoch 149, train loss: 0.07865326018538224 test loss: 0.11995897168930465
0    7.259241
dtype: float32
Epoch 150, train loss: 0.08687392017830169 test loss: 0.11920161294927203
0    7.036686
dtype: float32
Epoch 151, train loss: 0.07390439993993103 test loss: 0.11816507134125129
0    7.406141
dtype: float32
Epoch 152, train loss: 0.10077771134313677 test loss: 0.13099236693775318
0    7.178474
dtype: float32
Epoch 153, train loss: 0.08246123168074146 test loss: 0.12473638242831278
0    7.379626
dtype: float32
Epoch 154, train loss: 0.10490712922676969 test loss: 0.14032754502835998
0    7.129883
dtype: float32
Epoch 155, train loss: 0.0722928013715656 test loss: 0.11534746594538262
0    7.109893
dtype: float32
Epoch 156, train loss: 0.07422762577316273 test loss: 0.12074408053216959
0    7.242515
dtype: float32
Epoch 157, train loss: 0.07485126420336097 test loss: 0.11922918522039026
0    7.141897
dtype: float32
Epoch 158, train loss: 0.09565404828034346 test loss: 0.1353424924469788
0    6.89676
dtype: float32
Epoch 159, train loss: 0.0749871083941999 test loss: 0.12367605986656695
0    6.724722
dtype: float32
Epoch 160, train loss: 0.07246668751263989 test loss: 0.11933942111652653
0    6.965549
dtype: float32
Epoch 161, train loss: 0.06232944356076739 test loss: 0.11529679798303744
0    6.637739
dtype: float32
Epoch 162, train loss: 0.0673620289423625 test loss: 0.11272697195405101
0    6.374032
dtype: float32
Epoch 163, train loss: 0.09237332022037353 test loss: 0.11402266067226781
0    7.282324
dtype: float32
Epoch 164, train loss: 0.08324879155880423 test loss: 0.12619815109614196
0    6.785213
dtype: float32
Epoch 165, train loss: 0.06530196195886319 test loss: 0.1165625145547351
0    7.107542
dtype: float32
Epoch 166, train loss: 0.06368186214608836 test loss: 0.11723059681597962
0    6.709571
dtype: float32
Epoch 167, train loss: 0.08598893738896142 test loss: 0.12879771358696554
0    6.891289
dtype: float32
Epoch 168, train loss: 0.0650219000668462 test loss: 0.1143853522929336
0    6.517859
dtype: float32
Epoch 169, train loss: 0.08817956377944036 test loss: 0.11658294537180966
0    6.567691
dtype: float32
Epoch 170, train loss: 0.08650134977257216 test loss: 0.12198798621914589
0    6.804079
dtype: float32
Epoch 171, train loss: 0.06540065459865199 test loss: 0.11652265985026371
0    6.733325
dtype: float32
Epoch 172, train loss: 0.08037307345518559 test loss: 0.12004918600407792
0    6.746194
dtype: float32
Epoch 173, train loss: 0.08347190161272809 test loss: 0.1268105983300131
0    6.816877
dtype: float32
Epoch 174, train loss: 0.06481795054745645 test loss: 0.11994855777796304
0    6.275792
dtype: float32
Epoch 175, train loss: 0.10740527449108873 test loss: 0.11633767897953082
0    6.281556
dtype: float32
Epoch 176, train loss: 0.1349638551060643 test loss: 0.14185711240873894
0    6.522923
dtype: float32
Epoch 177, train loss: 0.08578232257016313 test loss: 0.12005298026363524
0    7.262807
dtype: float32
Epoch 178, train loss: 0.06977326039786472 test loss: 0.11899450918434301
0    7.074932
dtype: float32
Epoch 179, train loss: 0.0640441035641636 test loss: 0.11845388292015284
0    7.283211
dtype: float32
Epoch 180, train loss: 0.08631907899670296 test loss: 0.12840785974788702
0    7.090394
dtype: float32
Epoch 181, train loss: 0.06455469235802458 test loss: 0.1174436480219471
0    7.635552
dtype: float32
Epoch 182, train loss: 0.10867131968004197 test loss: 0.1422534284537547
0    7.452051
dtype: float32
Epoch 183, train loss: 0.08370453660605816 test loss: 0.1320704940879924
0    7.19944
dtype: float32
Epoch 184, train loss: 0.06361466061399294 test loss: 0.12373148595616587
0    7.061679
dtype: float32
Epoch 185, train loss: 0.059663879795956325 test loss: 0.12007772362990118
0    7.465072
dtype: float32
Epoch 186, train loss: 0.07701864589650775 test loss: 0.1264723795874423
0    7.33271
dtype: float32
Epoch 187, train loss: 0.0805869083388396 test loss: 0.13341752884507208
0    7.241373
dtype: float32
Epoch 188, train loss: 0.06176694326469297 test loss: 0.12076844852012873
0    6.876074
dtype: float32
Epoch 189, train loss: 0.06641720660733173 test loss: 0.12197908803519593
0    6.762264
dtype: float32
Epoch 190, train loss: 0.07734361290602675 test loss: 0.12378567584436931
0    6.623441
dtype: float32
Epoch 191, train loss: 0.11284425499052794 test loss: 0.12829145849548387
0    6.714846
dtype: float32
Epoch 192, train loss: 0.0886443999701072 test loss: 0.13309892882212063
0    6.760053
dtype: float32
Epoch 193, train loss: 0.07689388195062699 test loss: 0.12742104726376846
0    6.912453
dtype: float32
Epoch 194, train loss: 0.06594895019605956 test loss: 0.12540491675974574
0    6.99727
dtype: float32
Epoch 195, train loss: 0.0721332080272695 test loss: 0.12799233557473247
0    7.072316
dtype: float32
Epoch 196, train loss: 0.06497848050272262 test loss: 0.12233053575146441
0    6.827794
dtype: float32
Epoch 197, train loss: 0.07214659741258331 test loss: 0.1204079552438419
0    6.900533
dtype: float32
Epoch 198, train loss: 0.08493659010421536 test loss: 0.13147942418201644
0    7.200221
dtype: float32
Epoch 199, train loss: 0.07215811925274902 test loss: 0.1318979527173575
0    7.676248
dtype: float32
Epoch 200, train loss: 0.08335955566964719 test loss: 0.12900564447207116
0    7.365557
dtype: float32
Epoch 201, train loss: 0.06964873726111945 test loss: 0.12434660144687615
0    7.739466
dtype: float32
Epoch 202, train loss: 0.11722237051437454 test loss: 0.14821656922790247
0    7.516574
dtype: float32
Epoch 203, train loss: 0.08476710608514046 test loss: 0.1338735096304058
0    7.527927
dtype: float32
Epoch 204, train loss: 0.08890184616855823 test loss: 0.13887244467399557
0    7.769159
dtype: float32
Epoch 205, train loss: 0.09930670926350488 test loss: 0.13864248090062298
0    7.138366
dtype: float32
Epoch 206, train loss: 0.06184199948317825 test loss: 0.12494695943546336
0    7.428391
dtype: float32
Epoch 207, train loss: 0.08296416183097997 test loss: 0.13244635123751725
0    7.56198
dtype: float32
Epoch 208, train loss: 0.08716720091446278 test loss: 0.1278503196290665
0    7.914057
dtype: float32
Epoch 209, train loss: 0.12296295746274438 test loss: 0.15529625783977816
0    7.638215
dtype: float32
Epoch 210, train loss: 0.09100267185835939 test loss: 0.14066924352831753
0    7.598311
dtype: float32
Epoch 211, train loss: 0.08231022943306458 test loss: 0.14111307672483359
0    7.525662
dtype: float32
Epoch 212, train loss: 0.07744281271537572 test loss: 0.13342917212387148
0    7.388513
dtype: float32
Epoch 213, train loss: 0.08540649998318792 test loss: 0.1370725622620592
0    7.516888
dtype: float32
Epoch 214, train loss: 0.07109344420579636 test loss: 0.12924822600097816
0    7.200813
dtype: float32
Epoch 215, train loss: 0.07100841724844593 test loss: 0.1371695110480452
0    6.79254
dtype: float32
Epoch 216, train loss: 0.0792271579338367 test loss: 0.124748931513245
0    6.714569
dtype: float32
Epoch 217, train loss: 0.08488688025000894 test loss: 0.1293211276248567
0    6.861571
dtype: float32
Epoch 218, train loss: 0.07947799810519847 test loss: 0.12916106086142204
0    7.028183
dtype: float32
Epoch 219, train loss: 0.07056839538817711 test loss: 0.13006092655420018
0    6.845276
dtype: float32
Epoch 220, train loss: 0.0765052081166818 test loss: 0.1255329215954798
0    7.145824
dtype: float32
Epoch 221, train loss: 0.05726910957761639 test loss: 0.12366343235060404
0    7.154396
dtype: float32
Epoch 222, train loss: 0.07476061043609152 test loss: 0.13442312753801725
0    6.672581
dtype: float32
Epoch 223, train loss: 0.10952961254635847 test loss: 0.1421706975713519
0    7.033833
dtype: float32
Epoch 224, train loss: 0.07474744167693974 test loss: 0.1306428879089875
0    7.035487
dtype: float32
Epoch 225, train loss: 0.06973355739172726 test loss: 0.13051112629221612
0    7.006911
dtype: float32
Epoch 226, train loss: 0.06014683793880574 test loss: 0.1295778632342297
0    7.051054
dtype: float32
Epoch 227, train loss: 0.056441086788254345 test loss: 0.12660653065373115
0    6.802905
dtype: float32
Epoch 228, train loss: 0.07172486667468458 test loss: 0.1285785165385005
0    7.253494
dtype: float32
Epoch 229, train loss: 0.05711249056880168 test loss: 0.1289009543369966
0    7.046259
dtype: float32
Epoch 230, train loss: 0.05800663786149547 test loss: 0.12588195360967014
0    6.711219
dtype: float32
Epoch 231, train loss: 0.08482368399818337 test loss: 0.12989892169063877
0    7.00043
dtype: float32
Epoch 232, train loss: 0.1076497412670707 test loss: 0.16270793938826345
0    6.91449
dtype: float32
Epoch 233, train loss: 0.06490305895663313 test loss: 0.13236987640731954
0    7.145934
dtype: float32
Epoch 234, train loss: 0.0560718089793639 test loss: 0.13055761024061008
0    7.489458
dtype: float32
Epoch 235, train loss: 0.08668951244375628 test loss: 0.13984641319639557
0    6.907434
dtype: float32
Epoch 236, train loss: 0.0733305259825832 test loss: 0.12875882468878974
0    7.55871
dtype: float32
Epoch 237, train loss: 0.08766759582667369 test loss: 0.12724734911002974
0    7.081739
dtype: float32
Epoch 238, train loss: 0.057770782113202634 test loss: 0.1256861925782692
0    7.431599
dtype: float32
Epoch 239, train loss: 0.06189639342730065 test loss: 0.12628788791529885
0    7.540262
dtype: float32
Epoch 240, train loss: 0.06995356670721063 test loss: 0.13490677460828832
0    7.298468
dtype: float32
Epoch 241, train loss: 0.056299771491538524 test loss: 0.13253615597260762
0    7.122208
dtype: float32
Epoch 242, train loss: 0.0625086226287579 test loss: 0.13171533016536519
0    7.58703
dtype: float32
Epoch 243, train loss: 0.07948430928865204 test loss: 0.14059077510068738
0    7.357963
dtype: float32
Epoch 244, train loss: 0.05394084003964836 test loss: 0.1308507923988562
0    7.170891
dtype: float32
Epoch 245, train loss: 0.05409800673448897 test loss: 0.1276183653463353
0    7.479157
dtype: float32
Epoch 246, train loss: 0.05881488497743872 test loss: 0.12979826324509952
0    7.433457
dtype: float32
Epoch 247, train loss: 0.11121961213572852 test loss: 0.16318569456544024
0    7.3489
dtype: float32
Epoch 248, train loss: 0.08206686140836472 test loss: 0.13808329941839295
0    6.903019
dtype: float32
Epoch 249, train loss: 0.062082497350700545 test loss: 0.13161212327222305
0    7.186598
dtype: float32
Epoch 250, train loss: 0.05564107799017211 test loss: 0.13398253278766759
0    7.106954
dtype: float32
Epoch 251, train loss: 0.06058911338232808 test loss: 0.13127469951384688
0    7.13124
dtype: float32
Epoch 252, train loss: 0.054571582443257036 test loss: 0.1325654889108699
0    6.748345
dtype: float32
Epoch 253, train loss: 0.07715020225382065 test loss: 0.13094356971782112
0    7.523472
dtype: float32
Epoch 254, train loss: 0.07508235224831881 test loss: 0.13665786190423634
0    7.554905
dtype: float32
Epoch 255, train loss: 0.06540802194628424 test loss: 0.12961650639613867
0    7.304422
dtype: float32
Epoch 256, train loss: 0.05211467435733406 test loss: 0.1269761284748185
0    7.474735
dtype: float32
Epoch 257, train loss: 0.06191214872490395 test loss: 0.1298082784678658
0    6.963483
dtype: float32
Epoch 258, train loss: 0.0982524110113298 test loss: 0.15114143985551318
0    6.609985
dtype: float32
Epoch 259, train loss: 0.1016930455432035 test loss: 0.1391592951049648
0    7.17646
dtype: float32
Epoch 260, train loss: 0.05540459657793441 test loss: 0.12720923902584075
0    7.212831
dtype: float32
Epoch 261, train loss: 0.05120421721307497 test loss: 0.12605368573622242
0    7.746055
dtype: float32
Epoch 262, train loss: 0.08923621526503693 test loss: 0.13660837407517798
0    7.422323
dtype: float32
Epoch 263, train loss: 0.06832975046822415 test loss: 0.13496921969193607
0    7.428388
dtype: float32
Epoch 264, train loss: 0.07180575564101777 test loss: 0.13306719094836256
0    7.562188
dtype: float32
Epoch 265, train loss: 0.09891838965353571 test loss: 0.14399028920731288
0    7.986836
dtype: float32
Epoch 266, train loss: 0.10855386298301009 test loss: 0.13973503699012538
0    7.675079
dtype: float32
Epoch 267, train loss: 0.08059558492128562 test loss: 0.1375785968044695
0    7.242359
dtype: float32
Epoch 268, train loss: 0.056085204046836375 test loss: 0.12823352649136915
0    7.187732
dtype: float32
Epoch 269, train loss: 0.054348951771074946 test loss: 0.13158874299579262
0    7.26285
dtype: float32
Epoch 270, train loss: 0.05436917928659753 test loss: 0.13202453330082597
0    6.940491
dtype: float32
Epoch 271, train loss: 0.058717338992337935 test loss: 0.13154633419018633
0    6.555612
dtype: float32
Epoch 272, train loss: 0.12488485855715636 test loss: 0.17026681476086555
0    6.685335
dtype: float32
Epoch 273, train loss: 0.08060982199047874 test loss: 0.13237804296842853
0    7.037842
dtype: float32
Epoch 274, train loss: 0.05885219928998997 test loss: 0.1336741976914757
0    6.731256
dtype: float32
Epoch 275, train loss: 0.07011379026228771 test loss: 0.13872740180317733
0    6.754176
dtype: float32
Epoch 276, train loss: 0.07580964192534571 test loss: 0.14096097909299848
0    6.50397
dtype: float32
Epoch 277, train loss: 0.11573852457374967 test loss: 0.1333644864011355
0    6.7189
dtype: float32
Epoch 278, train loss: 0.07724525227330446 test loss: 0.13289753462175688
0    6.646104
dtype: float32
Epoch 279, train loss: 0.1159856908734081 test loss: 0.15185270050309357
0    6.930965
dtype: float32
Epoch 280, train loss: 0.06036414663515646 test loss: 0.12940603710792145
0    6.899316
dtype: float32
Epoch 281, train loss: 0.07231830180119202 test loss: 0.13513995688343292
0    7.704008
dtype: float32
Epoch 282, train loss: 0.09650053697306106 test loss: 0.14032678941183846
0    7.421793
dtype: float32
Epoch 283, train loss: 0.06456042154797105 test loss: 0.1341157960260241
0    7.413819
dtype: float32
Epoch 284, train loss: 0.05978639003757171 test loss: 0.13169177764073203
0    7.521148
dtype: float32
Epoch 285, train loss: 0.09052697365018667 test loss: 0.14739475194274093
0    7.423205
dtype: float32
Epoch 286, train loss: 0.0625353236513401 test loss: 0.12917074176553792
0    6.659873
dtype: float32
Epoch 287, train loss: 0.08726551502563984 test loss: 0.13273203393387745
0    7.206529
dtype: float32
Epoch 288, train loss: 0.053323102958562095 test loss: 0.1283565989134645
0    7.542243
dtype: float32
Epoch 289, train loss: 0.06653760549604308 test loss: 0.13088325947767954
0    6.959146
dtype: float32
Epoch 290, train loss: 0.0582442693026201 test loss: 0.1315322680240921
0    6.755224
dtype: float32
Epoch 291, train loss: 0.07221995792344378 test loss: 0.1294345088596555
0    7.241874
dtype: float32
Epoch 292, train loss: 0.05119584756944283 test loss: 0.13104244351219932
0    7.379377
dtype: float32
Epoch 293, train loss: 0.07709801110441744 test loss: 0.14213224521077433
0    7.714687
dtype: float32
Epoch 294, train loss: 0.11385808117764774 test loss: 0.14781790891848773
0    7.837307
dtype: float32
Epoch 295, train loss: 0.1174854332757421 test loss: 0.15410914987356203
0    7.442816
dtype: float32
Epoch 296, train loss: 0.06566827489713115 test loss: 0.13085231237538478
0    7.364028
dtype: float32
Epoch 297, train loss: 0.08658852999261542 test loss: 0.14712206148118798
0    7.095559
dtype: float32
Epoch 298, train loss: 0.060445268279877555 test loss: 0.13421897561410953
0    6.879787
dtype: float32
Epoch 299, train loss: 0.07546652787391306 test loss: 0.1387178224718098
Final train loss is: 0.07546652787391306, Test loss is: 0.1387178224718098
0    6.879787
dtype: float32
round is 2
0    7.214228
dtype: float32
Epoch 7, train loss: 0.2636025261354474 test loss: 0.21293033688115476
0    9.324384
dtype: float32
Epoch 8, train loss: 0.20814533518360806 test loss: 0.1254581687932524
0    8.35955
dtype: float32
Epoch 9, train loss: 0.16904894578049445 test loss: 0.18386703604664997
0    8.759678
dtype: float32
Epoch 10, train loss: 0.16089605188516196 test loss: 0.12754828803334878
0    8.259713
dtype: float32
Epoch 11, train loss: 0.14525346317718937 test loss: 0.12545984411976688
0    8.701457
dtype: float32
Epoch 12, train loss: 0.1573123115685353 test loss: 0.10768426270907334
0    8.46797
dtype: float32
Epoch 13, train loss: 0.1472335642065842 test loss: 0.10269223047833821
0    8.350224
dtype: float32
Epoch 14, train loss: 0.13129676903396206 test loss: 0.10974579678627301
0    8.03845
dtype: float32
Epoch 15, train loss: 0.1231445842376446 test loss: 0.10550361636998562
0    8.263161
dtype: float32
Epoch 16, train loss: 0.12782533342874244 test loss: 0.09601960429158383
0    6.538443
dtype: float32
Epoch 17, train loss: 0.2718449755438539 test loss: 0.20238243001538753
0    7.334478
dtype: float32
Epoch 18, train loss: 0.1325580817377309 test loss: 0.15017572616873917
0    7.330152
dtype: float32
Epoch 19, train loss: 0.13534370237878865 test loss: 0.13924060246905154
0    7.496974
dtype: float32
Epoch 20, train loss: 0.12376384355501178 test loss: 0.1307719643666649
0    6.98319
dtype: float32
Epoch 21, train loss: 0.1726965439090789 test loss: 0.13162479379912054
0    7.857063
dtype: float32
Epoch 22, train loss: 0.10551287525538816 test loss: 0.10649414710572297
0    7.199111
dtype: float32
Epoch 23, train loss: 0.12213787706668276 test loss: 0.13150970845763146
0    7.178868
dtype: float32
Epoch 24, train loss: 0.13906017822637443 test loss: 0.1620465318282324
0    7.658493
dtype: float32
Epoch 25, train loss: 0.10345543908272722 test loss: 0.09598950275952613
0    8.161915
dtype: float32
Epoch 26, train loss: 0.14683264520004827 test loss: 0.10843728003992366
0    7.583849
dtype: float32
Epoch 27, train loss: 0.09956329508121876 test loss: 0.08923235517802872
0    8.27498
dtype: float32
Epoch 28, train loss: 0.13584144831226508 test loss: 0.09489379626151301
0    7.542049
dtype: float32
Epoch 29, train loss: 0.10093960346319508 test loss: 0.09462229826992245
0    7.624023
dtype: float32
Epoch 30, train loss: 0.09536420918692198 test loss: 0.08829955509558247
0    6.989358
dtype: float32
Epoch 31, train loss: 0.12451882356857923 test loss: 0.11929827998050592
0    7.304094
dtype: float32
Epoch 32, train loss: 0.10360703433643173 test loss: 0.1048052764300725
0    7.140685
dtype: float32
Epoch 33, train loss: 0.12171857733978754 test loss: 0.12405474283888537
0    7.439724
dtype: float32
Epoch 34, train loss: 0.1033254473169999 test loss: 0.10945814027405501
0    7.03212
dtype: float32
Epoch 35, train loss: 0.09991437985990297 test loss: 0.0928962144482491
0    7.311981
dtype: float32
Epoch 36, train loss: 0.08947999410848739 test loss: 0.09271295070899069
0    7.645645
dtype: float32
Epoch 37, train loss: 0.10541271483498303 test loss: 0.10650736106881717
0    7.363139
dtype: float32
Epoch 38, train loss: 0.09321028299352906 test loss: 0.1025029306641619
0    7.104039
dtype: float32
Epoch 39, train loss: 0.1203435955422252 test loss: 0.1347513687426336
0    7.005763
dtype: float32
Epoch 40, train loss: 0.1004001873023809 test loss: 0.08645690847451173
0    7.543881
dtype: float32
Epoch 41, train loss: 0.09804860851621526 test loss: 0.10464478705410911
0    7.092166
dtype: float32
Epoch 42, train loss: 0.11393994910337671 test loss: 0.11138235023765854
0    7.181405
dtype: float32
Epoch 43, train loss: 0.08502721952994462 test loss: 0.07940107111081315
0    7.633411
dtype: float32
Epoch 44, train loss: 0.10588119794571904 test loss: 0.09475741285079278
0    7.181241
dtype: float32
Epoch 45, train loss: 0.08388914127333309 test loss: 0.08009647262028277
0    7.131896
dtype: float32
Epoch 46, train loss: 0.08451179732586919 test loss: 0.08464149195890876
0    7.248353
dtype: float32
Epoch 47, train loss: 0.08111242778827553 test loss: 0.08683548617652678
0    6.94747
dtype: float32
Epoch 48, train loss: 0.10387636456108805 test loss: 0.07979881928001523
0    7.150089
dtype: float32
Epoch 49, train loss: 0.08541047788373927 test loss: 0.08587937282872353
0    7.2487
dtype: float32
Epoch 50, train loss: 0.08424329312349167 test loss: 0.0799187343455472
0    7.286486
dtype: float32
Epoch 51, train loss: 0.0811892711080995 test loss: 0.08578140830741335
0    7.336
dtype: float32
Epoch 52, train loss: 0.0939963133346373 test loss: 0.10865218451116615
0    7.065451
dtype: float32
Epoch 53, train loss: 0.08834942555883206 test loss: 0.08411929849933929
0    6.984618
dtype: float32
Epoch 54, train loss: 0.12264796506220906 test loss: 0.1144934622726791
0    6.907727
dtype: float32
Epoch 55, train loss: 0.0954630790404281 test loss: 0.0729620636854113
0    6.887014
dtype: float32
Epoch 56, train loss: 0.10735694200410521 test loss: 0.0805944678004341
0    6.912407
dtype: float32
Epoch 57, train loss: 0.08968233321344472 test loss: 0.07986129767509839
0    6.994246
dtype: float32
Epoch 58, train loss: 0.08707345235780707 test loss: 0.08131897581566677
0    7.110706
dtype: float32
Epoch 59, train loss: 0.08303359065430896 test loss: 0.07671278842167675
0    7.504239
dtype: float32
Epoch 60, train loss: 0.092979858355677 test loss: 0.09241682754774641
0    7.251283
dtype: float32
Epoch 61, train loss: 0.07841611331050533 test loss: 0.07392024828644454
0    7.485336
dtype: float32
Epoch 62, train loss: 0.08451762126925695 test loss: 0.08284949543630908
0    7.079649
dtype: float32
Epoch 63, train loss: 0.10250721831362947 test loss: 0.10684615788922162
0    7.477372
dtype: float32
Epoch 64, train loss: 0.09728837925323194 test loss: 0.10854326235114037
0    7.350721
dtype: float32
Epoch 65, train loss: 0.0805557404535429 test loss: 0.07949535166748468
0    7.257916
dtype: float32
Epoch 66, train loss: 0.08659945259343177 test loss: 0.09631479000437511
0    7.383316
dtype: float32
Epoch 67, train loss: 0.07888651686073757 test loss: 0.08399210675997724
0    7.660131
dtype: float32
Epoch 68, train loss: 0.10909085759514561 test loss: 0.10858058539098361
0    6.970243
dtype: float32
Epoch 69, train loss: 0.08346202433529441 test loss: 0.08701784692681416
0    7.444932
dtype: float32
Epoch 70, train loss: 0.08339634529121573 test loss: 0.08160482681833177
0    7.23231
dtype: float32
Epoch 71, train loss: 0.08731297604440742 test loss: 0.08444910420333797
0    7.206706
dtype: float32
Epoch 72, train loss: 0.0745765788448161 test loss: 0.08229286333603762
0    7.089286
dtype: float32
Epoch 73, train loss: 0.07984425153151431 test loss: 0.08552026167380423
0    7.018815
dtype: float32
Epoch 74, train loss: 0.0781123984362948 test loss: 0.07660396203077897
0    7.354592
dtype: float32
Epoch 75, train loss: 0.08014064400118368 test loss: 0.07932099659627553
0    6.880851
dtype: float32
Epoch 76, train loss: 0.08512978504015871 test loss: 0.07148672368270048
0    7.230707
dtype: float32
Epoch 77, train loss: 0.07773237248514742 test loss: 0.07820597016403769
0    7.226346
dtype: float32
Epoch 78, train loss: 0.07297390815855008 test loss: 0.08303526811081242
0    7.595315
dtype: float32
Epoch 79, train loss: 0.09862655293777298 test loss: 0.09779357249787024
0    7.354783
dtype: float32
Epoch 80, train loss: 0.07610083599484872 test loss: 0.07470499041813841
0    7.31271
dtype: float32
Epoch 81, train loss: 0.07369513690575974 test loss: 0.07597461440394372
0    7.487824
dtype: float32
Epoch 82, train loss: 0.0902396064331725 test loss: 0.08109248797180604
0    7.590489
dtype: float32
Epoch 83, train loss: 0.09177955387133446 test loss: 0.09209864653577036
0    7.125779
dtype: float32
Epoch 84, train loss: 0.07322643659446834 test loss: 0.08301686335017006
0    7.115633
dtype: float32
Epoch 85, train loss: 0.07606100025933041 test loss: 0.09151984058205659
0    7.27305
dtype: float32
Epoch 86, train loss: 0.07725682583506592 test loss: 0.08371717326579893
0    7.194114
dtype: float32
Epoch 87, train loss: 0.07214574080985396 test loss: 0.08295879227503239
0    7.213945
dtype: float32
Epoch 88, train loss: 0.09227989392107976 test loss: 0.09526997852810894
0    6.913987
dtype: float32
Epoch 89, train loss: 0.07927803842439513 test loss: 0.08220024197909555
0    6.789375
dtype: float32
Epoch 90, train loss: 0.12873195320939568 test loss: 0.12797990842353285
0    6.821935
dtype: float32
Epoch 91, train loss: 0.08127143052137255 test loss: 0.07723473710282175
0    7.05036
dtype: float32
Epoch 92, train loss: 0.07063750838091451 test loss: 0.07740819863012037
0    7.301456
dtype: float32
Epoch 93, train loss: 0.08089113637374871 test loss: 0.08563855755953327
0    7.262111
dtype: float32
Epoch 94, train loss: 0.0754773683543452 test loss: 0.09517015651750747
0    7.210836
dtype: float32
Epoch 95, train loss: 0.07742701281688712 test loss: 0.08564735970642443
0    7.008027
dtype: float32
Epoch 96, train loss: 0.07162092725285935 test loss: 0.0807364904668526
0    7.030243
dtype: float32
Epoch 97, train loss: 0.07000001771109221 test loss: 0.07938137324484242
0    7.044057
dtype: float32
Epoch 98, train loss: 0.07075871763674982 test loss: 0.08050503232003396
0    7.03417
dtype: float32
Epoch 99, train loss: 0.07088900903434672 test loss: 0.07458749399279621
0    6.687344
dtype: float32
Epoch 100, train loss: 0.1300630105168101 test loss: 0.12304606425465203
0    7.008218
dtype: float32
Epoch 101, train loss: 0.07265157722338801 test loss: 0.07470100937578437
0    6.283676
dtype: float32
Epoch 102, train loss: 0.14752921979665284 test loss: 0.07437006775851696
0    7.097967
dtype: float32
Epoch 103, train loss: 0.07021008221193019 test loss: 0.08354249312524453
0    7.128937
dtype: float32
Epoch 104, train loss: 0.07212628623221232 test loss: 0.08759480983033444
0    7.524541
dtype: float32
Epoch 105, train loss: 0.09888364733268476 test loss: 0.08924182931942592
0    7.12429
dtype: float32
Epoch 106, train loss: 0.06897315945585882 test loss: 0.07925507618548719
0    6.953678
dtype: float32
Epoch 107, train loss: 0.0764241928926213 test loss: 0.08803581871349178
0    7.28247
dtype: float32
Epoch 108, train loss: 0.07176843376869978 test loss: 0.08000918984960284
0    7.522125
dtype: float32
Epoch 109, train loss: 0.0889928050164238 test loss: 0.08187194116563797
0    7.322391
dtype: float32
Epoch 110, train loss: 0.07780329270639534 test loss: 0.08239247422623366
0    7.558583
dtype: float32
Epoch 111, train loss: 0.09399246850550447 test loss: 0.10000966113252203
0    7.422511
dtype: float32
Epoch 112, train loss: 0.08280695846487734 test loss: 0.10077322870003355
0    7.166693
dtype: float32
Epoch 113, train loss: 0.07188467925168557 test loss: 0.07910495326933949
0    6.839106
dtype: float32
Epoch 114, train loss: 0.07714803493529422 test loss: 0.0751721673103489
0    7.156456
dtype: float32
Epoch 115, train loss: 0.0692237438328004 test loss: 0.07764774510644169
0    7.351134
dtype: float32
Epoch 116, train loss: 0.08058299598061953 test loss: 0.07302500866967727
0    7.265703
dtype: float32
Epoch 117, train loss: 0.07512718342361582 test loss: 0.08402102171621853
0    7.116117
dtype: float32
Epoch 118, train loss: 0.06933502581246545 test loss: 0.07816898513159294
0    7.229939
dtype: float32
Epoch 119, train loss: 0.06971741877466538 test loss: 0.0810941282115937
0    7.319115
dtype: float32
Epoch 120, train loss: 0.07532705056062834 test loss: 0.08561292618146381
0    6.973175
dtype: float32
Epoch 121, train loss: 0.07318419184802102 test loss: 0.0864521150967347
0    7.150665
dtype: float32
Epoch 122, train loss: 0.06597403775949039 test loss: 0.0773084958661873
0    7.244524
dtype: float32
Epoch 123, train loss: 0.07077029920332832 test loss: 0.08255992507825337
0    7.422832
dtype: float32
Epoch 124, train loss: 0.08769048378577345 test loss: 0.10011290525896395
0    7.319128
dtype: float32
Epoch 125, train loss: 0.07614054376565559 test loss: 0.08649295008252972
0    7.012471
dtype: float32
Epoch 126, train loss: 0.07054017888686631 test loss: 0.08157645522878618
0    7.260785
dtype: float32
Epoch 127, train loss: 0.07616500514630607 test loss: 0.09319156163857595
0    6.946806
dtype: float32
Epoch 128, train loss: 0.07408634114657654 test loss: 0.07627185843947074
0    6.966295
dtype: float32
Epoch 129, train loss: 0.0817800821190589 test loss: 0.08250243735477496
0    7.205958
dtype: float32
Epoch 130, train loss: 0.06692741837171255 test loss: 0.07249418879237218
0    7.18926
dtype: float32
Epoch 131, train loss: 0.06629992733638204 test loss: 0.07963472553697493
0    7.052041
dtype: float32
Epoch 132, train loss: 0.06702633862783443 test loss: 0.07710634795094423
0    6.944834
dtype: float32
Epoch 133, train loss: 0.07717450214343967 test loss: 0.07509379962806123
0    7.108165
dtype: float32
Epoch 134, train loss: 0.06580463862059917 test loss: 0.07598803700263534
0    6.884933
dtype: float32
Epoch 135, train loss: 0.10153804592760748 test loss: 0.11067782721648392
0    7.42686
dtype: float32
Epoch 136, train loss: 0.07769458865401145 test loss: 0.0892751232118311
0    7.132007
dtype: float32
Epoch 137, train loss: 0.0714410044132041 test loss: 0.0825352989013538
0    7.218122
dtype: float32
Epoch 138, train loss: 0.0857661386790825 test loss: 0.10710121590862691
0    7.509814
dtype: float32
Epoch 139, train loss: 0.07846983048331338 test loss: 0.08026225280415973
0    7.172648
dtype: float32
Epoch 140, train loss: 0.06383106162269069 test loss: 0.0750336228679077
0    7.001448
dtype: float32
Epoch 141, train loss: 0.06600951502397782 test loss: 0.079373445301979
0    7.159811
dtype: float32
Epoch 142, train loss: 0.06616832520963005 test loss: 0.07625937847689115
0    7.081084
dtype: float32
Epoch 143, train loss: 0.06388703975115935 test loss: 0.07312266237518245
0    7.089521
dtype: float32
Epoch 144, train loss: 0.06410564835235444 test loss: 0.07974882571034482
0    7.291632
dtype: float32
Epoch 145, train loss: 0.08011497266803708 test loss: 0.09616771653941426
0    7.290117
dtype: float32
Epoch 146, train loss: 0.07596169740383332 test loss: 0.08158277326948449
0    7.338964
dtype: float32
Epoch 147, train loss: 0.0757079168589886 test loss: 0.0803152742518011
0    7.280529
dtype: float32
Epoch 148, train loss: 0.06691473100105433 test loss: 0.0755152146960345
0    7.275571
dtype: float32
Epoch 149, train loss: 0.06695469522277761 test loss: 0.0782053082945246
0    7.327227
dtype: float32
Epoch 150, train loss: 0.06803919331652673 test loss: 0.07445713550883203
0    7.216033
dtype: float32
Epoch 151, train loss: 0.06500336831357836 test loss: 0.08431346947493351
0    7.106572
dtype: float32
Epoch 152, train loss: 0.06713481924876238 test loss: 0.09147685657753353
0    6.918934
dtype: float32
Epoch 153, train loss: 0.07134934388416436 test loss: 0.07082376705838979
0    7.393733
dtype: float32
Epoch 154, train loss: 0.09143876541183753 test loss: 0.11711782961013795
0    7.268785
dtype: float32
Epoch 155, train loss: 0.07084122349085964 test loss: 0.08968151467808731
0    7.052434
dtype: float32
Epoch 156, train loss: 0.06691934167242843 test loss: 0.07758648436354977
0    7.146111
dtype: float32
Epoch 157, train loss: 0.061740141128103755 test loss: 0.0748113501589179
0    6.990759
dtype: float32
Epoch 158, train loss: 0.06608490327827861 test loss: 0.07006179999928622
0    6.994437
dtype: float32
Epoch 159, train loss: 0.07353843766432219 test loss: 0.07485098759067017
0    7.154686
dtype: float32
Epoch 160, train loss: 0.06266315646947065 test loss: 0.07493329344216863
0    7.233221
dtype: float32
Epoch 161, train loss: 0.06600766390849759 test loss: 0.08355159494078658
0    7.203251
dtype: float32
Epoch 162, train loss: 0.06680907434220625 test loss: 0.08486037860180745
0    7.012085
dtype: float32
Epoch 163, train loss: 0.064648695654224 test loss: 0.07202889097244139
0    7.090479
dtype: float32
Epoch 164, train loss: 0.06316843467738151 test loss: 0.07144519784493404
0    6.935547
dtype: float32
Epoch 165, train loss: 0.06738559650224657 test loss: 0.07029245548192277
0    7.074501
dtype: float32
Epoch 166, train loss: 0.06060466501900771 test loss: 0.07309689107240123
0    7.130464
dtype: float32
Epoch 167, train loss: 0.0633442674631107 test loss: 0.0790482428726216
0    6.995999
dtype: float32
Epoch 168, train loss: 0.06462316882072962 test loss: 0.06842651511889149
0    6.795416
dtype: float32
Epoch 169, train loss: 0.09813396020352348 test loss: 0.08630023677537768
0    7.146295
dtype: float32
Epoch 170, train loss: 0.0629040332479111 test loss: 0.07767365431575399
0    7.193401
dtype: float32
Epoch 171, train loss: 0.06375929165376835 test loss: 0.07838111256856131
0    7.285548
dtype: float32
Epoch 172, train loss: 0.06581601473354445 test loss: 0.08384681370963669
0    7.367817
dtype: float32
Epoch 173, train loss: 0.07499364273834853 test loss: 0.0961827601655029
0    6.850916
dtype: float32
Epoch 174, train loss: 0.07358180922066904 test loss: 0.08020230068727516
0    7.097656
dtype: float32
Epoch 175, train loss: 0.06512873162733747 test loss: 0.08353460333182905
0    7.365229
dtype: float32
Epoch 176, train loss: 0.07095805069699242 test loss: 0.0827456161592191
0    7.447565
dtype: float32
Epoch 177, train loss: 0.07781548474380166 test loss: 0.07720776233242903
0    7.174967
dtype: float32
Epoch 178, train loss: 0.0621380539930143 test loss: 0.08729600502749228
0    7.054729
dtype: float32
Epoch 179, train loss: 0.062440140820020355 test loss: 0.0769522574903513
0    7.214126
dtype: float32
Epoch 180, train loss: 0.06564345279631428 test loss: 0.08948258493723547
0    7.523262
dtype: float32
Epoch 181, train loss: 0.08706853439029781 test loss: 0.10579899473364576
0    7.354604
dtype: float32
Epoch 182, train loss: 0.07104028309584007 test loss: 0.07411916291296
0    7.331748
dtype: float32
Epoch 183, train loss: 0.07133864567243464 test loss: 0.09603585362784736
0    7.157581
dtype: float32
Epoch 184, train loss: 0.061952329637983514 test loss: 0.07818498818027114
0    7.209628
dtype: float32
Epoch 185, train loss: 0.06748565577186048 test loss: 0.07855935468424204
0    7.339258
dtype: float32
Epoch 186, train loss: 0.07064079694329871 test loss: 0.08873036907646573
0    6.870113
dtype: float32
Epoch 187, train loss: 0.07893249011802353 test loss: 0.07679828268126293
0    7.29167
dtype: float32
Epoch 188, train loss: 0.07395780557039296 test loss: 0.09102579305174271
0    7.329378
dtype: float32
Epoch 189, train loss: 0.06572555925791494 test loss: 0.08835907958014733
0    7.272367
dtype: float32
Epoch 190, train loss: 0.06272595618808456 test loss: 0.07320452876427898
0    6.950884
dtype: float32
Epoch 191, train loss: 0.06888318826943829 test loss: 0.07598809892853998
0    7.187083
dtype: float32
Epoch 192, train loss: 0.0651840982815708 test loss: 0.08567534620759258
0    7.080387
dtype: float32
Epoch 193, train loss: 0.06811433858809553 test loss: 0.08341835937889906
0    6.940146
dtype: float32
Epoch 194, train loss: 0.06760318663926226 test loss: 0.07219585235663091
0    7.172823
dtype: float32
Epoch 195, train loss: 0.0600154592859641 test loss: 0.07262139253307102
0    7.360619
dtype: float32
Epoch 196, train loss: 0.07482503593524861 test loss: 0.09545498484121222
0    7.337974
dtype: float32
Epoch 197, train loss: 0.06617016471919178 test loss: 0.08219050196000753
0    7.291824
dtype: float32
Epoch 198, train loss: 0.06912138753796701 test loss: 0.09394884270871254
0    7.035609
dtype: float32
Epoch 199, train loss: 0.06206615854977201 test loss: 0.07103930054543656
0    7.3447
dtype: float32
Epoch 200, train loss: 0.06729259139547507 test loss: 0.08985264295478344
0    7.128793
dtype: float32
Epoch 201, train loss: 0.05865525347276535 test loss: 0.07219449445484057
0    6.99994
dtype: float32
Epoch 202, train loss: 0.06219696061743716 test loss: 0.06707743824677832
0    7.034475
dtype: float32
Epoch 203, train loss: 0.062275528610453296 test loss: 0.07416106542231411
0    6.954096
dtype: float32
Epoch 204, train loss: 0.06429537949052057 test loss: 0.07015398908358543
0    6.911383
dtype: float32
Epoch 205, train loss: 0.0656057597281335 test loss: 0.069601745331551
0    7.083289
dtype: float32
Epoch 206, train loss: 0.058757537003780405 test loss: 0.06997016645652966
0    7.168973
dtype: float32
Epoch 207, train loss: 0.05795575729450207 test loss: 0.07407896451440808
0    7.130955
dtype: float32
Epoch 208, train loss: 0.06025853043712212 test loss: 0.0716765201316856
0    7.293624
dtype: float32
Epoch 209, train loss: 0.06145854896600595 test loss: 0.0791357332205149
0    7.052109
dtype: float32
Epoch 210, train loss: 0.06195085861264411 test loss: 0.07821789087896613
0    7.074214
dtype: float32
Epoch 211, train loss: 0.06425599733509725 test loss: 0.0800967624507564
0    7.400713
dtype: float32
Epoch 212, train loss: 0.06765962797453652 test loss: 0.08114262795181126
0    7.208864
dtype: float32
Epoch 213, train loss: 0.05876466685494526 test loss: 0.07776156164208009
0    7.277431
dtype: float32
Epoch 214, train loss: 0.06206560256068541 test loss: 0.07662263387382508
0    7.237726
dtype: float32
Epoch 215, train loss: 0.059037766170854974 test loss: 0.07851099328750658
0    7.271961
dtype: float32
Epoch 216, train loss: 0.06388123052575329 test loss: 0.06912404705831024
0    7.140312
dtype: float32
Epoch 217, train loss: 0.05832122065095617 test loss: 0.06827711390304418
0    7.235336
dtype: float32
Epoch 218, train loss: 0.06161920396791528 test loss: 0.08166110248574726
0    7.338323
dtype: float32
Epoch 219, train loss: 0.06515680721400503 test loss: 0.07044813670422752
0    7.0919
dtype: float32
Epoch 220, train loss: 0.05692668203710638 test loss: 0.07366146183742751
0    7.063481
dtype: float32
Epoch 221, train loss: 0.057967986449409425 test loss: 0.07301724555282184
0    7.598319
dtype: float32
Epoch 222, train loss: 0.08457714798320427 test loss: 0.08704532431991222
0    7.005629
dtype: float32
Epoch 223, train loss: 0.06075618296674011 test loss: 0.07130953516107277
0    7.047558
dtype: float32
Epoch 224, train loss: 0.05900611729347863 test loss: 0.07127173776381918
0    7.076594
dtype: float32
Epoch 225, train loss: 0.05791929807153469 test loss: 0.06917358347927897
0    6.956352
dtype: float32
Epoch 226, train loss: 0.08267281123947356 test loss: 0.08256658960435848
0    7.052579
dtype: float32
Epoch 227, train loss: 0.0575907174252783 test loss: 0.07275697195694468
0    7.095815
dtype: float32
Epoch 228, train loss: 0.056808132601664556 test loss: 0.0719787024124348
0    7.256495
dtype: float32
Epoch 229, train loss: 0.06189078257980929 test loss: 0.08819517319844494
0    6.949963
dtype: float32
Epoch 230, train loss: 0.06141191284012768 test loss: 0.0751442851485155
0    6.808171
dtype: float32
Epoch 231, train loss: 0.074950590087265 test loss: 0.06909508863130934
0    7.197161
dtype: float32
Epoch 232, train loss: 0.05749360441783252 test loss: 0.07346632542316084
0    7.388538
dtype: float32
Epoch 233, train loss: 0.06928782338371975 test loss: 0.07577392989854032
0    7.401003
dtype: float32
Epoch 234, train loss: 0.07707411447296973 test loss: 0.10132412136338481
0    7.190495
dtype: float32
Epoch 235, train loss: 0.05739563842112636 test loss: 0.07247579300272186
0    7.066796
dtype: float32
Epoch 236, train loss: 0.05731167542742878 test loss: 0.06775183985188753
0    7.120728
dtype: float32
Epoch 237, train loss: 0.05689160357803099 test loss: 0.07793113748408881
0    7.282901
dtype: float32
Epoch 238, train loss: 0.060117056666999874 test loss: 0.08710172258103199
0    6.957818
dtype: float32
Epoch 239, train loss: 0.07268761485135129 test loss: 0.07741386403328758
0    7.245508
dtype: float32
Epoch 240, train loss: 0.05868134492950217 test loss: 0.08177247113454615
0    7.014394
dtype: float32
Epoch 241, train loss: 0.09352751985939786 test loss: 0.09533461477927498
0    7.095919
dtype: float32
Epoch 242, train loss: 0.05766425681516509 test loss: 0.07875133213710704
0    7.180861
dtype: float32
Epoch 243, train loss: 0.06016392218893099 test loss: 0.08610581337817158
0    6.974896
dtype: float32
Epoch 244, train loss: 0.07161008343103635 test loss: 0.0858844794294002
0    6.916333
dtype: float32
Epoch 245, train loss: 0.07026989410030007 test loss: 0.07120901838306362
0    7.283934
dtype: float32
Epoch 246, train loss: 0.06183843324103611 test loss: 0.07501324653762881
0    6.996483
dtype: float32
Epoch 247, train loss: 0.07076476245352728 test loss: 0.07959072665598436
0    7.363981
dtype: float32
Epoch 248, train loss: 0.06961861597238837 test loss: 0.09448400563811836
0    6.939069
dtype: float32
Epoch 249, train loss: 0.06295977180346486 test loss: 0.07037875082621348
0    6.845065
dtype: float32
Epoch 250, train loss: 0.07996118353597241 test loss: 0.0815806929461472
0    7.043464
dtype: float32
Epoch 251, train loss: 0.06031644069176066 test loss: 0.0664271153599534
0    7.420115
dtype: float32
Epoch 252, train loss: 0.06528530206824898 test loss: 0.06923611002993675
0    6.978191
dtype: float32
Epoch 253, train loss: 0.0598659260308791 test loss: 0.0706745352793287
0    7.069645
dtype: float32
Epoch 254, train loss: 0.058409079273883134 test loss: 0.0700170791376939
0    6.995213
dtype: float32
Epoch 255, train loss: 0.06266951410937707 test loss: 0.08470463155510097
0    7.218596
dtype: float32
Epoch 256, train loss: 0.058796829855121094 test loss: 0.08071743718563207
0    7.009698
dtype: float32
Epoch 257, train loss: 0.06126849926659189 test loss: 0.08549704958309326
0    7.175368
dtype: float32
Epoch 258, train loss: 0.05555592580024978 test loss: 0.07746671305041464
0    6.966833
dtype: float32
Epoch 259, train loss: 0.06566811247307576 test loss: 0.07747134969560782
0    7.362899
dtype: float32
Epoch 260, train loss: 0.0719072095162619 test loss: 0.07776267104965089
0    7.189951
dtype: float32
Epoch 261, train loss: 0.05878248903357384 test loss: 0.08425224848589696
0    7.294667
dtype: float32
Epoch 262, train loss: 0.06148805548977115 test loss: 0.08946460535354926
0    7.041844
dtype: float32
Epoch 263, train loss: 0.06268865321979689 test loss: 0.07126894490301677
0    7.210969
dtype: float32
Epoch 264, train loss: 0.05729424715694984 test loss: 0.07638107586359535
0    7.219458
dtype: float32
Epoch 265, train loss: 0.0686132252322734 test loss: 0.07385142295229649
0    7.10536
dtype: float32
Epoch 266, train loss: 0.05557847421684658 test loss: 0.06942659845877079
0    7.256784
dtype: float32
Epoch 267, train loss: 0.06243836224545788 test loss: 0.08388629167858362
0    7.164617
dtype: float32
Epoch 268, train loss: 0.05517243800275241 test loss: 0.07722559354883243
0    7.268978
dtype: float32
Epoch 269, train loss: 0.06787792259565606 test loss: 0.07799331006229755
0    7.038863
dtype: float32
Epoch 270, train loss: 0.057649468287118005 test loss: 0.06955822151380045
0    7.144782
dtype: float32
Epoch 271, train loss: 0.05420285642742308 test loss: 0.0762853027588424
0    7.249214
dtype: float32
Epoch 272, train loss: 0.06585484506923725 test loss: 0.0683872688001765
0    7.70506
dtype: float32
Epoch 273, train loss: 0.09008800205696646 test loss: 0.08439203726101158
0    7.278885
dtype: float32
Epoch 274, train loss: 0.06803164978477982 test loss: 0.09382873374473683
0    7.326457
dtype: float32
Epoch 275, train loss: 0.06170008642116899 test loss: 0.08517240318592245
0    7.343803
dtype: float32
Epoch 276, train loss: 0.05833590879467363 test loss: 0.07195953181916488
0    7.102509
dtype: float32
Epoch 277, train loss: 0.05923963899049568 test loss: 0.07814684913686322
0    7.012033
dtype: float32
Epoch 278, train loss: 0.05524072116939035 test loss: 0.06945913806306551
0    7.234682
dtype: float32
Epoch 279, train loss: 0.07161155755131957 test loss: 0.09744086677012456
0    7.2032
dtype: float32
Epoch 280, train loss: 0.05433775559162563 test loss: 0.07398142396444199
0    7.066584
dtype: float32
Epoch 281, train loss: 0.053391113107917686 test loss: 0.07176698909798404
0    7.06946
dtype: float32
Epoch 282, train loss: 0.05483172908574735 test loss: 0.07331769938955165
0    7.151179
dtype: float32
Epoch 283, train loss: 0.05602144185509168 test loss: 0.07704585381967445
0    6.990088
dtype: float32
Epoch 284, train loss: 0.061664485266527166 test loss: 0.06674509198706859
0    7.008869
dtype: float32
Epoch 285, train loss: 0.06475257244554306 test loss: 0.07589568647858022
0    7.079492
dtype: float32
Epoch 286, train loss: 0.05366172762988438 test loss: 0.06833202531996678
0    7.083375
dtype: float32
Epoch 287, train loss: 0.05867318106680096 test loss: 0.07520719318310777
0    7.356376
dtype: float32
Epoch 288, train loss: 0.06543400968193612 test loss: 0.08269115600200566
0    7.092726
dtype: float32
Epoch 289, train loss: 0.05528913845674565 test loss: 0.0784336018248576
0    7.014864
dtype: float32
Epoch 290, train loss: 0.058053102309898734 test loss: 0.06626158744598666
0    7.090766
dtype: float32
Epoch 291, train loss: 0.053076696728055456 test loss: 0.06838068120957494
0    7.270142
dtype: float32
Epoch 292, train loss: 0.06072039262401571 test loss: 0.08155108584865564
0    6.986575
dtype: float32
Epoch 293, train loss: 0.05866734751297917 test loss: 0.07052181831689595
0    7.392977
dtype: float32
Epoch 294, train loss: 0.0724276726746113 test loss: 0.08822532413931342
0    7.157475
dtype: float32
Epoch 295, train loss: 0.05761368917007728 test loss: 0.07293080309980637
0    7.316498
dtype: float32
Epoch 296, train loss: 0.06985489806948791 test loss: 0.07962486474596879
0    7.059224
dtype: float32
Epoch 297, train loss: 0.06423459766474715 test loss: 0.07239230300324637
0    6.918298
dtype: float32
Epoch 298, train loss: 0.07163668740081253 test loss: 0.06733708346676172
0    7.141402
dtype: float32
Epoch 299, train loss: 0.05387641785433269 test loss: 0.0717605762448391
Final train loss is: 0.05387641785433269, Test loss is: 0.0717605762448391
0    7.141402
dtype: float32
round is 3
0    7.203052
dtype: float32
Epoch 17, train loss: 0.18745615931835438 test loss: 0.234825915866255
0    4.416839
dtype: float32
Epoch 21, train loss: 0.3061938569329713 test loss: 0.3958417840480005
0    6.423382
dtype: float32
Epoch 22, train loss: 0.1857624524039032 test loss: 0.22883067102190233
0    8.058689
dtype: float32
Epoch 23, train loss: 0.20769776957599256 test loss: 0.3024126513633574
0    6.961237
dtype: float32
Epoch 26, train loss: 0.17329455689689885 test loss: 0.2211359336755542
0    6.259355
dtype: float32
Epoch 27, train loss: 0.14478209258182367 test loss: 0.1903781836664327
0    6.284935
dtype: float32
Epoch 28, train loss: 0.13145806783259614 test loss: 0.18321987242934312
0    6.142499
dtype: float32
Epoch 29, train loss: 0.15723778346993164 test loss: 0.18248201838593683
0    6.279102
dtype: float32
Epoch 30, train loss: 0.14641194584096986 test loss: 0.18070377352948822
0    6.990448
dtype: float32
Epoch 31, train loss: 0.10471802870919578 test loss: 0.22428475182754568
0    7.181531
dtype: float32
Epoch 32, train loss: 0.12446667686179679 test loss: 0.24599923698754214
0    8.484949
dtype: float32
Epoch 33, train loss: 0.14843354365182848 test loss: 0.31651161427421876
0    7.531248
dtype: float32
Epoch 34, train loss: 0.10266350482540186 test loss: 0.23883206783665592
0    6.035508
dtype: float32
Epoch 35, train loss: 0.1525681134387167 test loss: 0.19853001638083548
0    6.026223
dtype: float32
Epoch 36, train loss: 0.1779800261847266 test loss: 0.20810315449939162
0    5.688573
dtype: float32
Epoch 37, train loss: 0.213639271881493 test loss: 0.2535498906750264
0    6.242021
dtype: float32
Epoch 38, train loss: 0.13916566564867364 test loss: 0.2012419113324426
0    6.551629
dtype: float32
Epoch 39, train loss: 0.1984237065364767 test loss: 0.17361761212586058
0    6.179095
dtype: float32
Epoch 40, train loss: 0.20659036978826023 test loss: 0.1988405020471332
0    5.896195
dtype: float32
Epoch 41, train loss: 0.17213650025313892 test loss: 0.23567328406093968
0    6.395349
dtype: float32
Epoch 42, train loss: 0.13790508266703191 test loss: 0.17368035061211273
0    6.958638
dtype: float32
Epoch 43, train loss: 0.1095864109932637 test loss: 0.18322264616873243
0    6.011795
dtype: float32
Epoch 44, train loss: 0.20370036810625405 test loss: 0.20346490012233936
0    6.062267
dtype: float32
Epoch 45, train loss: 0.1562538066199549 test loss: 0.21585865992819253
0    7.073322
dtype: float32
Epoch 46, train loss: 0.08861844500385342 test loss: 0.22643226161798147
0    7.345499
dtype: float32
Epoch 47, train loss: 0.09480669230890389 test loss: 0.244019850883658
0    6.776599
dtype: float32
Epoch 48, train loss: 0.09546278328396263 test loss: 0.19127657028303238
0    7.804832
dtype: float32
Epoch 49, train loss: 0.1390924386541829 test loss: 0.28134348247094787
0    7.558844
dtype: float32
Epoch 50, train loss: 0.11338448087304266 test loss: 0.2602887398231852
0    8.207006
dtype: float32
Epoch 51, train loss: 0.12144521281192477 test loss: 0.29208453463447137
0    7.355352
dtype: float32
Epoch 52, train loss: 0.08597355866373475 test loss: 0.21966545888325348
0    6.811573
dtype: float32
Epoch 53, train loss: 0.11545665309471012 test loss: 0.20584778573549312
0    7.058386
dtype: float32
Epoch 54, train loss: 0.09186929236362347 test loss: 0.22222420011164418
0    6.774566
dtype: float32
Epoch 55, train loss: 0.08392848346042249 test loss: 0.1910500330898306
0    6.645901
dtype: float32
Epoch 56, train loss: 0.08580841152278026 test loss: 0.19586843294949527
0    6.952404
dtype: float32
Epoch 57, train loss: 0.07997565906174206 test loss: 0.20191275686261068
0    7.170055
dtype: float32
Epoch 58, train loss: 0.08565148025083547 test loss: 0.22667457314825787
0    7.385379
dtype: float32
Epoch 59, train loss: 0.0877949690480641 test loss: 0.23791576988118476
0    6.958982
dtype: float32
Epoch 60, train loss: 0.07815985855624658 test loss: 0.2023618749304256
0    6.985529
dtype: float32
Epoch 61, train loss: 0.07768174765708706 test loss: 0.20324650269536573
0    6.936481
dtype: float32
Epoch 62, train loss: 0.08600971163120293 test loss: 0.2100326673296331
0    7.133578
dtype: float32
Epoch 63, train loss: 0.07838475062040692 test loss: 0.20874694456502682
0    6.540635
dtype: float32
Epoch 64, train loss: 0.18827942253537197 test loss: 0.17158192740079758
0    6.117224
dtype: float32
Epoch 65, train loss: 0.1664028430360902 test loss: 0.21597282469980977
0    6.773932
dtype: float32
Epoch 66, train loss: 0.10827002844321637 test loss: 0.2157583119928748
0    6.965889
dtype: float32
Epoch 67, train loss: 0.08459910325451632 test loss: 0.22184183765068236
0    7.201322
dtype: float32
Epoch 68, train loss: 0.07953708810671777 test loss: 0.228472921111067
0    6.805865
dtype: float32
Epoch 69, train loss: 0.08016200636599069 test loss: 0.20480970671113868
0    6.698533
dtype: float32
Epoch 70, train loss: 0.13871778176502428 test loss: 0.1838933092072869
0    6.350623
dtype: float32
Epoch 71, train loss: 0.09622992096878558 test loss: 0.19367558421635736
0    6.887279
dtype: float32
Epoch 72, train loss: 0.07958200753015926 test loss: 0.20821162767998513
0    7.072338
dtype: float32
Epoch 73, train loss: 0.10090648662623147 test loss: 0.2405061189553662
0    7.306555
dtype: float32
Epoch 74, train loss: 0.08803730821073417 test loss: 0.24239041647228957
0    6.847599
dtype: float32
Epoch 75, train loss: 0.07455083464090945 test loss: 0.2099517454191956
0    6.906966
dtype: float32
Epoch 76, train loss: 0.07457555244430039 test loss: 0.2094780296111056
0    6.59141
dtype: float32
Epoch 77, train loss: 0.08399540841548711 test loss: 0.19057053848640806
0    6.859937
dtype: float32
Epoch 78, train loss: 0.08713156062209663 test loss: 0.19617094574973074
0    6.82324
dtype: float32
Epoch 79, train loss: 0.07784232549071826 test loss: 0.20870665313280282
0    7.641354
dtype: float32
Epoch 80, train loss: 0.09774595296761733 test loss: 0.255136181240104
0    7.022914
dtype: float32
Epoch 81, train loss: 0.07649909814618595 test loss: 0.20574926404826868
0    7.382695
dtype: float32
Epoch 82, train loss: 0.13912155278131402 test loss: 0.22179320957893842
0    6.088875
dtype: float32
Epoch 83, train loss: 0.14974991379405134 test loss: 0.19855813486907184
0    6.578306
dtype: float32
Epoch 84, train loss: 0.09418835468228864 test loss: 0.18852520458828098
0    6.720057
dtype: float32
Epoch 85, train loss: 0.07891209090234134 test loss: 0.20079160058573287
0    6.767919
dtype: float32
Epoch 86, train loss: 0.07529493031578977 test loss: 0.2025861627941273
0    6.932887
dtype: float32
Epoch 87, train loss: 0.07585735173814642 test loss: 0.21314074873051084
0    8.451097
dtype: float32
Epoch 88, train loss: 0.12968576607908724 test loss: 0.3057408871475259
0    6.866167
dtype: float32
Epoch 89, train loss: 0.08495471190751265 test loss: 0.2122380960437206
0    6.748186
dtype: float32
Epoch 90, train loss: 0.10676258203814798 test loss: 0.18484060689490117
0    6.460495
dtype: float32
Epoch 91, train loss: 0.10086089045404606 test loss: 0.18036794778489543
0    6.586396
dtype: float32
Epoch 92, train loss: 0.10598080313122882 test loss: 0.1807090093448964
0    6.124743
dtype: float32
Epoch 93, train loss: 0.13258727732629547 test loss: 0.18681400694355768
0    6.723076
dtype: float32
Epoch 94, train loss: 0.15072763039391288 test loss: 0.18689148521130533
0    6.204622
dtype: float32
Epoch 95, train loss: 0.13022040274380445 test loss: 0.18583234051302724
0    6.762249
dtype: float32
Epoch 96, train loss: 0.0775010824208859 test loss: 0.19205633412195322
0    6.863578
dtype: float32
Epoch 97, train loss: 0.07375075286290396 test loss: 0.19842033580750137
0    7.488982
dtype: float32
Epoch 98, train loss: 0.10452335191278136 test loss: 0.24979418263168043
0    7.558382
dtype: float32
Epoch 99, train loss: 0.08665305299375228 test loss: 0.24599714558112032
0    6.583748
dtype: float32
Epoch 100, train loss: 0.08676674944718017 test loss: 0.1814750050173968
0    6.88657
dtype: float32
Epoch 101, train loss: 0.07066274711807684 test loss: 0.2031658548512618
0    6.796782
dtype: float32
Epoch 102, train loss: 0.0788448697325823 test loss: 0.2062312651525806
0    6.974927
dtype: float32
Epoch 103, train loss: 0.07495177458558887 test loss: 0.2173857864535068
0    6.898583
dtype: float32
Epoch 104, train loss: 0.07330535841427108 test loss: 0.20845386966711382
0    6.962488
dtype: float32
Epoch 105, train loss: 0.08396970884651273 test loss: 0.2187781064899848
0    6.987884
dtype: float32
Epoch 106, train loss: 0.07790481055590512 test loss: 0.2191563667980077
0    6.916136
dtype: float32
Epoch 107, train loss: 0.07367513554124078 test loss: 0.2137410960833542
0    6.86242
dtype: float32
Epoch 108, train loss: 0.07293136228697139 test loss: 0.20852191755251154
0    7.068557
dtype: float32
Epoch 109, train loss: 0.08298592766120304 test loss: 0.22640365321422357
0    6.739997
dtype: float32
Epoch 110, train loss: 0.0778282512751279 test loss: 0.1924583553760268
0    6.210658
dtype: float32
Epoch 111, train loss: 0.10782359376770294 test loss: 0.17800382682435922
0    6.632023
dtype: float32
Epoch 112, train loss: 0.2151848672233745 test loss: 0.18385563164411675
0    6.067547
dtype: float32
Epoch 113, train loss: 0.1004141782074757 test loss: 0.18915314295614916
0    6.189733
dtype: float32
Epoch 114, train loss: 0.1011975577301971 test loss: 0.18864794892544212
0    6.450812
dtype: float32
Epoch 115, train loss: 0.10047809665702892 test loss: 0.17936586273834748
0    6.780165
dtype: float32
Epoch 116, train loss: 0.07092431895654788 test loss: 0.2018630328461111
0    6.72116
dtype: float32
Epoch 117, train loss: 0.07493864360539701 test loss: 0.20562107500459537
0    6.449545
dtype: float32
Epoch 118, train loss: 0.10414890807175282 test loss: 0.21491353484981868
0    6.705991
dtype: float32
Epoch 119, train loss: 0.06984563729967866 test loss: 0.20468181205255248
0    6.820341
dtype: float32
Epoch 120, train loss: 0.12043373533913447 test loss: 0.20083547309579228
0    6.987575
dtype: float32
Epoch 121, train loss: 0.07742569196140403 test loss: 0.22329585668664476
0    6.718216
dtype: float32
Epoch 122, train loss: 0.07814127300838727 test loss: 0.19826680891713078
0    6.395034
dtype: float32
Epoch 123, train loss: 0.07790497968216556 test loss: 0.1986177273392689
0    7.170615
dtype: float32
Epoch 124, train loss: 0.0877758467923061 test loss: 0.217941027383951
0    6.643651
dtype: float32
Epoch 125, train loss: 0.07321175354538767 test loss: 0.2048882743861898
0    7.057459
dtype: float32
Epoch 126, train loss: 0.06895792106294497 test loss: 0.22143636431178185
0    6.665036
dtype: float32
Epoch 127, train loss: 0.0851521172803137 test loss: 0.21844116437647668
0    7.549079
dtype: float32
Epoch 128, train loss: 0.07716476196558121 test loss: 0.2432952262635048
0    7.810874
dtype: float32
Epoch 129, train loss: 0.08422278715741258 test loss: 0.2631758362526645
0    7.634031
dtype: float32
Epoch 130, train loss: 0.08069476402237787 test loss: 0.24864221577884488
0    6.81987
dtype: float32
Epoch 131, train loss: 0.0769084820289785 test loss: 0.2057974637408961
0    6.862914
dtype: float32
Epoch 132, train loss: 0.1154776490271186 test loss: 0.20236560166337236
0    6.306062
dtype: float32
Epoch 133, train loss: 0.24771346423010274 test loss: 0.19760688497000511
0    6.00177
dtype: float32
Epoch 134, train loss: 0.10195947509239674 test loss: 0.19819852601859173
0    6.633174
dtype: float32
Epoch 135, train loss: 0.07154437869145118 test loss: 0.2048350395939784
0    7.144277
dtype: float32
Epoch 136, train loss: 0.10845789357272385 test loss: 0.24222026402555671
0    6.675496
dtype: float32
Epoch 137, train loss: 0.07060915733289012 test loss: 0.20215295029565816
0    5.847745
dtype: float32
Epoch 138, train loss: 0.13706496837062396 test loss: 0.20204103799626982
0    6.300223
dtype: float32
Epoch 139, train loss: 0.10507146955687133 test loss: 0.22461287227325918
0    7.504502
dtype: float32
Epoch 140, train loss: 0.12403987770815347 test loss: 0.26448925488892494
0    7.137625
dtype: float32
Epoch 141, train loss: 0.07225589171149939 test loss: 0.2260358890026671
0    7.470992
dtype: float32
Epoch 142, train loss: 0.09582189285055819 test loss: 0.24902903075181418
0    6.729518
dtype: float32
Epoch 143, train loss: 0.09355433943599582 test loss: 0.1954421855634569
0    6.820693
dtype: float32
Epoch 144, train loss: 0.07859168153431599 test loss: 0.2194405233388803
0    6.907526
dtype: float32
Epoch 145, train loss: 0.06754714863998755 test loss: 0.21437417142999712
0    7.305527
dtype: float32
Epoch 146, train loss: 0.07383247517766901 test loss: 0.23530796611116495
0    6.681786
dtype: float32
Epoch 147, train loss: 0.07450689034514905 test loss: 0.20111826171049044
0    6.811653
dtype: float32
Epoch 148, train loss: 0.09195142766495357 test loss: 0.2005951596553808
0    6.694563
dtype: float32
Epoch 149, train loss: 0.08680564394048464 test loss: 0.1960420559180262
0    6.511909
dtype: float32
Epoch 150, train loss: 0.07521872165847807 test loss: 0.19684916034308947
0    7.103723
dtype: float32
Epoch 151, train loss: 0.08346628659152569 test loss: 0.23000415318141548
0    7.609602
dtype: float32
Epoch 152, train loss: 0.1207038392058983 test loss: 0.26102412745809545
0    7.170671
dtype: float32
Epoch 153, train loss: 0.06901616587425266 test loss: 0.21924975678962058
0    6.895147
dtype: float32
Epoch 154, train loss: 0.06716739489134971 test loss: 0.20978149366003868
0    6.755216
dtype: float32
Epoch 155, train loss: 0.06813707273261818 test loss: 0.2000591303601301
0    6.880757
dtype: float32
Epoch 156, train loss: 0.07199066292092707 test loss: 0.2098574346131686
0    7.017258
dtype: float32
Epoch 157, train loss: 0.06705764305192917 test loss: 0.21183704620835042
0    6.553088
dtype: float32
Epoch 158, train loss: 0.09445332837059031 test loss: 0.18280785846866826
0    6.749762
dtype: float32
Epoch 159, train loss: 0.06859967438382154 test loss: 0.20090097970245197
0    7.185873
dtype: float32
Epoch 160, train loss: 0.06823087388453673 test loss: 0.2193895212922376
0    6.842405
dtype: float32
Epoch 161, train loss: 0.08287421373195858 test loss: 0.22253781142323262
0    7.281269
dtype: float32
Epoch 162, train loss: 0.07609922416782784 test loss: 0.22180569006610393
0    6.752461
dtype: float32
Epoch 163, train loss: 0.06584267523093285 test loss: 0.20928231920208257
0    6.483616
dtype: float32
Epoch 164, train loss: 0.0944703850717478 test loss: 0.18776620405345462
0    6.603722
dtype: float32
Epoch 165, train loss: 0.08297188279454101 test loss: 0.19208056601235146
0    6.774252
dtype: float32
Epoch 166, train loss: 0.08574489565904522 test loss: 0.1998235601850139
0    6.760794
dtype: float32
Epoch 167, train loss: 0.06646672615906543 test loss: 0.20322675743027535
0    7.209846
dtype: float32
Epoch 168, train loss: 0.0730084159911855 test loss: 0.23311665352765462
0    6.88417
dtype: float32
Epoch 169, train loss: 0.06968389232121265 test loss: 0.20898678877187574
0    6.404682
dtype: float32
Epoch 170, train loss: 0.08977634511476469 test loss: 0.19231510260046142
0    5.897046
dtype: float32
Epoch 171, train loss: 0.12171773712806881 test loss: 0.19428572753950915
0    6.036031
dtype: float32
Epoch 172, train loss: 0.2122064978735849 test loss: 0.1835420439594904
0    6.607203
dtype: float32
Epoch 173, train loss: 0.0714281854762499 test loss: 0.20273434529015602
0    7.09141
dtype: float32
Epoch 174, train loss: 0.07563343089042848 test loss: 0.22611700383584518
0    6.791044
dtype: float32
Epoch 175, train loss: 0.06608818815855318 test loss: 0.20185590266127007
0    6.333905
dtype: float32
Epoch 176, train loss: 0.14738075520232974 test loss: 0.1733293900897135
0    6.794425
dtype: float32
Epoch 177, train loss: 0.08821207791450336 test loss: 0.18572216767352406
0    6.460451
dtype: float32
Epoch 178, train loss: 0.1906879324458421 test loss: 0.18718016936311668
0    6.677089
dtype: float32
Epoch 179, train loss: 0.06987316899459242 test loss: 0.19176270823300512
0    7.100539
dtype: float32
Epoch 180, train loss: 0.06860443474724952 test loss: 0.2027921227079118
0    6.731924
dtype: float32
Epoch 181, train loss: 0.0755468758637207 test loss: 0.18134151024830752
0    6.567462
dtype: float32
Epoch 182, train loss: 0.13638909313708059 test loss: 0.17486807647715846
0    6.787732
dtype: float32
Epoch 183, train loss: 0.09535910032482094 test loss: 0.19224719914641472
0    6.85269
dtype: float32
Epoch 184, train loss: 0.06518470948604654 test loss: 0.20387148198194494
0    6.943796
dtype: float32
Epoch 185, train loss: 0.0708363787269016 test loss: 0.20558216078950975
0    6.274532
dtype: float32
Epoch 186, train loss: 0.1061522172644413 test loss: 0.18070076668628085
0    6.568645
dtype: float32
Epoch 187, train loss: 0.0969407187376043 test loss: 0.19222949005539175
0    6.656921
dtype: float32
Epoch 188, train loss: 0.09429184780261225 test loss: 0.1935265150783775
0    6.608303
dtype: float32
Epoch 189, train loss: 0.11904506850318838 test loss: 0.19287599276547956
0    6.434274
dtype: float32
Epoch 190, train loss: 0.09231793026947838 test loss: 0.18733283504965928
0    6.820582
dtype: float32
Epoch 191, train loss: 0.07339552291554556 test loss: 0.20353029411915327
0    6.785527
dtype: float32
Epoch 192, train loss: 0.07281664774256859 test loss: 0.20964333239854993
0    6.974207
dtype: float32
Epoch 193, train loss: 0.06438319109780272 test loss: 0.20688413148859605
0    7.013526
dtype: float32
Epoch 194, train loss: 0.0645448315181801 test loss: 0.2044927471339047
0    6.589917
dtype: float32
Epoch 195, train loss: 0.0717094671354443 test loss: 0.1947542907147335
0    7.430418
dtype: float32
Epoch 196, train loss: 0.08732355296426039 test loss: 0.2466325233690408
0    7.410897
dtype: float32
Epoch 197, train loss: 0.07261733614354823 test loss: 0.22937793514814225
0    6.970175
dtype: float32
Epoch 198, train loss: 0.0860058964046817 test loss: 0.19486266042349723
0    6.495834
dtype: float32
Epoch 199, train loss: 0.08186219657449734 test loss: 0.19501330135967213
0    6.076993
dtype: float32
Epoch 200, train loss: 0.1482348720733961 test loss: 0.1886262963119284
0    6.158253
dtype: float32
Epoch 201, train loss: 0.16043343411832064 test loss: 0.19171475666269092
0    6.42967
dtype: float32
Epoch 202, train loss: 0.10579722156605331 test loss: 0.1835303732231029
0    7.128881
dtype: float32
Epoch 203, train loss: 0.06516473168225981 test loss: 0.21162070120817975
0    6.565583
dtype: float32
Epoch 204, train loss: 0.07070589939185916 test loss: 0.19725392651322068
0    6.84164
dtype: float32
Epoch 205, train loss: 0.06878225217977711 test loss: 0.20136021923284814
0    6.963148
dtype: float32
Epoch 206, train loss: 0.06449553632057102 test loss: 0.20760792307707834
0    6.412079
dtype: float32
Epoch 207, train loss: 0.07960665275585435 test loss: 0.20022298403711733
0    7.096236
dtype: float32
Epoch 208, train loss: 0.0742815887637379 test loss: 0.23179019220746752
0    7.109275
dtype: float32
Epoch 209, train loss: 0.07385666884216391 test loss: 0.23452992455381386
0    7.057265
dtype: float32
Epoch 210, train loss: 0.0772394161040013 test loss: 0.20959589738351886
0    6.936111
dtype: float32
Epoch 211, train loss: 0.0710298254125611 test loss: 0.21871844759668685
0    7.742882
dtype: float32
Epoch 212, train loss: 0.08021268887100441 test loss: 0.24883512858853984
0    6.474771
dtype: float32
Epoch 213, train loss: 0.0861167717044438 test loss: 0.1816591176764403
0    6.774631
dtype: float32
Epoch 214, train loss: 0.0748098237713346 test loss: 0.1838597130136748
0    6.841645
dtype: float32
Epoch 215, train loss: 0.1225624997329845 test loss: 0.18317843255700134
0    6.421036
dtype: float32
Epoch 216, train loss: 0.08565439564517832 test loss: 0.18808663267970466
0    6.565879
dtype: float32
Epoch 217, train loss: 0.07724093509378481 test loss: 0.18955155711763985
0    6.953131
dtype: float32
Epoch 218, train loss: 0.07688420006836387 test loss: 0.21659891379381063
0    6.634004
dtype: float32
Epoch 219, train loss: 0.06848334522655615 test loss: 0.19142779793410208
0    7.090624
dtype: float32
Epoch 220, train loss: 0.08034230288813136 test loss: 0.19878290802384385
0    7.208225
dtype: float32
Epoch 221, train loss: 0.06751865686831068 test loss: 0.209687465338884
0    7.008614
dtype: float32
Epoch 222, train loss: 0.06358917008703388 test loss: 0.2076129880985597
0    6.902762
dtype: float32
Epoch 223, train loss: 0.06660441542501629 test loss: 0.21429130527784118
0    7.227455
dtype: float32
Epoch 224, train loss: 0.07796807037659233 test loss: 0.23539360488961056
0    6.806728
dtype: float32
Epoch 225, train loss: 0.062371870511395956 test loss: 0.20469726686329986
0    7.342172
dtype: float32
Epoch 226, train loss: 0.10975642418476127 test loss: 0.25675291529188826
0    7.082425
dtype: float32
Epoch 227, train loss: 0.06501111122869778 test loss: 0.22320916306203362
0    6.746254
dtype: float32
Epoch 228, train loss: 0.07524549227088483 test loss: 0.2130828799786069
0    7.014918
dtype: float32
Epoch 229, train loss: 0.07706358816341168 test loss: 0.22621598511861546
0    7.733532
dtype: float32
Epoch 230, train loss: 0.10415991978796979 test loss: 0.25672292492168053
0    6.80517
dtype: float32
Epoch 231, train loss: 0.061597611435200685 test loss: 0.1958391786039722
0    6.96451
dtype: float32
Epoch 232, train loss: 0.06599811522516763 test loss: 0.21508649190571774
0    6.711388
dtype: float32
Epoch 233, train loss: 0.06437919794038933 test loss: 0.19615146701838934
0    7.35694
dtype: float32
Epoch 234, train loss: 0.07087284360130053 test loss: 0.21397592887468736
0    6.766539
dtype: float32
Epoch 235, train loss: 0.08079314964311711 test loss: 0.18292988428968956
0    6.821557
dtype: float32
Epoch 236, train loss: 0.08491424551394533 test loss: 0.18914321828970201
0    7.180588
dtype: float32
Epoch 237, train loss: 0.06680018498094244 test loss: 0.20495079581214337
0    6.531723
dtype: float32
Epoch 238, train loss: 0.087069917934513 test loss: 0.17545931777385823
0    6.930891
dtype: float32
Epoch 239, train loss: 0.0676726114453915 test loss: 0.2010251250204986
0    7.24786
dtype: float32
Epoch 240, train loss: 0.07423070668626414 test loss: 0.22185363666682348
0    7.386627
dtype: float32
Epoch 241, train loss: 0.1572118128092974 test loss: 0.2769919662078874
0    7.116578
dtype: float32
Epoch 242, train loss: 0.06875922492527299 test loss: 0.21794250134496718
0    7.701842
dtype: float32
Epoch 243, train loss: 0.11498037175113585 test loss: 0.2617135430212831
0    6.767223
dtype: float32
Epoch 244, train loss: 0.0889484552407908 test loss: 0.2081254155827258
0    7.310437
dtype: float32
Epoch 245, train loss: 0.0735842947406623 test loss: 0.22261847600934698
0    7.001522
dtype: float32
Epoch 246, train loss: 0.07187690426815728 test loss: 0.21318110859503037
0    6.663902
dtype: float32
Epoch 247, train loss: 0.06550240741978526 test loss: 0.18312413556165746
0    6.731426
dtype: float32
Epoch 248, train loss: 0.07834887501336868 test loss: 0.17734327734130875
0    6.696036
dtype: float32
Epoch 249, train loss: 0.06509962233360524 test loss: 0.18758385774036268
0    6.949134
dtype: float32
Epoch 250, train loss: 0.06618079541899091 test loss: 0.19171615081099927
0    6.93085
dtype: float32
Epoch 251, train loss: 0.09385088795891483 test loss: 0.23513528217098953
0    6.774123
dtype: float32
Epoch 252, train loss: 0.0680485915898126 test loss: 0.20948013818338132
0    7.06403
dtype: float32
Epoch 253, train loss: 0.061360688728552604 test loss: 0.2066967714162789
0    6.627362
dtype: float32
Epoch 254, train loss: 0.06509501289129407 test loss: 0.18408515327870462
0    6.736486
dtype: float32
Epoch 255, train loss: 0.07277894554326933 test loss: 0.18102473888066037
0    6.468081
dtype: float32
Epoch 256, train loss: 0.09231764482581835 test loss: 0.16970939297553764
0    6.695538
dtype: float32
Epoch 257, train loss: 0.08940396774175706 test loss: 0.17690700968543957
0    5.786152
dtype: float32
Epoch 258, train loss: 0.13189111220562538 test loss: 0.19273601277125335
0    6.650283
dtype: float32
Epoch 259, train loss: 0.11015674324679894 test loss: 0.17262346029472705
0    6.967396
dtype: float32
Epoch 260, train loss: 0.15965294158623541 test loss: 0.1859397081583969
0    6.56578
dtype: float32
Epoch 261, train loss: 0.09646102131679442 test loss: 0.22089017094303545
0    6.546357
dtype: float32
Epoch 262, train loss: 0.09240500375784441 test loss: 0.20700093021760915
0    6.826785
dtype: float32
Epoch 263, train loss: 0.08315787624947268 test loss: 0.21012385384916993
0    6.437649
dtype: float32
Epoch 264, train loss: 0.07939638120968343 test loss: 0.1713333355626748
0    6.830887
dtype: float32
Epoch 265, train loss: 0.07114178792446225 test loss: 0.1874463590219902
0    6.43279
dtype: float32
Epoch 266, train loss: 0.08078131769599396 test loss: 0.1718571922896747
0    6.393748
dtype: float32
Epoch 267, train loss: 0.11124675450477778 test loss: 0.16573306576493918
0    6.589949
dtype: float32
Epoch 268, train loss: 0.06571100951738885 test loss: 0.17488787364563702
0    6.88757
dtype: float32
Epoch 269, train loss: 0.06833103825938981 test loss: 0.18241670760917775
0    6.712956
dtype: float32
Epoch 270, train loss: 0.08273319511810263 test loss: 0.17598307840551158
0    6.459536
dtype: float32
Epoch 271, train loss: 0.07502759793792385 test loss: 0.17723393762912673
0    6.762287
dtype: float32
Epoch 272, train loss: 0.0764349098638439 test loss: 0.17685644931150543
0    6.792849
dtype: float32
Epoch 273, train loss: 0.0631805734479617 test loss: 0.18942885509900562
0    6.374819
dtype: float32
Epoch 274, train loss: 0.07529304291378225 test loss: 0.18249729041719456
0    6.79861
dtype: float32
Epoch 275, train loss: 0.08001817998610987 test loss: 0.18682758827737034
0    6.310924
dtype: float32
Epoch 276, train loss: 0.12969167311974628 test loss: 0.1782543230699015
0    6.565234
dtype: float32
Epoch 277, train loss: 0.09493692835173118 test loss: 0.18065856143829712
0    6.73283
dtype: float32
Epoch 278, train loss: 0.0750258376137568 test loss: 0.18464303725755002
0    7.047462
dtype: float32
Epoch 279, train loss: 0.06218271531184463 test loss: 0.20386312328292228
0    6.603979
dtype: float32
Epoch 280, train loss: 0.07013438010796924 test loss: 0.1748391982987352
0    6.966612
dtype: float32
Epoch 281, train loss: 0.06959584967045176 test loss: 0.20417542457576493
0    7.090939
dtype: float32
Epoch 282, train loss: 0.08050844970457191 test loss: 0.18980657400657527
0    6.53725
dtype: float32
Epoch 283, train loss: 0.07807716109591271 test loss: 0.1881460070233151
0    6.544884
dtype: float32
Epoch 284, train loss: 0.10037211212886454 test loss: 0.16927099724683148
0    6.374572
dtype: float32
Epoch 285, train loss: 0.14402341439388786 test loss: 0.163878901726807
0    6.59356
dtype: float32
Epoch 286, train loss: 0.06617442905562841 test loss: 0.17626095283880663
0    6.992092
dtype: float32
Epoch 287, train loss: 0.08726495422326926 test loss: 0.18110150660095156
0    7.092521
dtype: float32
Epoch 288, train loss: 0.06069370206199965 test loss: 0.1920914037142662
0    7.046457
dtype: float32
Epoch 289, train loss: 0.07109415242846266 test loss: 0.2032976906788392
0    7.067535
dtype: float32
Epoch 290, train loss: 0.11532866051730671 test loss: 0.17516669744913835
0    7.429218
dtype: float32
Epoch 291, train loss: 0.06896011377940456 test loss: 0.2132529439063311
0    7.319608
dtype: float32
Epoch 292, train loss: 0.1065992184869207 test loss: 0.2371743693538574
0    7.299411
dtype: float32
Epoch 293, train loss: 0.07842499405904864 test loss: 0.2204161442550669
0    7.413626
dtype: float32
Epoch 294, train loss: 0.11414128932899036 test loss: 0.2407002663118822
0    7.589733
dtype: float32
Epoch 295, train loss: 0.08019091751033923 test loss: 0.23366603770256003
0    6.608812
dtype: float32
Epoch 296, train loss: 0.12494969108486957 test loss: 0.16555836917892752
0    6.722506
dtype: float32
Epoch 297, train loss: 0.0875082772147483 test loss: 0.16627912555318838
0    6.608104
dtype: float32
Epoch 298, train loss: 0.07473836319855132 test loss: 0.16982617830692043
0    7.162264
dtype: float32
Epoch 299, train loss: 0.08971027436990864 test loss: 0.22682648111047127
Final train loss is: 0.08971027436990864, Test loss is: 0.22682648111047127
0    7.162264
dtype: float32
round is 4
0    9.800822
dtype: float32
Epoch 4, train loss: 0.35144082267062665 test loss: 0.43583903126195683
0    7.603773
dtype: float32
Epoch 6, train loss: 0.3853304061477422 test loss: 0.4724123225373091
0    7.298825
dtype: float32
Epoch 7, train loss: 0.24385976855173863 test loss: 0.4408498682209088
0    7.421014
dtype: float32
Epoch 8, train loss: 0.20208181393418345 test loss: 0.4193570252424163
0    7.1032
dtype: float32
Epoch 9, train loss: 0.15891474352428453 test loss: 0.3906172773702081
0    4.956137
dtype: float32
Epoch 11, train loss: 0.32510693601654045 test loss: 0.39658739820040184
0    5.338267
dtype: float32
Epoch 12, train loss: 0.29697400922686096 test loss: 0.371587991617206
0    6.686519
dtype: float32
Epoch 13, train loss: 0.1790470047419558 test loss: 0.35674855859670906
0    7.085223
dtype: float32
Epoch 14, train loss: 0.18187821312099886 test loss: 0.37795205228433487
0    6.298063
dtype: float32
Epoch 15, train loss: 0.22311156997181095 test loss: 0.341214744522039
0    8.841268
dtype: float32
Epoch 16, train loss: 0.2073650075329344 test loss: 0.3905415720942137
0    7.268241
dtype: float32
Epoch 17, train loss: 0.1606056890181753 test loss: 0.3636001646468114
0    6.374034
dtype: float32
Epoch 18, train loss: 0.1809778458374926 test loss: 0.3521923326126814
0    7.169604
dtype: float32
Epoch 19, train loss: 0.140427130085348 test loss: 0.3579886576003457
0    7.657838
dtype: float32
Epoch 20, train loss: 0.10852300613831153 test loss: 0.3629124754191272
0    7.831258
dtype: float32
Epoch 21, train loss: 0.12415295764949703 test loss: 0.3543652130506329
0    8.049113
dtype: float32
Epoch 22, train loss: 0.13444254752117862 test loss: 0.3986229558433545
0    6.961792
dtype: float32
Epoch 23, train loss: 0.14604662353327635 test loss: 0.33996438102630167
0    8.029772
dtype: float32
Epoch 24, train loss: 0.11047463308171578 test loss: 0.3280496993699783
0    8.285044
dtype: float32
Epoch 25, train loss: 0.15496251564588262 test loss: 0.35694674535561766
0    7.320733
dtype: float32
Epoch 26, train loss: 0.09966940630808284 test loss: 0.36059427723583803
0    7.036839
dtype: float32
Epoch 27, train loss: 0.11162033829088873 test loss: 0.348777445627301
0    7.256503
dtype: float32
Epoch 28, train loss: 0.09182115598920994 test loss: 0.34758424199291554
0    6.499102
dtype: float32
Epoch 29, train loss: 0.12565521879650202 test loss: 0.33355447393839355
0    7.219505
dtype: float32
Epoch 30, train loss: 0.09328150892688376 test loss: 0.3372756509783672
0    6.651055
dtype: float32
Epoch 31, train loss: 0.11418377205780969 test loss: 0.33428979811715104
0    6.452664
dtype: float32
Epoch 32, train loss: 0.16029945797174633 test loss: 0.3360980655188038
0    7.289833
dtype: float32
Epoch 33, train loss: 0.0951076580713047 test loss: 0.33833836761492786
0    7.02298
dtype: float32
Epoch 34, train loss: 0.09798277865351396 test loss: 0.3275439325570453
0    6.877053
dtype: float32
Epoch 35, train loss: 0.10705166774740911 test loss: 0.3215629487958641
0    6.790771
dtype: float32
Epoch 36, train loss: 0.09852813525360332 test loss: 0.3320066536216698
0    7.118026
dtype: float32
Epoch 37, train loss: 0.09290966736239975 test loss: 0.29416968768056684
0    7.036687
dtype: float32
Epoch 38, train loss: 0.0975577377555912 test loss: 0.3116094005198935
0    7.466264
dtype: float32
Epoch 39, train loss: 0.0968924598956877 test loss: 0.281840288311126
0    7.199183
dtype: float32
Epoch 40, train loss: 0.08982437239073983 test loss: 0.2754505646147641
0    7.078402
dtype: float32
Epoch 41, train loss: 0.08501515767082837 test loss: 0.27495875254581303
0    6.750986
dtype: float32
Epoch 42, train loss: 0.08930912478155273 test loss: 0.29415358002067604
0    5.896009
dtype: float32
Epoch 43, train loss: 0.20046328668191396 test loss: 0.3408699985461402
0    7.045549
dtype: float32
Epoch 44, train loss: 0.08390028816749415 test loss: 0.3061705128640245
0    7.310576
dtype: float32
Epoch 45, train loss: 0.0917525745218282 test loss: 0.28153227979000783
0    6.849323
dtype: float32
Epoch 46, train loss: 0.08276963019277886 test loss: 0.27891111441364186
0    6.515392
dtype: float32
Epoch 47, train loss: 0.11981476503591924 test loss: 0.3017164583739614
0    6.346699
dtype: float32
Epoch 48, train loss: 0.1263751134308431 test loss: 0.30188184088805603
0    6.586006
dtype: float32
Epoch 49, train loss: 0.09153625468457317 test loss: 0.2729601095814137
0    6.693767
dtype: float32
Epoch 50, train loss: 0.09516156599199113 test loss: 0.26438162121011033
0    6.549109
dtype: float32
Epoch 51, train loss: 0.10091134572737952 test loss: 0.2842067275806597
0    6.399308
dtype: float32
Epoch 52, train loss: 0.10006170564994128 test loss: 0.29471198744414373
0    7.246973
dtype: float32
Epoch 53, train loss: 0.09083916339494949 test loss: 0.25991802568107686
0    6.700207
dtype: float32
Epoch 54, train loss: 0.08726319270520475 test loss: 0.27567780299053907
0    6.620231
dtype: float32
Epoch 55, train loss: 0.08754124852296451 test loss: 0.2935070267517406
0    6.919039
dtype: float32
Epoch 56, train loss: 0.079906980996392 test loss: 0.2659433447248465
0    6.756869
dtype: float32
Epoch 57, train loss: 0.08035040853481028 test loss: 0.2690009095638021
0    6.878498
dtype: float32
Epoch 58, train loss: 0.0771931538359399 test loss: 0.25135552183421017
0    7.09517
dtype: float32
Epoch 59, train loss: 0.08417990066439841 test loss: 0.24671279692023243
0    7.641324
dtype: float32
Epoch 60, train loss: 0.11130827976073696 test loss: 0.2714711831356886
0    7.587213
dtype: float32
Epoch 61, train loss: 0.13071336054073884 test loss: 0.2855711104963764
0    7.023018
dtype: float32
Epoch 62, train loss: 0.08681683914287129 test loss: 0.25237314302626374
0    6.425749
dtype: float32
Epoch 63, train loss: 0.09661942529976363 test loss: 0.25575945302704406
0    5.976535
dtype: float32
Epoch 64, train loss: 0.14556521863558716 test loss: 0.28911384137426344
0    6.319458
dtype: float32
Epoch 65, train loss: 0.12768558864203175 test loss: 0.27245945450631587
0    7.116397
dtype: float32
Epoch 66, train loss: 0.07919259883850356 test loss: 0.24698626344672678
0    7.175126
dtype: float32
Epoch 67, train loss: 0.08423697725183978 test loss: 0.2573122369766768
0    6.461167
dtype: float32
Epoch 68, train loss: 0.08825074065332594 test loss: 0.2609663174667443
0    6.642446
dtype: float32
Epoch 69, train loss: 0.09150220302313754 test loss: 0.24566730719862437
0    6.474932
dtype: float32
Epoch 70, train loss: 0.11596161096870668 test loss: 0.24550082643974785
0    7.29453
dtype: float32
Epoch 71, train loss: 0.08456724028445457 test loss: 0.2537866225653412
0    7.150427
dtype: float32
Epoch 72, train loss: 0.07857622842801171 test loss: 0.23503030818617326
0    7.413292
dtype: float32
Epoch 73, train loss: 0.09467087597581281 test loss: 0.2512169181738013
0    7.032192
dtype: float32
Epoch 74, train loss: 0.07617823359298609 test loss: 0.22755098520618497
0    6.884257
dtype: float32
Epoch 75, train loss: 0.08182648842709661 test loss: 0.23078334819222004
0    7.598763
dtype: float32
Epoch 76, train loss: 0.11688508750099282 test loss: 0.2638457048375193
0    6.802849
dtype: float32
Epoch 77, train loss: 0.07641703372608737 test loss: 0.2245905468903481
0    6.624185
dtype: float32
Epoch 78, train loss: 0.09200085982612695 test loss: 0.23821693059192142
0    6.282732
dtype: float32
Epoch 79, train loss: 0.12763447522806254 test loss: 0.24385870853065975
0    7.189023
dtype: float32
Epoch 80, train loss: 0.07780262741129194 test loss: 0.23265067795919386
0    6.789977
dtype: float32
Epoch 81, train loss: 0.07910106279538799 test loss: 0.23121351494165196
0    7.236582
dtype: float32
Epoch 82, train loss: 0.0907867006755689 test loss: 0.2352229789911791
0    6.712403
dtype: float32
Epoch 83, train loss: 0.0835294619850023 test loss: 0.23617293483750632
0    6.553536
dtype: float32
Epoch 84, train loss: 0.11740670566067746 test loss: 0.22964514954148435
0    6.533985
dtype: float32
Epoch 85, train loss: 0.08168091885567692 test loss: 0.22156319621018294
0    6.646836
dtype: float32
Epoch 86, train loss: 0.08421556456138075 test loss: 0.21540689502077637
0    7.113659
dtype: float32
Epoch 87, train loss: 0.07981885038707175 test loss: 0.22843814141974939
0    7.103196
dtype: float32
Epoch 88, train loss: 0.08065241698848243 test loss: 0.2298057309221226
0    7.009398
dtype: float32
Epoch 89, train loss: 0.0735672482702839 test loss: 0.22988122513831177
0    6.998662
dtype: float32
Epoch 90, train loss: 0.08197058631133193 test loss: 0.22644342245980772
0    7.340788
dtype: float32
Epoch 91, train loss: 0.08736880297356622 test loss: 0.24113102842485987
0    6.190901
dtype: float32
Epoch 92, train loss: 0.12277293676478676 test loss: 0.23895694487495125
0    6.726254
dtype: float32
Epoch 93, train loss: 0.07442397804980963 test loss: 0.2081421882063944
0    7.024621
dtype: float32
Epoch 94, train loss: 0.07606588755786835 test loss: 0.2157691060836782
0    6.872636
dtype: float32
Epoch 95, train loss: 0.07206108916776079 test loss: 0.20703948079390322
0    6.704051
dtype: float32
Epoch 96, train loss: 0.07270614473840731 test loss: 0.2085876692553538
0    6.870551
dtype: float32
Epoch 97, train loss: 0.07050793796944707 test loss: 0.216874305496018
0    6.831455
dtype: float32
Epoch 98, train loss: 0.07292026807261578 test loss: 0.21726007372045628
0    6.595063
dtype: float32
Epoch 99, train loss: 0.07884478617755451 test loss: 0.20892099450471
0    6.859963
dtype: float32
Epoch 100, train loss: 0.07097001524359235 test loss: 0.21214671810554928
0    7.863567
dtype: float32
Epoch 101, train loss: 0.15655551154626166 test loss: 0.2757756587699204
0    7.236137
dtype: float32
Epoch 102, train loss: 0.08411540871780296 test loss: 0.23224423557272936
0    6.81471
dtype: float32
Epoch 103, train loss: 0.07595303666322556 test loss: 0.21763600236836086
0    6.985941
dtype: float32
Epoch 104, train loss: 0.07674263926419432 test loss: 0.21891974266668607
0    6.528357
dtype: float32
Epoch 105, train loss: 0.08424028048198783 test loss: 0.20746564098062117
0    6.415412
dtype: float32
Epoch 106, train loss: 0.08343065209300922 test loss: 0.20630380515786695
0    6.30856
dtype: float32
Epoch 107, train loss: 0.1089909745646714 test loss: 0.2131263595563597
0    6.791078
dtype: float32
Epoch 108, train loss: 0.07079055850795557 test loss: 0.21870846461580587
0    6.746926
dtype: float32
Epoch 109, train loss: 0.07020318752942335 test loss: 0.20787442442939286
0    6.852783
dtype: float32
Epoch 110, train loss: 0.07232443097648375 test loss: 0.21614622294653507
0    6.738798
dtype: float32
Epoch 111, train loss: 0.07270012541646681 test loss: 0.21231035681101573
0    7.146834
dtype: float32
Epoch 112, train loss: 0.0784832740174936 test loss: 0.22809717164002577
0    7.28899
dtype: float32
Epoch 113, train loss: 0.08868802102943532 test loss: 0.23738076764985283
0    7.009275
dtype: float32
Epoch 114, train loss: 0.0778843274561409 test loss: 0.22359912068803164
0    6.887275
dtype: float32
Epoch 115, train loss: 0.07271531299879869 test loss: 0.22443806485515375
0    6.868004
dtype: float32
Epoch 116, train loss: 0.07154585635786602 test loss: 0.21724596894004858
0    6.608558
dtype: float32
Epoch 117, train loss: 0.06942378107579905 test loss: 0.21364257282708207
0    6.563797
dtype: float32
Epoch 118, train loss: 0.06995280881804675 test loss: 0.21089527086657783
0    6.775465
dtype: float32
Epoch 119, train loss: 0.06960404621670055 test loss: 0.21690567491671053
0    6.929319
dtype: float32
Epoch 120, train loss: 0.08348613666728275 test loss: 0.2317174644392585
0    6.37261
dtype: float32
Epoch 121, train loss: 0.08060097957965875 test loss: 0.21018375521999896
0    6.977216
dtype: float32
Epoch 122, train loss: 0.08041305914988763 test loss: 0.22443459840449934
0    6.67941
dtype: float32
Epoch 123, train loss: 0.07413900217350677 test loss: 0.20833764456588047
0    7.0078
dtype: float32
Epoch 124, train loss: 0.07444675748034704 test loss: 0.22118603378619836
0    6.769289
dtype: float32
Epoch 125, train loss: 0.0714805446209629 test loss: 0.21696346099497532
0    6.581367
dtype: float32
Epoch 126, train loss: 0.0761237606415509 test loss: 0.21149411296447287
0    6.756336
dtype: float32
Epoch 127, train loss: 0.06925360200252867 test loss: 0.21891274958932505
0    6.253049
dtype: float32
Epoch 128, train loss: 0.09509899262624101 test loss: 0.21657958629572704
0    6.900897
dtype: float32
Epoch 129, train loss: 0.08002300985603837 test loss: 0.22553397723386234
0    6.919271
dtype: float32
Epoch 130, train loss: 0.07242081151185874 test loss: 0.23174538437869935
0    6.85402
dtype: float32
Epoch 131, train loss: 0.06870560695776452 test loss: 0.22005963197217226
0    6.699443
dtype: float32
Epoch 132, train loss: 0.06741485881178635 test loss: 0.21426713141077341
0    6.138579
dtype: float32
Epoch 133, train loss: 0.10809933749268505 test loss: 0.2118513807976543
0    6.467302
dtype: float32
Epoch 134, train loss: 0.07494050225815056 test loss: 0.21029072554619538
0    6.385315
dtype: float32
Epoch 135, train loss: 0.08269672502320842 test loss: 0.21081985851694413
0    6.788529
dtype: float32
Epoch 136, train loss: 0.06844937473387129 test loss: 0.21641206699086307
0    6.950368
dtype: float32
Epoch 137, train loss: 0.0695230412614709 test loss: 0.22493760208553992
0    6.558208
dtype: float32
Epoch 138, train loss: 0.07797350600710277 test loss: 0.2063810014611849
0    6.737098
dtype: float32
Epoch 139, train loss: 0.06725734549441302 test loss: 0.21806500102849674
0    7.278853
dtype: float32
Epoch 140, train loss: 0.08498929768318267 test loss: 0.24313880597341161
0    6.931011
dtype: float32
Epoch 141, train loss: 0.07328696719096074 test loss: 0.22811464315060778
0    7.018058
dtype: float32
Epoch 142, train loss: 0.07523593600537856 test loss: 0.23257121603234895
0    6.716238
dtype: float32
Epoch 143, train loss: 0.06654374382681773 test loss: 0.21970645924117338
0    6.887665
dtype: float32
Epoch 144, train loss: 0.07096195879217268 test loss: 0.227027827831358
0    6.668519
dtype: float32
Epoch 145, train loss: 0.06972706325103181 test loss: 0.21420715345161503
0    6.23937
dtype: float32
Epoch 146, train loss: 0.0961261027192391 test loss: 0.22729745173692084
0    6.022151
dtype: float32
Epoch 147, train loss: 0.0855275684913601 test loss: 0.21747609398849238
0    6.676358
dtype: float32
Epoch 148, train loss: 0.07356704358631345 test loss: 0.2313364184896281
0    6.418679
dtype: float32
Epoch 149, train loss: 0.06946534338684753 test loss: 0.2250697089287547
0    6.569527
dtype: float32
Epoch 150, train loss: 0.06764638926966358 test loss: 0.22483115972059814
0    6.449913
dtype: float32
Epoch 151, train loss: 0.07055782774935808 test loss: 0.21730315636375533
0    6.290929
dtype: float32
Epoch 152, train loss: 0.08331114155605507 test loss: 0.2135988223459425
0    6.140499
dtype: float32
Epoch 153, train loss: 0.1153217947112214 test loss: 0.20830168366533805
0    6.674083
dtype: float32
Epoch 154, train loss: 0.06672193762462966 test loss: 0.22150808299706246
0    6.946568
dtype: float32
Epoch 155, train loss: 0.07265747103828166 test loss: 0.2370537514927145
0    6.725373
dtype: float32
Epoch 156, train loss: 0.0678968941681587 test loss: 0.22669184431738265
0    6.717164
dtype: float32
Epoch 157, train loss: 0.06766221976798344 test loss: 0.22210878535917924
0    6.550778
dtype: float32
Epoch 158, train loss: 0.06648333772643676 test loss: 0.21221786287699113
0    6.596458
dtype: float32
Epoch 159, train loss: 0.06441337661789531 test loss: 0.21230611311664263
0    6.922211
dtype: float32
Epoch 160, train loss: 0.07369055639991752 test loss: 0.22646553193727567
0    6.745661
dtype: float32
Epoch 161, train loss: 0.06486756656011032 test loss: 0.2160722483517055
0    6.542714
dtype: float32
Epoch 162, train loss: 0.07095398764132928 test loss: 0.2089412946904335
0    6.429234
dtype: float32
Epoch 163, train loss: 0.06923098528185212 test loss: 0.2135983641167968
0    6.384576
dtype: float32
Epoch 164, train loss: 0.08938737968152201 test loss: 0.20693142405790152
0    6.719664
dtype: float32
Epoch 165, train loss: 0.0653216840809064 test loss: 0.22122363262066466
0    6.065434
dtype: float32
Epoch 166, train loss: 0.11533575983147733 test loss: 0.2036535390574542
0    6.877904
dtype: float32
Epoch 167, train loss: 0.08177769609026087 test loss: 0.2344038881936325
0    6.475282
dtype: float32
Epoch 168, train loss: 0.06502566319390679 test loss: 0.20925906583284876
0    6.765717
dtype: float32
Epoch 169, train loss: 0.06964226223838799 test loss: 0.22763486766383398
0    6.709752
dtype: float32
Epoch 170, train loss: 0.06638422030752983 test loss: 0.22232606591957194
0    6.409462
dtype: float32
Epoch 171, train loss: 0.06766632053351662 test loss: 0.2072596028384451
0    6.529665
dtype: float32
Epoch 172, train loss: 0.06420536393666612 test loss: 0.20888318765892644
0    6.597989
dtype: float32
Epoch 173, train loss: 0.06395891897028354 test loss: 0.2128008835214525
0    6.70241
dtype: float32
Epoch 174, train loss: 0.06553366909785299 test loss: 0.21543115068453816
0    6.771496
dtype: float32
Epoch 175, train loss: 0.06449971925650251 test loss: 0.21939537815130236
0    6.723858
dtype: float32
Epoch 176, train loss: 0.07039113917447927 test loss: 0.21824436116478974
0    6.592723
dtype: float32
Epoch 177, train loss: 0.06409531953610763 test loss: 0.21571772463560424
0    6.819424
dtype: float32
Epoch 178, train loss: 0.0714529122382108 test loss: 0.2287722733246332
0    6.398568
dtype: float32
Epoch 179, train loss: 0.07116604995758119 test loss: 0.21589980200308836
0    6.562366
dtype: float32
Epoch 180, train loss: 0.06344721188923863 test loss: 0.2174216877286341
0    6.793451
dtype: float32
Epoch 181, train loss: 0.07265191834365883 test loss: 0.22681207497446504
0    6.364632
dtype: float32
Epoch 182, train loss: 0.07692778952734483 test loss: 0.2079146840071031
0    7.050727
dtype: float32
Epoch 183, train loss: 0.07845396950822552 test loss: 0.2431972212549481
0    6.64326
dtype: float32
Epoch 184, train loss: 0.06429126377141904 test loss: 0.22538509541313473
0    6.906385
dtype: float32
Epoch 185, train loss: 0.07487437032728606 test loss: 0.2388387508894311
0    6.580311
dtype: float32
Epoch 186, train loss: 0.062434601448523086 test loss: 0.21780581815408928
0    6.314717
dtype: float32
Epoch 187, train loss: 0.08481912749429535 test loss: 0.20973931895092596
0    6.599813
dtype: float32
Epoch 188, train loss: 0.06282133267558261 test loss: 0.22010283936681155
0    6.217538
dtype: float32
Epoch 189, train loss: 0.08225342914546677 test loss: 0.2063902188155006
0    7.00809
dtype: float32
Epoch 190, train loss: 0.08211103493529737 test loss: 0.23406326710913905
0    6.212938
dtype: float32
Epoch 191, train loss: 0.07646152545292839 test loss: 0.20353686627157616
0    7.226354
dtype: float32
Epoch 192, train loss: 0.10036676745618242 test loss: 0.2543497932758063
0    6.504985
dtype: float32
Epoch 193, train loss: 0.06581467534783612 test loss: 0.20415036634585434
0    6.283788
dtype: float32
Epoch 194, train loss: 0.08447262282642136 test loss: 0.2003666578593426
0    7.028772
dtype: float32
Epoch 195, train loss: 0.07569817860715661 test loss: 0.23927064068389106
0    6.86189
dtype: float32
Epoch 196, train loss: 0.08388099237164094 test loss: 0.23598290076741302
0    7.058639
dtype: float32
Epoch 197, train loss: 0.09336432381059608 test loss: 0.24582559991402034
0    6.930739
dtype: float32
Epoch 198, train loss: 0.07493688537793035 test loss: 0.2434280616977505
0    6.573885
dtype: float32
Epoch 199, train loss: 0.06275100248627469 test loss: 0.2250852189219411
0    6.484435
dtype: float32
Epoch 200, train loss: 0.062142324941105304 test loss: 0.21624546242396167
0    6.593686
dtype: float32
Epoch 201, train loss: 0.06215997356597177 test loss: 0.22162109279877187
0    6.501381
dtype: float32
Epoch 202, train loss: 0.0620791041057599 test loss: 0.22036565272593786
0    6.317237
dtype: float32
Epoch 203, train loss: 0.06514470681962103 test loss: 0.22138205841673622
0    6.073252
dtype: float32
Epoch 204, train loss: 0.07867682072425874 test loss: 0.21849621270007946
0    6.724897
dtype: float32
Epoch 205, train loss: 0.07023995432644352 test loss: 0.23200993701125716
0    6.590775
dtype: float32
Epoch 206, train loss: 0.06798940022942264 test loss: 0.22568445112349667
0    6.598597
dtype: float32
Epoch 207, train loss: 0.06171737862524086 test loss: 0.22568093709470816
0    6.52766
dtype: float32
Epoch 208, train loss: 0.06146964491719745 test loss: 0.22318935100134923
0    6.170923
dtype: float32
Epoch 209, train loss: 0.07826040079063476 test loss: 0.21777903819945804
0    6.314003
dtype: float32
Epoch 210, train loss: 0.07097144961598245 test loss: 0.21772992921897752
0    6.400017
dtype: float32
Epoch 211, train loss: 0.062495811221648656 test loss: 0.2198757374647453
0    6.207773
dtype: float32
Epoch 212, train loss: 0.06905880935666496 test loss: 0.21506483466164023
0    6.147597
dtype: float32
Epoch 213, train loss: 0.07552723196884634 test loss: 0.22519913054304913
0    6.349722
dtype: float32
Epoch 214, train loss: 0.07112327390669951 test loss: 0.21513105975987443
0    6.067608
dtype: float32
Epoch 215, train loss: 0.079285900730342 test loss: 0.21905553604331082
0    6.374756
dtype: float32
Epoch 216, train loss: 0.06354666233035797 test loss: 0.21912547992451367
0    6.67028
dtype: float32
Epoch 217, train loss: 0.07320885257719448 test loss: 0.23320675597970575
0    6.882891
dtype: float32
Epoch 218, train loss: 0.08551425288919128 test loss: 0.24637222277635465
0    6.504622
dtype: float32
Epoch 219, train loss: 0.06192222869438474 test loss: 0.22979726712323575
0    6.462414
dtype: float32
Epoch 220, train loss: 0.06420787285863151 test loss: 0.22251755611879923
0    6.35266
dtype: float32
Epoch 221, train loss: 0.06359657463845969 test loss: 0.21245730889498446
0    6.502532
dtype: float32
Epoch 222, train loss: 0.06037127121510179 test loss: 0.21977356953319674
0    6.216908
dtype: float32
Epoch 223, train loss: 0.08969442148117424 test loss: 0.20716629548478435
0    6.161998
dtype: float32
Epoch 224, train loss: 0.08942555533346518 test loss: 0.21504639628042355
0    6.149633
dtype: float32
Epoch 225, train loss: 0.07399622985710146 test loss: 0.21664156028265757
0    6.518322
dtype: float32
Epoch 226, train loss: 0.061531987946522745 test loss: 0.21480110876927636
0    6.218317
dtype: float32
Epoch 227, train loss: 0.07202118818237489 test loss: 0.21459207934432514
0    6.479434
dtype: float32
Epoch 228, train loss: 0.0677154362256664 test loss: 0.21391659665302928
0    6.734733
dtype: float32
Epoch 229, train loss: 0.06204168778829121 test loss: 0.225101976541555
0    6.697349
dtype: float32
Epoch 230, train loss: 0.06846628877602312 test loss: 0.2275612530121413
0    6.106197
dtype: float32
Epoch 231, train loss: 0.08397667988480474 test loss: 0.21640907501748374
0    6.333784
dtype: float32
Epoch 232, train loss: 0.0813112676565602 test loss: 0.20708561082259722
0    6.600254
dtype: float32
Epoch 233, train loss: 0.060085417634047844 test loss: 0.2219380554229359
0    6.494232
dtype: float32
Epoch 234, train loss: 0.06029237584662572 test loss: 0.21782939192946013
0    6.926318
dtype: float32
Epoch 235, train loss: 0.0774096778347486 test loss: 0.23363386795750427
0    6.649305
dtype: float32
Epoch 236, train loss: 0.06000478976355565 test loss: 0.22086236731936884
0    6.242346
dtype: float32
Epoch 237, train loss: 0.07145183438072818 test loss: 0.2152592400407971
0    6.27238
dtype: float32
Epoch 238, train loss: 0.07126265451306424 test loss: 0.21668620208105518
0    6.556616
dtype: float32
Epoch 239, train loss: 0.06214444768493975 test loss: 0.22421160430686762
0    5.624515
dtype: float32
Epoch 240, train loss: 0.13143901838222807 test loss: 0.2643528285833033
0    6.59498
dtype: float32
Epoch 241, train loss: 0.06827521399358752 test loss: 0.236075587531561
0    6.77527
dtype: float32
Epoch 242, train loss: 0.06245594730848828 test loss: 0.23852913760112157
0    6.812711
dtype: float32
Epoch 243, train loss: 0.07606104975253512 test loss: 0.2452495170558626
0    7.11496
dtype: float32
Epoch 244, train loss: 0.09126037475420463 test loss: 0.25740113361789024
0    6.486643
dtype: float32
Epoch 245, train loss: 0.06996871379941837 test loss: 0.22995064832263085
0    6.829737
dtype: float32
Epoch 246, train loss: 0.0675219440111874 test loss: 0.249364124539487
0    6.308452
dtype: float32
Epoch 247, train loss: 0.07014068670565637 test loss: 0.2299517615425592
0    6.323241
dtype: float32
Epoch 248, train loss: 0.07838256540819682 test loss: 0.2267028152548558
0    6.830311
dtype: float32
Epoch 249, train loss: 0.06697019034719247 test loss: 0.2397840949204824
0    6.950836
dtype: float32
Epoch 250, train loss: 0.07176929924584959 test loss: 0.24662254076281162
0    6.424898
dtype: float32
Epoch 251, train loss: 0.062192584972226655 test loss: 0.23065359987022788
0    6.877638
dtype: float32
Epoch 252, train loss: 0.06454206593578267 test loss: 0.24420635422761927
0    6.459072
dtype: float32
Epoch 253, train loss: 0.06494100772084756 test loss: 0.22590660237731297
0    6.297755
dtype: float32
Epoch 254, train loss: 0.0690971385216892 test loss: 0.22513530968076045
0    6.970983
dtype: float32
Epoch 255, train loss: 0.06939860707841833 test loss: 0.23803176523817104
0    6.669886
dtype: float32
Epoch 256, train loss: 0.0706328805969513 test loss: 0.23815928539459114
0    6.713361
dtype: float32
Epoch 257, train loss: 0.06467409842313672 test loss: 0.2349182471977601
0    6.717963
dtype: float32
Epoch 258, train loss: 0.0627827697499607 test loss: 0.232120472020138
0    6.515942
dtype: float32
Epoch 259, train loss: 0.061650534181889566 test loss: 0.22213019646189816
0    6.77968
dtype: float32
Epoch 260, train loss: 0.06098845869852252 test loss: 0.22894196270274308
0    6.841413
dtype: float32
Epoch 261, train loss: 0.059915312764553905 test loss: 0.2284721192384594
0    6.628919
dtype: float32
Epoch 262, train loss: 0.058151147527783636 test loss: 0.22695097529611938
0    6.6591
dtype: float32
Epoch 263, train loss: 0.059383100131476324 test loss: 0.22803427192260173
0    6.360347
dtype: float32
Epoch 264, train loss: 0.07119422330316563 test loss: 0.2208259457536627
0    6.62352
dtype: float32
Epoch 265, train loss: 0.058195092426124376 test loss: 0.22878607337415227
0    6.581563
dtype: float32
Epoch 266, train loss: 0.057841077120260556 test loss: 0.23031223777925514
0    6.81485
dtype: float32
Epoch 267, train loss: 0.0617214347158866 test loss: 0.2371834693007005
0    6.931623
dtype: float32
Epoch 268, train loss: 0.08002706719191331 test loss: 0.25217826928372217
0    6.965708
dtype: float32
Epoch 269, train loss: 0.07177098864466021 test loss: 0.2537254721606242
0    6.751079
dtype: float32
Epoch 270, train loss: 0.06454112541634806 test loss: 0.24222744416394282
0    6.587511
dtype: float32
Epoch 271, train loss: 0.058594617335274705 test loss: 0.2293805172561809
0    6.568258
dtype: float32
Epoch 272, train loss: 0.06883365250888557 test loss: 0.22025391304108435
0    6.868476
dtype: float32
Epoch 273, train loss: 0.07297888613278122 test loss: 0.241397157451375
0    7.052767
dtype: float32
Epoch 274, train loss: 0.07788171331871796 test loss: 0.2541901543302311
0    6.458629
dtype: float32
Epoch 275, train loss: 0.0586306913941816 test loss: 0.23026728404084051
0    6.887652
dtype: float32
Epoch 276, train loss: 0.06403429392260977 test loss: 0.23671197104608138
0    6.624788
dtype: float32
Epoch 277, train loss: 0.059335586167734065 test loss: 0.2306803321651152
0    6.550441
dtype: float32
Epoch 278, train loss: 0.06035725770229895 test loss: 0.2249076319042149
0    6.761262
dtype: float32
Epoch 279, train loss: 0.07053081906269767 test loss: 0.23925465517183658
0    6.732853
dtype: float32
Epoch 280, train loss: 0.05995285264811176 test loss: 0.23924649417710528
0    6.503344
dtype: float32
Epoch 281, train loss: 0.05903342737981707 test loss: 0.23364141938396804
0    6.544734
dtype: float32
Epoch 282, train loss: 0.05872054719123316 test loss: 0.2285741431659464
0    6.720944
dtype: float32
Epoch 283, train loss: 0.0630174125129023 test loss: 0.23509732485483228
0    6.676701
dtype: float32
Epoch 284, train loss: 0.06051014172894263 test loss: 0.2377028890480416
0    6.685822
dtype: float32
Epoch 285, train loss: 0.05765095384045254 test loss: 0.23480695572302226
0    6.535256
dtype: float32
Epoch 286, train loss: 0.06041645971956251 test loss: 0.22586231627779543
0    7.414103
dtype: float32
Epoch 287, train loss: 0.09504707908154633 test loss: 0.2735792208657244
0    6.721228
dtype: float32
Epoch 288, train loss: 0.058521335760873844 test loss: 0.23615950267962466
0    6.484129
dtype: float32
Epoch 289, train loss: 0.061628871181595886 test loss: 0.22711487604273972
0    7.060507
dtype: float32
Epoch 290, train loss: 0.08371894944050817 test loss: 0.246659579186521
0    7.031111
dtype: float32
Epoch 291, train loss: 0.07384059867555502 test loss: 0.24518811061119875
0    6.648176
dtype: float32
Epoch 292, train loss: 0.060122379094335314 test loss: 0.23001846850377416
0    6.681745
dtype: float32
Epoch 293, train loss: 0.06400114311511831 test loss: 0.24517063766743621
0    6.452661
dtype: float32
Epoch 294, train loss: 0.058806291547906835 test loss: 0.23122903612163223
0    6.441983
dtype: float32
Epoch 295, train loss: 0.058135460288530214 test loss: 0.23193728896813964
0    6.855885
dtype: float32
Epoch 296, train loss: 0.07175758600697896 test loss: 0.24459882988730106
0    6.974974
dtype: float32
Epoch 297, train loss: 0.07234956687376072 test loss: 0.24349505519185277
0    6.948276
dtype: float32
Epoch 298, train loss: 0.07848256652047325 test loss: 0.24503928970653738
0    6.848223
dtype: float32
Epoch 299, train loss: 0.07129402390908927 test loss: 0.25226866668152276
Final train loss is: 0.07129402390908927, Test loss is: 0.25226866668152276
0    6.848223
dtype: float32
high
round is 0
0    8.652276
dtype: float32
Epoch 6, train loss: 0.27304563048844366 test loss: 0.23497378238298822
0    10.001211
dtype: float32
Epoch 7, train loss: 0.21938803417422567 test loss: 0.23048322157467088
0    9.935022
dtype: float32
Epoch 8, train loss: 0.1855931071752213 test loss: 0.21502354449780486
0    9.310343
dtype: float32
Epoch 9, train loss: 0.15630205592304838 test loss: 0.20781884495084124
0    8.658017
dtype: float32
Epoch 10, train loss: 0.14658035506893857 test loss: 0.2040386824529924
0    8.452433
dtype: float32
Epoch 11, train loss: 0.14050116189239384 test loss: 0.20088073528179295
0    7.956927
dtype: float32
Epoch 12, train loss: 0.1239137432394569 test loss: 0.19008460610034886
0    7.639059
dtype: float32
Epoch 13, train loss: 0.1198663340629345 test loss: 0.18853999376825842
0    6.12218
dtype: float32
Epoch 14, train loss: 0.21502570373335214 test loss: 0.24914474760657812
0    5.921787
dtype: float32
Epoch 15, train loss: 0.19417363663485493 test loss: 0.24888835506772355
0    6.837277
dtype: float32
Epoch 16, train loss: 0.0991660188633803 test loss: 0.18725685952297152
0    7.032721
dtype: float32
Epoch 17, train loss: 0.10856203528258161 test loss: 0.18991841448165225
0    6.205891
dtype: float32
Epoch 18, train loss: 0.11538164730862077 test loss: 0.19877280131331043
0    6.549518
dtype: float32
Epoch 19, train loss: 0.09240481024654709 test loss: 0.18573727462683376
0    7.349006
dtype: float32
Epoch 20, train loss: 0.14046597328565985 test loss: 0.20252304768912585
0    6.65017
dtype: float32
Epoch 21, train loss: 0.08910242455632598 test loss: 0.18378956637475324
0    6.557917
dtype: float32
Epoch 22, train loss: 0.0871551112701173 test loss: 0.18193526838544757
0    5.369236
dtype: float32
Epoch 23, train loss: 0.2120889331240205 test loss: 0.22561721915145733
0    5.021657
dtype: float32
Epoch 24, train loss: 0.22821117442945268 test loss: 0.2557777430889376
0    6.128434
dtype: float32
Epoch 25, train loss: 0.09683441646205261 test loss: 0.19644508044733014
0    6.3245
dtype: float32
Epoch 26, train loss: 0.08171928188307892 test loss: 0.18213266116093663
0    6.891318
dtype: float32
Epoch 27, train loss: 0.09823413643054307 test loss: 0.1823926297101511
0    6.740828
dtype: float32
Epoch 28, train loss: 0.08325604903997601 test loss: 0.18658030303514675
0    6.471011
dtype: float32
Epoch 29, train loss: 0.0784076516617359 test loss: 0.18461893705825352
0    6.70569
dtype: float32
Epoch 30, train loss: 0.08632817514794663 test loss: 0.1838914872676712
0    6.390222
dtype: float32
Epoch 31, train loss: 0.09488275063296484 test loss: 0.1848182502255201
0    6.467836
dtype: float32
Epoch 32, train loss: 0.07866296759931138 test loss: 0.18335829584631655
0    6.440239
dtype: float32
Epoch 33, train loss: 0.0816520050886047 test loss: 0.18530571563969836
0    6.338857
dtype: float32
Epoch 34, train loss: 0.07905586613217302 test loss: 0.1842001883395234
0    6.499958
dtype: float32
Epoch 35, train loss: 0.0736434534743288 test loss: 0.1814729859308049
0    6.579752
dtype: float32
Epoch 36, train loss: 0.07333538563988302 test loss: 0.18072641699329095
0    6.884567
dtype: float32
Epoch 37, train loss: 0.0921832557538336 test loss: 0.19060255680493976
0    6.690339
dtype: float32
Epoch 38, train loss: 0.07474550267707553 test loss: 0.18172074403802543
0    6.368434
dtype: float32
Epoch 39, train loss: 0.07148358375038995 test loss: 0.17760355135259634
0    6.45324
dtype: float32
Epoch 40, train loss: 0.0701331835795137 test loss: 0.18100262495856784
0    6.627704
dtype: float32
Epoch 41, train loss: 0.07502910735164654 test loss: 0.1819469241936329
0    6.851635
dtype: float32
Epoch 42, train loss: 0.0899508224503274 test loss: 0.19420552613602862
0    6.944955
dtype: float32
Epoch 43, train loss: 0.09587489528253713 test loss: 0.21283571869745374
0    6.934816
dtype: float32
Epoch 44, train loss: 0.08251444831525978 test loss: 0.19717063027916423
0    6.952768
dtype: float32
Epoch 45, train loss: 0.08916381258445898 test loss: 0.18984285899302902
0    6.720224
dtype: float32
Epoch 46, train loss: 0.07304322963458003 test loss: 0.18419199291012542
0    6.650128
dtype: float32
Epoch 47, train loss: 0.07099483750961462 test loss: 0.18793365790484504
0    6.334598
dtype: float32
Epoch 48, train loss: 0.09312927478827522 test loss: 0.18878026523515534
0    6.688878
dtype: float32
Epoch 49, train loss: 0.06766240985983828 test loss: 0.18653188703650392
0    6.571899
dtype: float32
Epoch 50, train loss: 0.07616829188023679 test loss: 0.19180854126440466
0    7.011604
dtype: float32
Epoch 51, train loss: 0.07684503577728737 test loss: 0.1936946187425317
0    6.937903
dtype: float32
Epoch 52, train loss: 0.0912054646016333 test loss: 0.1907589695909533
0    7.424281
dtype: float32
Epoch 53, train loss: 0.11657625031407792 test loss: 0.23007196849868966
0    7.163301
dtype: float32
Epoch 54, train loss: 0.09867496196173377 test loss: 0.20565374602770978
0    6.72327
dtype: float32
Epoch 55, train loss: 0.07364080381185881 test loss: 0.17907542859242012
0    6.672939
dtype: float32
Epoch 56, train loss: 0.07150930475183151 test loss: 0.17448320446551388
0    6.660024
dtype: float32
Epoch 57, train loss: 0.06933453942339314 test loss: 0.1764644725574439
0    6.354573
dtype: float32
Epoch 58, train loss: 0.0914218636998564 test loss: 0.17607242137778725
0    6.844818
dtype: float32
Epoch 59, train loss: 0.08844550691199231 test loss: 0.18001229199607183
0    6.344207
dtype: float32
Epoch 60, train loss: 0.07651748399165506 test loss: 0.17197337278544425
0    6.756558
dtype: float32
Epoch 61, train loss: 0.06356598644015993 test loss: 0.1737679601282254
0    6.697137
dtype: float32
Epoch 62, train loss: 0.06381908590379194 test loss: 0.17222131764149717
0    6.630175
dtype: float32
Epoch 63, train loss: 0.06938408833243132 test loss: 0.17416543655774447
0    6.23238
dtype: float32
Epoch 64, train loss: 0.08164728695142688 test loss: 0.1762602337994858
0    6.556993
dtype: float32
Epoch 65, train loss: 0.06514272999964937 test loss: 0.17503849265886995
0    6.722511
dtype: float32
Epoch 66, train loss: 0.060742562964727145 test loss: 0.1747986718174313
0    6.746629
dtype: float32
Epoch 67, train loss: 0.060669355099203126 test loss: 0.17442421518529108
0    6.343427
dtype: float32
Epoch 68, train loss: 0.07164374626211958 test loss: 0.17715566396043914
0    6.628531
dtype: float32
Epoch 69, train loss: 0.06494167918067524 test loss: 0.17557417244637227
0    6.782115
dtype: float32
Epoch 70, train loss: 0.06142477156465449 test loss: 0.17767625325015557
0    6.769602
dtype: float32
Epoch 71, train loss: 0.06861159296207736 test loss: 0.18047032002487276
0    6.206944
dtype: float32
Epoch 72, train loss: 0.09217553380096334 test loss: 0.1808901001950671
0    6.923165
dtype: float32
Epoch 73, train loss: 0.06894837829498561 test loss: 0.17770922490056318
0    6.837826
dtype: float32
Epoch 74, train loss: 0.05928138263358295 test loss: 0.17441584818376646
0    7.122717
dtype: float32
Epoch 75, train loss: 0.06797209983551034 test loss: 0.1772801434417969
0    6.637196
dtype: float32
Epoch 76, train loss: 0.0619931195882652 test loss: 0.17492011548680853
0    6.552019
dtype: float32
Epoch 77, train loss: 0.08046837886048322 test loss: 0.17794649120942332
0    6.956899
dtype: float32
Epoch 78, train loss: 0.06419186244535013 test loss: 0.18076111618974608
0    6.992525
dtype: float32
Epoch 79, train loss: 0.0734992277266662 test loss: 0.18751796167908005
0    6.985086
dtype: float32
Epoch 80, train loss: 0.06477529992481619 test loss: 0.17288178886587163
0    6.795367
dtype: float32
Epoch 81, train loss: 0.06018278693035386 test loss: 0.1737786473581263
0    6.546305
dtype: float32
Epoch 82, train loss: 0.06990301903695684 test loss: 0.1757552992197541
0    6.666934
dtype: float32
Epoch 83, train loss: 0.06051130561509633 test loss: 0.17528227362549656
0    6.946803
dtype: float32
Epoch 84, train loss: 0.06275018510173262 test loss: 0.18052907141162336
0    6.832978
dtype: float32
Epoch 85, train loss: 0.05868100545948244 test loss: 0.17320884510943493
0    7.033286
dtype: float32
Epoch 86, train loss: 0.07565583372473232 test loss: 0.18174901900513096
0    6.922166
dtype: float32
Epoch 87, train loss: 0.06380313772715902 test loss: 0.1760107137736444
0    7.144085
dtype: float32
Epoch 88, train loss: 0.06441020114260217 test loss: 0.17805551316584908
0    6.71273
dtype: float32
Epoch 89, train loss: 0.05921594444381217 test loss: 0.17224609613952158
0    6.79424
dtype: float32
Epoch 90, train loss: 0.061793434249829 test loss: 0.17392498185157168
0    6.421827
dtype: float32
Epoch 91, train loss: 0.08312726475506574 test loss: 0.17669052791232778
0    6.781157
dtype: float32
Epoch 92, train loss: 0.057361669832740804 test loss: 0.17468033326481353
0    6.862136
dtype: float32
Epoch 93, train loss: 0.059966487225491104 test loss: 0.17484104279814464
0    6.796527
dtype: float32
Epoch 94, train loss: 0.057304408589700775 test loss: 0.17623567079375313
0    6.871471
dtype: float32
Epoch 95, train loss: 0.05764345222093688 test loss: 0.17629214635460574
0    7.056849
dtype: float32
Epoch 96, train loss: 0.07547566424085982 test loss: 0.18342937360159303
0    6.847513
dtype: float32
Epoch 97, train loss: 0.05776906070452226 test loss: 0.17551795917004437
0    6.734833
dtype: float32
Epoch 98, train loss: 0.05670919542780814 test loss: 0.17467299864947156
0    6.905502
dtype: float32
Epoch 99, train loss: 0.05567218583872209 test loss: 0.17394779356533888
0    6.463276
dtype: float32
Epoch 100, train loss: 0.0806073507277261 test loss: 0.1795256070879674
0    7.19059
dtype: float32
Epoch 101, train loss: 0.0652746913337357 test loss: 0.18342275142423092
0    6.930748
dtype: float32
Epoch 102, train loss: 0.05604556338389606 test loss: 0.17518277196414972
0    6.919009
dtype: float32
Epoch 103, train loss: 0.05535132135585884 test loss: 0.1767031617021592
0    6.957713
dtype: float32
Epoch 104, train loss: 0.05578362330646668 test loss: 0.17613149272049633
0    6.894806
dtype: float32
Epoch 105, train loss: 0.05730749334486274 test loss: 0.17913116996810297
0    6.559014
dtype: float32
Epoch 106, train loss: 0.07116388553658415 test loss: 0.18143058683818358
0    6.870302
dtype: float32
Epoch 107, train loss: 0.0544533758828118 test loss: 0.1756667378743345
0    6.730549
dtype: float32
Epoch 108, train loss: 0.06018643303199744 test loss: 0.1770510562419846
0    6.653152
dtype: float32
Epoch 109, train loss: 0.057665758307888566 test loss: 0.1750910686935949
0    6.911626
dtype: float32
Epoch 110, train loss: 0.05422005178380672 test loss: 0.17581030176137308
0    6.598963
dtype: float32
Epoch 111, train loss: 0.06103644889667354 test loss: 0.17707980047113053
0    6.764385
dtype: float32
Epoch 112, train loss: 0.057641473938076934 test loss: 0.1769887823338209
0    6.863024
dtype: float32
Epoch 113, train loss: 0.055547779812052285 test loss: 0.17700719387375333
0    6.908621
dtype: float32
Epoch 114, train loss: 0.05450137308675983 test loss: 0.17564499241994316
0    6.732285
dtype: float32
Epoch 115, train loss: 0.05908492762769918 test loss: 0.176334855860959
0    6.699534
dtype: float32
Epoch 116, train loss: 0.057679370602067646 test loss: 0.17473326841762588
0    6.951904
dtype: float32
Epoch 117, train loss: 0.0539041764641083 test loss: 0.17677353647303123
0    7.135154
dtype: float32
Epoch 118, train loss: 0.06120722302298836 test loss: 0.1843609235360072
0    6.824568
dtype: float32
Epoch 119, train loss: 0.05226344370752455 test loss: 0.17589710009612744
0    7.089247
dtype: float32
Epoch 120, train loss: 0.061177455419095625 test loss: 0.18191817644774852
0    6.791994
dtype: float32
Epoch 121, train loss: 0.05501160629229545 test loss: 0.17724717692823658
0    6.522418
dtype: float32
Epoch 122, train loss: 0.07179917148049986 test loss: 0.1811197286969913
0    6.687364
dtype: float32
Epoch 123, train loss: 0.06456810340426804 test loss: 0.17708470409953245
0    7.062718
dtype: float32
Epoch 124, train loss: 0.057124557020681185 test loss: 0.17751384797028402
0    7.044663
dtype: float32
Epoch 125, train loss: 0.05437997671754063 test loss: 0.1781965610401936
0    7.009279
dtype: float32
Epoch 126, train loss: 0.05273365221030157 test loss: 0.1766482453716136
0    7.09493
dtype: float32
Epoch 127, train loss: 0.05429983770108295 test loss: 0.1792939159497755
0    6.829588
dtype: float32
Epoch 128, train loss: 0.051839542353591714 test loss: 0.17633128349087643
0    6.98736
dtype: float32
Epoch 129, train loss: 0.053376251465579776 test loss: 0.1771266415826022
0    6.992558
dtype: float32
Epoch 130, train loss: 0.05399483589758689 test loss: 0.18035500714791058
0    6.967888
dtype: float32
Epoch 131, train loss: 0.052610839346332046 test loss: 0.1788715333248756
0    6.953245
dtype: float32
Epoch 132, train loss: 0.052800980829067784 test loss: 0.17851858289254535
0    6.650093
dtype: float32
Epoch 133, train loss: 0.05796239312869586 test loss: 0.17768701614061747
0    6.853153
dtype: float32
Epoch 134, train loss: 0.0497957109327804 test loss: 0.1758824392937246
0    6.901681
dtype: float32
Epoch 135, train loss: 0.04993095964425662 test loss: 0.17753658022373026
0    6.974417
dtype: float32
Epoch 136, train loss: 0.04984641516917121 test loss: 0.1767201970689232
0    6.977399
dtype: float32
Epoch 137, train loss: 0.05008184360135146 test loss: 0.17810804404360908
0    7.008758
dtype: float32
Epoch 138, train loss: 0.05661946366977827 test loss: 0.1757135700414361
0    7.186518
dtype: float32
Epoch 139, train loss: 0.06184377491823342 test loss: 0.18170625615987823
0    6.916371
dtype: float32
Epoch 140, train loss: 0.05168522552999784 test loss: 0.17605458919711325
0    7.149047
dtype: float32
Epoch 141, train loss: 0.05663820458864015 test loss: 0.1813294279939692
0    6.848899
dtype: float32
Epoch 142, train loss: 0.05089896300315345 test loss: 0.17433379000974747
0    6.758037
dtype: float32
Epoch 143, train loss: 0.05545195430581096 test loss: 0.17544861848548204
0    6.974719
dtype: float32
Epoch 144, train loss: 0.054119075815850744 test loss: 0.17344171944880724
0    6.851603
dtype: float32
Epoch 145, train loss: 0.05406923366445625 test loss: 0.17319047898942394
0    7.088923
dtype: float32
Epoch 146, train loss: 0.05196082145342824 test loss: 0.17450549018747677
0    6.867924
dtype: float32
Epoch 147, train loss: 0.054201927497212074 test loss: 0.1729782688197018
0    6.891673
dtype: float32
Epoch 148, train loss: 0.06296367063308908 test loss: 0.174580100392589
0    6.909286
dtype: float32
Epoch 149, train loss: 0.05041642977683913 test loss: 0.17333966277093962
0    7.009804
dtype: float32
Epoch 150, train loss: 0.06446559608916431 test loss: 0.17095834975432134
0    7.174343
dtype: float32
Epoch 151, train loss: 0.058173382974283455 test loss: 0.17610822995486872
0    7.068665
dtype: float32
Epoch 152, train loss: 0.050315266433684204 test loss: 0.172979465773507
0    6.971917
dtype: float32
Epoch 153, train loss: 0.050122567579053104 test loss: 0.17227256825557938
0    7.176912
dtype: float32
Epoch 154, train loss: 0.05562355208810644 test loss: 0.1792058009376617
0    7.268462
dtype: float32
Epoch 155, train loss: 0.05961684482333561 test loss: 0.17543321923330543
0    7.064134
dtype: float32
Epoch 156, train loss: 0.052484837304772214 test loss: 0.17254988757152817
0    7.125177
dtype: float32
Epoch 157, train loss: 0.05139630927179238 test loss: 0.1773779804424601
0    7.022032
dtype: float32
Epoch 158, train loss: 0.048740933922760375 test loss: 0.17443636568781817
0    6.935337
dtype: float32
Epoch 159, train loss: 0.04993545324946806 test loss: 0.17556972693477843
0    6.948654
dtype: float32
Epoch 160, train loss: 0.050018263605778754 test loss: 0.1755384908255565
0    6.489373
dtype: float32
Epoch 161, train loss: 0.0794633332266559 test loss: 0.17888106684193233
0    6.77209
dtype: float32
Epoch 162, train loss: 0.05091936426023803 test loss: 0.1747611373225744
0    6.847435
dtype: float32
Epoch 163, train loss: 0.05091107718738869 test loss: 0.1749648381524564
0    6.615059
dtype: float32
Epoch 164, train loss: 0.06559820895091333 test loss: 0.17777723917405483
0    7.052414
dtype: float32
Epoch 165, train loss: 0.04851383289008449 test loss: 0.1759396344772459
0    6.548972
dtype: float32
Epoch 166, train loss: 0.09147932569587681 test loss: 0.18604652147689943
0    6.509834
dtype: float32
Epoch 167, train loss: 0.07648860754185585 test loss: 0.17830642942584532
0    6.853011
dtype: float32
Epoch 168, train loss: 0.05363709260467458 test loss: 0.17446041241120963
0    6.696944
dtype: float32
Epoch 169, train loss: 0.07007342735947021 test loss: 0.17757776088316443
0    6.430417
dtype: float32
Epoch 170, train loss: 0.09144811388005844 test loss: 0.1870469827915611
0    6.919222
dtype: float32
Epoch 171, train loss: 0.048709173571882404 test loss: 0.1758054553761111
0    6.974495
dtype: float32
Epoch 172, train loss: 0.047325139617926094 test loss: 0.17334628648145367
0    7.107609
dtype: float32
Epoch 173, train loss: 0.05067184802662796 test loss: 0.17453138953845346
0    7.021627
dtype: float32
Epoch 174, train loss: 0.048658546310781974 test loss: 0.17360877980234107
0    6.879032
dtype: float32
Epoch 175, train loss: 0.051331978533847925 test loss: 0.17500681039278776
0    7.000206
dtype: float32
Epoch 176, train loss: 0.05016886779919799 test loss: 0.17338239754028353
0    6.872265
dtype: float32
Epoch 177, train loss: 0.052088163386127956 test loss: 0.17455755102726891
0    6.863051
dtype: float32
Epoch 178, train loss: 0.053382304749323393 test loss: 0.1744071785971322
0    7.031639
dtype: float32
Epoch 179, train loss: 0.04794791219122956 test loss: 0.17298201199314317
0    7.055597
dtype: float32
Epoch 180, train loss: 0.04840858030074561 test loss: 0.1737840773744787
0    7.151772
dtype: float32
Epoch 181, train loss: 0.05214500122659868 test loss: 0.1764578876708206
0    7.084194
dtype: float32
Epoch 182, train loss: 0.05698499171836726 test loss: 0.1734145430107921
0    7.147084
dtype: float32
Epoch 183, train loss: 0.05398329314810481 test loss: 0.175802428994136
0    6.999982
dtype: float32
Epoch 184, train loss: 0.049374158637332966 test loss: 0.17300795808319458
0    6.919903
dtype: float32
Epoch 185, train loss: 0.04875016584381023 test loss: 0.16931037883627142
0    6.782063
dtype: float32
Epoch 186, train loss: 0.05583704788984839 test loss: 0.1728210258904001
0    7.135543
dtype: float32
Epoch 187, train loss: 0.04848868672202594 test loss: 0.17045210159715762
0    7.038708
dtype: float32
Epoch 188, train loss: 0.04618361031535094 test loss: 0.17208609143733497
0    6.752815
dtype: float32
Epoch 189, train loss: 0.05512177836647553 test loss: 0.17164344338775064
0    7.226155
dtype: float32
Epoch 190, train loss: 0.05645116283504264 test loss: 0.17064127591256942
0    6.898061
dtype: float32
Epoch 191, train loss: 0.05037331223397477 test loss: 0.17315618310649009
0    6.930593
dtype: float32
Epoch 192, train loss: 0.04605265443485811 test loss: 0.17218027701492591
0    7.01755
dtype: float32
Epoch 193, train loss: 0.04519509650394274 test loss: 0.17183439514334775
0    6.994604
dtype: float32
Epoch 194, train loss: 0.04719703047551924 test loss: 0.1720225964391193
0    6.959806
dtype: float32
Epoch 195, train loss: 0.04705049222855856 test loss: 0.17386282242365148
0    7.007126
dtype: float32
Epoch 196, train loss: 0.04579841334527977 test loss: 0.17168521898459652
0    6.966741
dtype: float32
Epoch 197, train loss: 0.04698354133920103 test loss: 0.17717007066806192
0    7.064947
dtype: float32
Epoch 198, train loss: 0.046629830057615174 test loss: 0.1758470628465283
0    7.097777
dtype: float32
Epoch 199, train loss: 0.04797587406720959 test loss: 0.17531614643903157
0    6.984089
dtype: float32
Epoch 200, train loss: 0.04615322533029388 test loss: 0.1720753501329232
0    6.9364
dtype: float32
Epoch 201, train loss: 0.07049795088187608 test loss: 0.17606297097461085
0    6.843455
dtype: float32
Epoch 202, train loss: 0.049254162954631385 test loss: 0.17126985456080576
0    6.825646
dtype: float32
Epoch 203, train loss: 0.05741723216319885 test loss: 0.1723843196680307
0    7.078758
dtype: float32
Epoch 204, train loss: 0.0473993868550115 test loss: 0.17179516119800722
0    6.886979
dtype: float32
Epoch 205, train loss: 0.051763109619854655 test loss: 0.171489323013096
0    7.09632
dtype: float32
Epoch 206, train loss: 0.04762782844842459 test loss: 0.17031788727672822
0    6.939967
dtype: float32
Epoch 207, train loss: 0.04689047708486183 test loss: 0.1699402399402495
0    7.046728
dtype: float32
Epoch 208, train loss: 0.04634499149816925 test loss: 0.17084143492488635
0    7.132746
dtype: float32
Epoch 209, train loss: 0.04661444982060723 test loss: 0.17032718493830185
0    6.888447
dtype: float32
Epoch 210, train loss: 0.05287601715548655 test loss: 0.17066110752906438
0    6.894004
dtype: float32
Epoch 211, train loss: 0.04543773804388711 test loss: 0.17005840892479288
0    7.07903
dtype: float32
Epoch 212, train loss: 0.046585121965623026 test loss: 0.17196826503376658
0    6.973456
dtype: float32
Epoch 213, train loss: 0.045138983634166324 test loss: 0.16926212345010963
0    7.287051
dtype: float32
Epoch 214, train loss: 0.07795708127916469 test loss: 0.17739760361503062
0    7.067805
dtype: float32
Epoch 215, train loss: 0.05430484931277635 test loss: 0.17076027515481623
0    7.011486
dtype: float32
Epoch 216, train loss: 0.04770906991959148 test loss: 0.17369042192270148
0    6.800744
dtype: float32
Epoch 217, train loss: 0.061528857509469306 test loss: 0.1724675527589592
0    6.978385
dtype: float32
Epoch 218, train loss: 0.04827156497354721 test loss: 0.17166453347678107
0    7.089931
dtype: float32
Epoch 219, train loss: 0.04558953787599875 test loss: 0.1720957091851056
0    6.963368
dtype: float32
Epoch 220, train loss: 0.04995137158833937 test loss: 0.17326511228434582
0    7.014192
dtype: float32
Epoch 221, train loss: 0.04469076454276402 test loss: 0.17059277911450632
0    7.004001
dtype: float32
Epoch 222, train loss: 0.04514634291346811 test loss: 0.1704044493535242
0    6.965746
dtype: float32
Epoch 223, train loss: 0.04798972796130335 test loss: 0.17218209169533513
0    7.023313
dtype: float32
Epoch 224, train loss: 0.044358020981249344 test loss: 0.17108761703768205
0    7.017097
dtype: float32
Epoch 225, train loss: 0.045069198483124635 test loss: 0.17157076690185724
0    7.092947
dtype: float32
Epoch 226, train loss: 0.05749275321162935 test loss: 0.18473509335373015
0    7.187496
dtype: float32
Epoch 227, train loss: 0.05090263315199449 test loss: 0.17158032577485688
0    7.091058
dtype: float32
Epoch 228, train loss: 0.04466007685733173 test loss: 0.17301088828884414
0    7.151189
dtype: float32
Epoch 229, train loss: 0.05001672540301948 test loss: 0.174507661796513
0    7.099293
dtype: float32
Epoch 230, train loss: 0.045970729100791294 test loss: 0.17111916695905802
0    6.939711
dtype: float32
Epoch 231, train loss: 0.04790047543690769 test loss: 0.17232842025295736
0    7.047385
dtype: float32
Epoch 232, train loss: 0.04503967238772618 test loss: 0.17057626469862736
0    6.974709
dtype: float32
Epoch 233, train loss: 0.04903508066274232 test loss: 0.17236577105142242
0    7.072045
dtype: float32
Epoch 234, train loss: 0.047528968653061714 test loss: 0.17345244848332927
0    6.816961
dtype: float32
Epoch 235, train loss: 0.061692103377966004 test loss: 0.17568080954913642
0    7.228438
dtype: float32
Epoch 236, train loss: 0.0566742812617 test loss: 0.17310403426185061
0    7.140517
dtype: float32
Epoch 237, train loss: 0.044873532399158915 test loss: 0.17170000430602525
0    7.044049
dtype: float32
Epoch 238, train loss: 0.053164920039507554 test loss: 0.17620708083976228
0    6.826031
dtype: float32
Epoch 239, train loss: 0.048626249907094514 test loss: 0.17049546445715585
0    6.713078
dtype: float32
Epoch 240, train loss: 0.06967688253845286 test loss: 0.1727980581660595
0    6.934071
dtype: float32
Epoch 241, train loss: 0.04796982521854582 test loss: 0.16840105024254204
0    6.997917
dtype: float32
Epoch 242, train loss: 0.046492240270719236 test loss: 0.16950833399124332
0    7.055051
dtype: float32
Epoch 243, train loss: 0.043919818465692685 test loss: 0.1697549783798513
0    7.033236
dtype: float32
Epoch 244, train loss: 0.04395513056785604 test loss: 0.17048883303156168
0    7.109211
dtype: float32
Epoch 245, train loss: 0.04520220894926076 test loss: 0.17258907354915376
0    7.024725
dtype: float32
Epoch 246, train loss: 0.04797960108610122 test loss: 0.17195321087741688
0    6.633229
dtype: float32
Epoch 247, train loss: 0.07242804949994791 test loss: 0.17485798688035567
0    7.229671
dtype: float32
Epoch 248, train loss: 0.04792950732381726 test loss: 0.17132334542078637
0    7.146375
dtype: float32
Epoch 249, train loss: 0.05612002632122179 test loss: 0.17326060752701744
0    7.08244
dtype: float32
Epoch 250, train loss: 0.046425562099715524 test loss: 0.16939284073067012
0    6.765846
dtype: float32
Epoch 251, train loss: 0.07512253572461312 test loss: 0.17998556385932826
0    6.927006
dtype: float32
Epoch 252, train loss: 0.0513060414428804 test loss: 0.17449830642727482
0    6.912424
dtype: float32
Epoch 253, train loss: 0.051359148600733505 test loss: 0.17330604806295175
0    6.751934
dtype: float32
Epoch 254, train loss: 0.069629679829251 test loss: 0.175404498484239
0    7.215065
dtype: float32
Epoch 255, train loss: 0.04640874197213016 test loss: 0.171885220894512
0    7.300922
dtype: float32
Epoch 256, train loss: 0.060359625130777535 test loss: 0.17682291414344492
0    6.785761
dtype: float32
Epoch 257, train loss: 0.05140840847162648 test loss: 0.17187261990446093
0    6.963642
dtype: float32
Epoch 258, train loss: 0.04595047242767393 test loss: 0.173713221096872
0    7.176198
dtype: float32
Epoch 259, train loss: 0.05286468408265262 test loss: 0.17305917876280155
0    7.119565
dtype: float32
Epoch 260, train loss: 0.04655295892410089 test loss: 0.17091944331665793
0    7.213768
dtype: float32
Epoch 261, train loss: 0.0597233226598996 test loss: 0.17093626960246244
0    6.920281
dtype: float32
Epoch 262, train loss: 0.04410197747508196 test loss: 0.1712307843958522
0    6.98527
dtype: float32
Epoch 263, train loss: 0.04573929248368575 test loss: 0.17371543150406177
0    6.872733
dtype: float32
Epoch 264, train loss: 0.04414491175111899 test loss: 0.1716404898374083
0    6.963956
dtype: float32
Epoch 265, train loss: 0.04305516547112889 test loss: 0.1730504919677762
0    6.810152
dtype: float32
Epoch 266, train loss: 0.05080995404820764 test loss: 0.17447416423729453
0    6.99058
dtype: float32
Epoch 267, train loss: 0.04811921458431849 test loss: 0.17416719453056484
0    7.073382
dtype: float32
Epoch 268, train loss: 0.04357431422846792 test loss: 0.17466258167329496
0    7.08841
dtype: float32
Epoch 269, train loss: 0.04477837204565465 test loss: 0.17657162376678168
0    6.862183
dtype: float32
Epoch 270, train loss: 0.04748570005040996 test loss: 0.17284276363086745
0    7.199036
dtype: float32
Epoch 271, train loss: 0.052572952890810126 test loss: 0.17448922383264726
0    6.85933
dtype: float32
Epoch 272, train loss: 0.047379876725821536 test loss: 0.17175704339817766
0    6.964976
dtype: float32
Epoch 273, train loss: 0.04503847958777894 test loss: 0.17260458841740736
0    6.989092
dtype: float32
Epoch 274, train loss: 0.04256464746265656 test loss: 0.1714556748791403
0    7.127285
dtype: float32
Epoch 275, train loss: 0.04994643347320885 test loss: 0.1771942137966472
0    7.16421
dtype: float32
Epoch 276, train loss: 0.04596369633217998 test loss: 0.1720762689672637
0    6.854941
dtype: float32
Epoch 277, train loss: 0.04730064816844198 test loss: 0.1705068130910038
0    7.033095
dtype: float32
Epoch 278, train loss: 0.04372226258873298 test loss: 0.1724398589464883
0    7.068881
dtype: float32
Epoch 279, train loss: 0.044131240593390415 test loss: 0.1702847740485983
0    6.947272
dtype: float32
Epoch 280, train loss: 0.045099573006168396 test loss: 0.17317768313695636
0    6.853317
dtype: float32
Epoch 281, train loss: 0.04559400868695933 test loss: 0.17140978041535657
0    7.383592
dtype: float32
Epoch 282, train loss: 0.0595623968886879 test loss: 0.17741588785499549
0    7.132664
dtype: float32
Epoch 283, train loss: 0.04373166266463047 test loss: 0.17066996740638812
0    7.105116
dtype: float32
Epoch 284, train loss: 0.04342478904512216 test loss: 0.16960779091064002
0    6.79247
dtype: float32
Epoch 285, train loss: 0.04973412111714183 test loss: 0.16965617726500806
0    7.117371
dtype: float32
Epoch 286, train loss: 0.0465201886515321 test loss: 0.16870786799003754
0    6.973403
dtype: float32
Epoch 287, train loss: 0.04305570464674203 test loss: 0.16994495823531422
0    7.195034
dtype: float32
Epoch 288, train loss: 0.04503712306594406 test loss: 0.17017743231436355
0    7.043019
dtype: float32
Epoch 289, train loss: 0.04359002407395312 test loss: 0.17185064992032736
0    6.800883
dtype: float32
Epoch 290, train loss: 0.06203458564384143 test loss: 0.1741783759751174
0    6.91319
dtype: float32
Epoch 291, train loss: 0.051080919156187204 test loss: 0.17349029504383626
0    7.136783
dtype: float32
Epoch 292, train loss: 0.044126658901997184 test loss: 0.17404601857406893
0    7.127439
dtype: float32
Epoch 293, train loss: 0.04727370867934144 test loss: 0.17217233300809423
0    6.884277
dtype: float32
Epoch 294, train loss: 0.044921002063082326 test loss: 0.17255401091662245
0    6.951831
dtype: float32
Epoch 295, train loss: 0.04182025726364821 test loss: 0.17208302881194373
0    7.246985
dtype: float32
Epoch 296, train loss: 0.04948419966245129 test loss: 0.1750514750675004
0    7.369122
dtype: float32
Epoch 297, train loss: 0.06446770072772359 test loss: 0.17715938970117132
0    7.211855
dtype: float32
Epoch 298, train loss: 0.04801493943493803 test loss: 0.17494806221656428
0    7.051012
dtype: float32
Epoch 299, train loss: 0.04616762106837479 test loss: 0.1710846832300632
Final train loss is: 0.04616762106837479, Test loss is: 0.1710846832300632
0    7.051012
dtype: float32
round is 1
0    4.698959
dtype: float32
Epoch 32, train loss: 0.3782506228820787 test loss: 0.4293765228602189
0    4.916676
dtype: float32
Epoch 33, train loss: 0.33991605401440955 test loss: 0.3846560037453754
0    5.145226
dtype: float32
Epoch 34, train loss: 0.31102260503444706 test loss: 0.3817990106361845
0    5.468942
dtype: float32
Epoch 35, train loss: 0.2925238192148263 test loss: 0.3214048668479005
0    5.68965
dtype: float32
Epoch 36, train loss: 0.30345327616377815 test loss: 0.38073970422950804
0    5.930285
dtype: float32
Epoch 37, train loss: 0.22772965171043572 test loss: 0.2793584559860241
0    6.11963
dtype: float32
Epoch 38, train loss: 0.19883160998789282 test loss: 0.2867029905398857
0    6.316795
dtype: float32
Epoch 39, train loss: 0.1893855735659019 test loss: 0.2438715108071143
0    6.4095
dtype: float32
Epoch 40, train loss: 0.242321885134975 test loss: 0.31878163089235134
0    6.609583
dtype: float32
Epoch 41, train loss: 0.16446505995776814 test loss: 0.24204255771640865
0    6.678653
dtype: float32
Epoch 42, train loss: 0.2172776427681593 test loss: 0.2865830768281972
0    6.649733
dtype: float32
Epoch 43, train loss: 0.2766896083095173 test loss: 0.3507985806658328
0    7.045751
dtype: float32
Epoch 44, train loss: 0.15507865742826288 test loss: 0.22839042332850074
0    7.145444
dtype: float32
Epoch 45, train loss: 0.14141892412141158 test loss: 0.238933239330486
0    7.287443
dtype: float32
Epoch 46, train loss: 0.13231474012134392 test loss: 0.21298949608755172
0    7.329415
dtype: float32
Epoch 47, train loss: 0.13313189858862057 test loss: 0.2237891066400357
0    7.434552
dtype: float32
Epoch 48, train loss: 0.1265575742599579 test loss: 0.20248998308596453
0    7.499789
dtype: float32
Epoch 49, train loss: 0.13235357969712014 test loss: 0.1976233565892274
0    7.498222
dtype: float32
Epoch 50, train loss: 0.12734508716939272 test loss: 0.20868925242828357
0    7.540182
dtype: float32
Epoch 51, train loss: 0.121018956244724 test loss: 0.20342161321494592
0    7.597171
dtype: float32
Epoch 52, train loss: 0.1507924695986187 test loss: 0.1850955722237494
0    7.57233
dtype: float32
Epoch 53, train loss: 0.12350513148137855 test loss: 0.2036322002680334
0    7.647917
dtype: float32
Epoch 54, train loss: 0.12637833052978922 test loss: 0.18096246637790536
0    7.657749
dtype: float32
Epoch 55, train loss: 0.11638752184678121 test loss: 0.18238416041348818
0    7.611917
dtype: float32
Epoch 56, train loss: 0.18331918038186962 test loss: 0.22790521596915858
0    7.679169
dtype: float32
Epoch 57, train loss: 0.12687732982202438 test loss: 0.19335267756542915
0    7.663085
dtype: float32
Epoch 58, train loss: 0.13675221428004783 test loss: 0.19852884706098223
0    7.700629
dtype: float32
Epoch 59, train loss: 0.13029581818504857 test loss: 0.1917800351262885
0    7.764557
dtype: float32
Epoch 60, train loss: 0.11606430662863985 test loss: 0.16960621503363707
0    7.688108
dtype: float32
Epoch 61, train loss: 0.13333566333173794 test loss: 0.19212617299669155
0    7.718478
dtype: float32
Epoch 62, train loss: 0.11395557565275634 test loss: 0.1812062897913183
0    7.675659
dtype: float32
Epoch 63, train loss: 0.11412345066339415 test loss: 0.18526686232630019
0    7.692312
dtype: float32
Epoch 64, train loss: 0.11051222925361748 test loss: 0.17916439915641988
0    7.729143
dtype: float32
Epoch 65, train loss: 0.10811693403415597 test loss: 0.16606254174517382
0    7.707658
dtype: float32
Epoch 66, train loss: 0.1181147037141522 test loss: 0.18098476547459574
0    7.75507
dtype: float32
Epoch 67, train loss: 0.11490722278949647 test loss: 0.16997776116332655
0    7.724437
dtype: float32
Epoch 68, train loss: 0.1091472118059921 test loss: 0.16931194264402696
0    7.699229
dtype: float32
Epoch 69, train loss: 0.10579445797469952 test loss: 0.1725289711676661
0    7.671662
dtype: float32
Epoch 70, train loss: 0.1277474871109427 test loss: 0.1923176146661784
0    7.700734
dtype: float32
Epoch 71, train loss: 0.1050295543427149 test loss: 0.16919188023661139
0    7.703716
dtype: float32
Epoch 72, train loss: 0.10377408049958332 test loss: 0.16928204250931297
0    7.729275
dtype: float32
Epoch 73, train loss: 0.11694214953002209 test loss: 0.16197206708983267
0    7.707216
dtype: float32
Epoch 74, train loss: 0.1031180481339487 test loss: 0.17210251201344548
0    7.735948
dtype: float32
Epoch 75, train loss: 0.11587032052100839 test loss: 0.16371510374083112
0    7.752804
dtype: float32
Epoch 76, train loss: 0.11570044670148895 test loss: 0.15931157285927738
0    7.717002
dtype: float32
Epoch 77, train loss: 0.10156073626635459 test loss: 0.16382909247859
0    7.713175
dtype: float32
Epoch 78, train loss: 0.10132437214641067 test loss: 0.15784011448140156
0    7.718234
dtype: float32
Epoch 79, train loss: 0.10808833819954648 test loss: 0.16019516987386007
0    7.687915
dtype: float32
Epoch 80, train loss: 0.10345235214810157 test loss: 0.16269551457494796
0    7.695152
dtype: float32
Epoch 81, train loss: 0.10078983838370663 test loss: 0.16552966346767667
0    7.69054
dtype: float32
Epoch 82, train loss: 0.0998888345259082 test loss: 0.16527105733270844
0    7.693404
dtype: float32
Epoch 83, train loss: 0.10039740951021363 test loss: 0.16517701158909137
0    7.670441
dtype: float32
Epoch 84, train loss: 0.127751588053041 test loss: 0.1840068684459175
0    7.679881
dtype: float32
Epoch 85, train loss: 0.10891806588140598 test loss: 0.17301383295046646
0    7.703277
dtype: float32
Epoch 86, train loss: 0.11409425960269083 test loss: 0.15740963720267367
0    7.713355
dtype: float32
Epoch 87, train loss: 0.0990949323734611 test loss: 0.16146797622010794
0    7.678938
dtype: float32
Epoch 88, train loss: 0.10456780410415156 test loss: 0.16828859243204985
0    7.704388
dtype: float32
Epoch 89, train loss: 0.10024126399667092 test loss: 0.16588458390089778
0    7.673505
dtype: float32
Epoch 90, train loss: 0.15014378699906464 test loss: 0.19230746832923357
0    7.773244
dtype: float32
Epoch 91, train loss: 0.10532445722643091 test loss: 0.15886688488703904
0    7.707853
dtype: float32
Epoch 92, train loss: 0.15449844805562257 test loss: 0.183849953066184
0    7.779078
dtype: float32
Epoch 93, train loss: 0.1005214665828746 test loss: 0.15707819642192036
0    7.735163
dtype: float32
Epoch 94, train loss: 0.11524917820527412 test loss: 0.16708702900094646
0    7.7402
dtype: float32
Epoch 95, train loss: 0.09869541489422994 test loss: 0.15620988832896276
0    7.719172
dtype: float32
Epoch 96, train loss: 0.09733474007827347 test loss: 0.15629931826004945
0    7.723591
dtype: float32
Epoch 97, train loss: 0.09622040784541575 test loss: 0.15581083720673336
0    7.734519
dtype: float32
Epoch 98, train loss: 0.10358652151274025 test loss: 0.15324769149696213
0    7.699545
dtype: float32
Epoch 99, train loss: 0.09645617219372098 test loss: 0.15576722903654552
0    7.688642
dtype: float32
Epoch 100, train loss: 0.0989444803983708 test loss: 0.162169152887367
0    7.656415
dtype: float32
Epoch 101, train loss: 0.14107120507000123 test loss: 0.18263900974315403
0    7.719781
dtype: float32
Epoch 102, train loss: 0.10062578490924762 test loss: 0.15260925631666447
0    7.71007
dtype: float32
Epoch 103, train loss: 0.10510855696632189 test loss: 0.15979342809619104
0    7.761676
dtype: float32
Epoch 104, train loss: 0.09953234265592958 test loss: 0.15298528638177541
0    7.712506
dtype: float32
Epoch 105, train loss: 0.0956557011931032 test loss: 0.14900799539903545
0    7.70074
dtype: float32
Epoch 106, train loss: 0.10558707754884626 test loss: 0.160863487600818
0    7.713488
dtype: float32
Epoch 107, train loss: 0.09518002180912731 test loss: 0.15329614206427858
0    7.703826
dtype: float32
Epoch 108, train loss: 0.096348361785092 test loss: 0.14902847448881695
0    7.651587
dtype: float32
Epoch 109, train loss: 0.15845621646913477 test loss: 0.18648028238455444
0    7.760521
dtype: float32
Epoch 110, train loss: 0.09849864427905959 test loss: 0.14339770219551412
0    7.761091
dtype: float32
Epoch 111, train loss: 0.10429240885864441 test loss: 0.14383172477109163
0    7.721635
dtype: float32
Epoch 112, train loss: 0.09710779311775099 test loss: 0.15064953662691036
0    7.665103
dtype: float32
Epoch 113, train loss: 0.1774575773632304 test loss: 0.1952725982061603
0    7.731175
dtype: float32
Epoch 114, train loss: 0.10250968493148689 test loss: 0.14546736974113664
0    7.713495
dtype: float32
Epoch 115, train loss: 0.10051880137360528 test loss: 0.15582611409400363
0    7.733174
dtype: float32
Epoch 116, train loss: 0.09436510974946427 test loss: 0.1469431549202246
0    7.698742
dtype: float32
Epoch 117, train loss: 0.09661615242082802 test loss: 0.1539647807657255
0    7.703756
dtype: float32
Epoch 118, train loss: 0.09272878486314036 test loss: 0.14866740420928848
0    7.717205
dtype: float32
Epoch 119, train loss: 0.09436491360885646 test loss: 0.14387463768336878
0    7.694258
dtype: float32
Epoch 120, train loss: 0.10531795794385866 test loss: 0.14016123811977355
0    7.720227
dtype: float32
Epoch 121, train loss: 0.09243127000457434 test loss: 0.14261174537849045
0    7.735141
dtype: float32
Epoch 122, train loss: 0.10847861886427343 test loss: 0.13914779312291514
0    7.691244
dtype: float32
Epoch 123, train loss: 0.11444128683465773 test loss: 0.1550972508128288
0    7.747794
dtype: float32
Epoch 124, train loss: 0.09575556087871734 test loss: 0.14009431343955517
0    7.746692
dtype: float32
Epoch 125, train loss: 0.09382841277608092 test loss: 0.14317828477741268
0    7.714193
dtype: float32
Epoch 126, train loss: 0.0946244996551014 test loss: 0.14187940198444918
0    7.723376
dtype: float32
Epoch 127, train loss: 0.10004428522900297 test loss: 0.14732895399730084
0    7.653861
dtype: float32
Epoch 128, train loss: 0.1115695073051373 test loss: 0.15869570781113318
0    7.641471
dtype: float32
Epoch 129, train loss: 0.11490123824591253 test loss: 0.16334749605651766
0    7.674326
dtype: float32
Epoch 130, train loss: 0.10978770586790672 test loss: 0.1574867133939555
0    7.685186
dtype: float32
Epoch 131, train loss: 0.09457181149107055 test loss: 0.1481433691147215
0    7.686348
dtype: float32
Epoch 132, train loss: 0.09709857600709046 test loss: 0.14400779165274932
0    7.689507
dtype: float32
Epoch 133, train loss: 0.09246716102261722 test loss: 0.1398066169950173
0    7.738223
dtype: float32
Epoch 134, train loss: 0.09771747476855382 test loss: 0.14312850456883186
0    7.64981
dtype: float32
Epoch 135, train loss: 0.1882271303371484 test loss: 0.19577177318262226
0    7.794667
dtype: float32
Epoch 136, train loss: 0.09371580537619434 test loss: 0.1427666241106826
0    7.747785
dtype: float32
Epoch 137, train loss: 0.0925896156494286 test loss: 0.14619029725698268
0    7.774665
dtype: float32
Epoch 138, train loss: 0.09217497224103634 test loss: 0.14547069080081812
0    7.717279
dtype: float32
Epoch 139, train loss: 0.17556906938974565 test loss: 0.1899509985443191
0    7.840677
dtype: float32
Epoch 140, train loss: 0.09885373879736885 test loss: 0.14020605759103685
0    7.788387
dtype: float32
Epoch 141, train loss: 0.0941592769302511 test loss: 0.14615978806620278
0    7.794522
dtype: float32
Epoch 142, train loss: 0.09368370121152506 test loss: 0.1447110486204757
0    7.806475
dtype: float32
Epoch 143, train loss: 0.11189687468478213 test loss: 0.1426056739688654
0    7.762908
dtype: float32
Epoch 144, train loss: 0.09282115438274512 test loss: 0.14135871125829433
0    7.784369
dtype: float32
Epoch 145, train loss: 0.09182865152434984 test loss: 0.142604327664761
0    7.74948
dtype: float32
Epoch 146, train loss: 0.09156377400546115 test loss: 0.1433771321284274
0    7.750488
dtype: float32
Epoch 147, train loss: 0.1041505105054659 test loss: 0.13997057060459522
0    7.696589
dtype: float32
Epoch 148, train loss: 0.11512139096034725 test loss: 0.1593565655608304
0    7.689157
dtype: float32
Epoch 149, train loss: 0.16259466186293672 test loss: 0.17731698194817552
0    7.708046
dtype: float32
Epoch 150, train loss: 0.11546782531867932 test loss: 0.15959883365383556
0    7.71695
dtype: float32
Epoch 151, train loss: 0.09086551631521383 test loss: 0.14270844392971269
0    7.727064
dtype: float32
Epoch 152, train loss: 0.09625413313444176 test loss: 0.1395705819329985
0    7.736087
dtype: float32
Epoch 153, train loss: 0.09146537087184406 test loss: 0.14377338646923304
0    7.736234
dtype: float32
Epoch 154, train loss: 0.09413675207371966 test loss: 0.1399535764362797
0    7.754798
dtype: float32
Epoch 155, train loss: 0.10086063540828691 test loss: 0.13817561138779533
0    7.701569
dtype: float32
Epoch 156, train loss: 0.12053961135398525 test loss: 0.16100966717022588
0    7.702894
dtype: float32
Epoch 157, train loss: 0.14357481698234523 test loss: 0.17129937109838644
0    7.786768
dtype: float32
Epoch 158, train loss: 0.09881293233801451 test loss: 0.14759369568545488
0    7.783143
dtype: float32
Epoch 159, train loss: 0.1044290317030366 test loss: 0.14253379611219927
0    7.743576
dtype: float32
Epoch 160, train loss: 0.09232014582597141 test loss: 0.14545570661398455
0    7.757657
dtype: float32
Epoch 161, train loss: 0.10270732029482833 test loss: 0.13819269253566646
0    7.680837
dtype: float32
Epoch 162, train loss: 0.1189155882359463 test loss: 0.16250432584000932
0    7.724867
dtype: float32
Epoch 163, train loss: 0.09033491713362243 test loss: 0.13996944549395285
0    7.729718
dtype: float32
Epoch 164, train loss: 0.11190275638135729 test loss: 0.14231340384028235
0    7.716266
dtype: float32
Epoch 165, train loss: 0.08945027660059895 test loss: 0.14006838927923787
0    7.73296
dtype: float32
Epoch 166, train loss: 0.09724228021832841 test loss: 0.13716528000602032
0    7.739615
dtype: float32
Epoch 167, train loss: 0.1352754935538479 test loss: 0.14473006355802878
0    7.689576
dtype: float32
Epoch 168, train loss: 0.09299462492758719 test loss: 0.1396446769469167
0    7.685143
dtype: float32
Epoch 169, train loss: 0.09222909429697591 test loss: 0.14043241553633837
0    7.617486
dtype: float32
Epoch 170, train loss: 0.1564659473504653 test loss: 0.1756242517204227
0    7.657187
dtype: float32
Epoch 171, train loss: 0.11889890913395991 test loss: 0.16295210922417994
0    7.653835
dtype: float32
Epoch 172, train loss: 0.097626739861775 test loss: 0.14681852649729238
0    7.64907
dtype: float32
Epoch 173, train loss: 0.10929265758933362 test loss: 0.14980916214400233
0    7.737535
dtype: float32
Epoch 174, train loss: 0.09702102781873481 test loss: 0.13084336008272235
0    7.737963
dtype: float32
Epoch 175, train loss: 0.09428742944761388 test loss: 0.135888865333118
0    7.718544
dtype: float32
Epoch 176, train loss: 0.09367204068239868 test loss: 0.14714349381915942
0    7.729548
dtype: float32
Epoch 177, train loss: 0.09563443087856319 test loss: 0.14117230994126131
0    7.72359
dtype: float32
Epoch 178, train loss: 0.09077837612144922 test loss: 0.14525089739206004
0    7.715379
dtype: float32
Epoch 179, train loss: 0.10274529161484522 test loss: 0.13863174615702104
0    7.691825
dtype: float32
Epoch 180, train loss: 0.09018453045730093 test loss: 0.13796527935264236
0    7.691985
dtype: float32
Epoch 181, train loss: 0.09250173244237674 test loss: 0.13961812554893677
0    7.636938
dtype: float32
Epoch 182, train loss: 0.09283643955610331 test loss: 0.14227932490624337
0    7.664817
dtype: float32
Epoch 183, train loss: 0.09672782547236122 test loss: 0.1371883227391458
0    7.650136
dtype: float32
Epoch 184, train loss: 0.09315540417016947 test loss: 0.13668079279547088
0    7.638687
dtype: float32
Epoch 185, train loss: 0.08690675674314129 test loss: 0.1381115723397299
0    7.632488
dtype: float32
Epoch 186, train loss: 0.08972097427303923 test loss: 0.1423500751031346
0    7.633398
dtype: float32
Epoch 187, train loss: 0.08680103245601556 test loss: 0.13974149353297008
0    7.648184
dtype: float32
Epoch 188, train loss: 0.08994605134526784 test loss: 0.14068680236168213
0    7.642159
dtype: float32
Epoch 189, train loss: 0.08837816793272588 test loss: 0.14571587749108367
0    7.631281
dtype: float32
Epoch 190, train loss: 0.08644417513989759 test loss: 0.1360637745240161
0    7.61769
dtype: float32
Epoch 191, train loss: 0.08700243012322274 test loss: 0.13654818572277982
0    7.604147
dtype: float32
Epoch 192, train loss: 0.0885245039833436 test loss: 0.14202823224223715
0    7.621977
dtype: float32
Epoch 193, train loss: 0.08900502570370322 test loss: 0.14000902512507668
0    7.612734
dtype: float32
Epoch 194, train loss: 0.12477538356516289 test loss: 0.15921595366304828
0    7.633398
dtype: float32
Epoch 195, train loss: 0.09644161685593608 test loss: 0.13128518992809785
0    7.597585
dtype: float32
Epoch 196, train loss: 0.08922668427377156 test loss: 0.14065717362555258
0    7.633675
dtype: float32
Epoch 197, train loss: 0.08896290008221829 test loss: 0.14009205623963264
0    7.616325
dtype: float32
Epoch 198, train loss: 0.09206365455756456 test loss: 0.1448298748485155
0    7.608549
dtype: float32
Epoch 199, train loss: 0.095208896549042 test loss: 0.1443013214034129
0    7.62513
dtype: float32
Epoch 200, train loss: 0.09132713432405012 test loss: 0.14355100742407506
0    7.641301
dtype: float32
Epoch 201, train loss: 0.10320970016806558 test loss: 0.13287646285780427
0    7.617794
dtype: float32
Epoch 202, train loss: 0.09232441028274686 test loss: 0.13901647869883846
0    7.605822
dtype: float32
Epoch 203, train loss: 0.16723506943137062 test loss: 0.17258149009532742
0    7.764172
dtype: float32
Epoch 204, train loss: 0.1127596385467292 test loss: 0.1353709809204954
0    7.74391
dtype: float32
Epoch 205, train loss: 0.08737753134829783 test loss: 0.13853873272531433
0    7.725863
dtype: float32
Epoch 206, train loss: 0.09417881521112355 test loss: 0.13480088669567056
0    7.682339
dtype: float32
Epoch 207, train loss: 0.08605275433622304 test loss: 0.13624920747637903
0    7.65066
dtype: float32
Epoch 208, train loss: 0.09204097131634595 test loss: 0.14020029371660303
0    7.654642
dtype: float32
Epoch 209, train loss: 0.08863937097056794 test loss: 0.1378858136312659
0    7.701653
dtype: float32
Epoch 210, train loss: 0.09368740803147595 test loss: 0.1281404468788597
0    7.715707
dtype: float32
Epoch 211, train loss: 0.09378861752925494 test loss: 0.13107226391017515
0    7.67832
dtype: float32
Epoch 212, train loss: 0.09090777483471178 test loss: 0.13699394809458945
0    7.721568
dtype: float32
Epoch 213, train loss: 0.11387152054447465 test loss: 0.13512854923286172
0    7.731334
dtype: float32
Epoch 214, train loss: 0.09327405615126719 test loss: 0.1394226022819035
0    7.71874
dtype: float32
Epoch 215, train loss: 0.09276318099793036 test loss: 0.13501513535722118
0    7.721722
dtype: float32
Epoch 216, train loss: 0.0873888722653856 test loss: 0.13618317067059435
0    7.682612
dtype: float32
Epoch 217, train loss: 0.08626254362235079 test loss: 0.13434728292224174
0    7.674348
dtype: float32
Epoch 218, train loss: 0.08661363723849386 test loss: 0.1340515914033813
0    7.637345
dtype: float32
Epoch 219, train loss: 0.08562895218722283 test loss: 0.13494004660206182
0    7.654387
dtype: float32
Epoch 220, train loss: 0.08585566955027138 test loss: 0.13930163179458588
0    7.640981
dtype: float32
Epoch 221, train loss: 0.08791147085232018 test loss: 0.13608395164033632
0    7.631286
dtype: float32
Epoch 222, train loss: 0.08510558916029543 test loss: 0.1393190162264076
0    7.654453
dtype: float32
Epoch 223, train loss: 0.1163063949639427 test loss: 0.14113956471328493
0    7.615516
dtype: float32
Epoch 224, train loss: 0.08935974128433154 test loss: 0.14190289954286348
0    7.627625
dtype: float32
Epoch 225, train loss: 0.08778845486957929 test loss: 0.13388366051376144
0    7.611968
dtype: float32
Epoch 226, train loss: 0.09770210554774951 test loss: 0.1438115614440708
0    7.616892
dtype: float32
Epoch 227, train loss: 0.09491991252163538 test loss: 0.14184892541733016
0    7.693123
dtype: float32
Epoch 228, train loss: 0.09087421262075898 test loss: 0.13435968150648153
0    7.666699
dtype: float32
Epoch 229, train loss: 0.08702658887238726 test loss: 0.12990944592693254
0    7.705605
dtype: float32
Epoch 230, train loss: 0.0964001896115113 test loss: 0.1316148834344801
0    7.667707
dtype: float32
Epoch 231, train loss: 0.09159553207463739 test loss: 0.13863746662974283
0    7.645779
dtype: float32
Epoch 232, train loss: 0.108307694735896 test loss: 0.14549869682623964
0    7.634954
dtype: float32
Epoch 233, train loss: 0.10453718110827075 test loss: 0.14938431251057555
0    7.637881
dtype: float32
Epoch 234, train loss: 0.08829621542174491 test loss: 0.13572043866111627
0    7.657442
dtype: float32
Epoch 235, train loss: 0.08656147296114314 test loss: 0.1358663087537529
0    7.672686
dtype: float32
Epoch 236, train loss: 0.09176128932243463 test loss: 0.13185037098896288
0    7.656305
dtype: float32
Epoch 237, train loss: 0.08524294077971058 test loss: 0.13269691279672305
0    7.627405
dtype: float32
Epoch 238, train loss: 0.08406879566421654 test loss: 0.13443554246258493
0    7.616163
dtype: float32
Epoch 239, train loss: 0.08747655224518197 test loss: 0.13214338655604121
0    7.691119
dtype: float32
Epoch 240, train loss: 0.14306563878594447 test loss: 0.1541742436015322
0    7.650169
dtype: float32
Epoch 241, train loss: 0.09137268823070535 test loss: 0.1368203197446768
0    7.656529
dtype: float32
Epoch 242, train loss: 0.09145582178802728 test loss: 0.13018811252923254
0    7.638268
dtype: float32
Epoch 243, train loss: 0.0843811151917129 test loss: 0.1322945714748371
0    7.654316
dtype: float32
Epoch 244, train loss: 0.1079378692515542 test loss: 0.13424743611311102
0    7.648092
dtype: float32
Epoch 245, train loss: 0.08823430554846926 test loss: 0.13206611393964948
0    7.673636
dtype: float32
Epoch 246, train loss: 0.09617640964158213 test loss: 0.13885509018372438
0    7.613469
dtype: float32
Epoch 247, train loss: 0.08415113722618538 test loss: 0.13493506213822495
0    7.604352
dtype: float32
Epoch 248, train loss: 0.08436874158228297 test loss: 0.12976045751561677
0    7.599642
dtype: float32
Epoch 249, train loss: 0.08651185186445005 test loss: 0.1370698158761074
0    7.616058
dtype: float32
Epoch 250, train loss: 0.08406511252323073 test loss: 0.1314386937873664
0    7.595084
dtype: float32
Epoch 251, train loss: 0.1006875843712127 test loss: 0.1427581464714562
0    7.664752
dtype: float32
Epoch 252, train loss: 0.16028716743803093 test loss: 0.16558638788383842
0    7.641589
dtype: float32
Epoch 253, train loss: 0.08752453323845617 test loss: 0.13726017036018262
0    7.655881
dtype: float32
Epoch 254, train loss: 0.08668843766497403 test loss: 0.13831233759270908
0    7.63186
dtype: float32
Epoch 255, train loss: 0.08669717664149167 test loss: 0.1381834257528154
0    7.636211
dtype: float32
Epoch 256, train loss: 0.08865805928899055 test loss: 0.13435768286667815
0    7.660274
dtype: float32
Epoch 257, train loss: 0.10289459163549235 test loss: 0.13250298588560055
0    7.658855
dtype: float32
Epoch 258, train loss: 0.08828252143814903 test loss: 0.14328895501276173
0    7.645961
dtype: float32
Epoch 259, train loss: 0.08473710184628003 test loss: 0.13819382303156438
0    7.749282
dtype: float32
Epoch 260, train loss: 0.09017635904456668 test loss: 0.13677000074703669
0    7.717517
dtype: float32
Epoch 261, train loss: 0.08578525545929724 test loss: 0.1436577219234235
0    7.650245
dtype: float32
Epoch 262, train loss: 0.11546166877450204 test loss: 0.15526867745258854
0    7.713194
dtype: float32
Epoch 263, train loss: 0.08779854574468345 test loss: 0.1470146139319578
0    7.676447
dtype: float32
Epoch 264, train loss: 0.08658195765444153 test loss: 0.14956417514905712
0    7.697011
dtype: float32
Epoch 265, train loss: 0.0859608522655592 test loss: 0.15017893475218672
0    7.692609
dtype: float32
Epoch 266, train loss: 0.09864485340659584 test loss: 0.14654681885892085
0    7.646439
dtype: float32
Epoch 267, train loss: 0.11584308075784311 test loss: 0.16542154219902266
0    7.650959
dtype: float32
Epoch 268, train loss: 0.0889448683529028 test loss: 0.15322260875022325
0    7.637478
dtype: float32
Epoch 269, train loss: 0.0871975526049961 test loss: 0.14967706953919796
0    7.621469
dtype: float32
Epoch 270, train loss: 0.08791868598441453 test loss: 0.15082140102666283
0    7.613223
dtype: float32
Epoch 271, train loss: 0.08586959346187019 test loss: 0.148690521077888
0    7.627827
dtype: float32
Epoch 272, train loss: 0.08733971047225755 test loss: 0.1452966427745884
0    7.64467
dtype: float32
Epoch 273, train loss: 0.08778071083711937 test loss: 0.14755013375291787
0    7.608102
dtype: float32
Epoch 274, train loss: 0.12681435850538506 test loss: 0.15929442456323303
0    7.674517
dtype: float32
Epoch 275, train loss: 0.08655814233618739 test loss: 0.1445174621690667
0    7.667034
dtype: float32
Epoch 276, train loss: 0.08584943941229906 test loss: 0.13991247438409934
0    7.68268
dtype: float32
Epoch 277, train loss: 0.10096669126017843 test loss: 0.13916709030219934
0    7.679847
dtype: float32
Epoch 278, train loss: 0.10864747237737739 test loss: 0.14008133852225407
0    7.651083
dtype: float32
Epoch 279, train loss: 0.08529695962451574 test loss: 0.13580768569299065
0    7.664787
dtype: float32
Epoch 280, train loss: 0.08764575062573124 test loss: 0.13516749934913055
0    7.629396
dtype: float32
Epoch 281, train loss: 0.10134337721702114 test loss: 0.1471867157278673
0    7.625764
dtype: float32
Epoch 282, train loss: 0.12288388425642119 test loss: 0.1556658053154146
0    7.664994
dtype: float32
Epoch 283, train loss: 0.08641586768637972 test loss: 0.13589817315964925
0    7.647891
dtype: float32
Epoch 284, train loss: 0.11076582399044493 test loss: 0.15009002159297827
0    7.654914
dtype: float32
Epoch 285, train loss: 0.0839227046084661 test loss: 0.1356296105703318
0    7.67045
dtype: float32
Epoch 286, train loss: 0.09502906951597324 test loss: 0.1314512235219762
0    7.631953
dtype: float32
Epoch 287, train loss: 0.1087670488603606 test loss: 0.14798680408356601
0    7.673802
dtype: float32
Epoch 288, train loss: 0.10509625962997551 test loss: 0.14054778360502962
0    7.657343
dtype: float32
Epoch 289, train loss: 0.08687966160543144 test loss: 0.12630085909176467
0    7.673456
dtype: float32
Epoch 290, train loss: 0.08860413165706674 test loss: 0.12974046727337923
0    7.667917
dtype: float32
Epoch 291, train loss: 0.08463431250795336 test loss: 0.13211599248212547
0    7.657889
dtype: float32
Epoch 292, train loss: 0.08796357991871148 test loss: 0.13852119148573003
0    7.633618
dtype: float32
Epoch 293, train loss: 0.08700137002746629 test loss: 0.12932150605087062
0    7.639634
dtype: float32
Epoch 294, train loss: 0.09390001508307359 test loss: 0.12945123606222342
0    7.601682
dtype: float32
Epoch 295, train loss: 0.11921770237327316 test loss: 0.14764806416149634
0    7.7887
dtype: float32
Epoch 296, train loss: 0.09071170031216078 test loss: 0.1322263793422092
0    7.731869
dtype: float32
Epoch 297, train loss: 0.09277088785234344 test loss: 0.13368947927942854
0    7.707145
dtype: float32
Epoch 298, train loss: 0.08609912403345961 test loss: 0.1271105820739155
0    7.718232
dtype: float32
Epoch 299, train loss: 0.08621142230987962 test loss: 0.1353650853275385
Final train loss is: 0.08621142230987962, Test loss is: 0.1353650853275385
0    7.718232
dtype: float32
round is 2
0    5.123977
dtype: float32
Epoch 6, train loss: 0.22113709126939077 test loss: 0.299301619519436
0    6.948869
dtype: float32
Epoch 7, train loss: 0.18148668347136024 test loss: 0.12587459675676388
0    7.279168
dtype: float32
Epoch 8, train loss: 0.15902658649749363 test loss: 0.11325530985788243
0    7.992351
dtype: float32
Epoch 9, train loss: 0.205748227240555 test loss: 0.1112180720646099
0    7.896354
dtype: float32
Epoch 10, train loss: 0.15671480612549743 test loss: 0.09866915336982465
0    8.345571
dtype: float32
Epoch 11, train loss: 0.2117020402405288 test loss: 0.12148094772795547
0    8.062622
dtype: float32
Epoch 12, train loss: 0.1669336932145024 test loss: 0.08431995819908332
0    8.194776
dtype: float32
Epoch 13, train loss: 0.18349325712598366 test loss: 0.09617058388209791
0    7.942476
dtype: float32
Epoch 14, train loss: 0.15061571507891458 test loss: 0.09272750266793978
0    6.04039
dtype: float32
Epoch 15, train loss: 0.1945447105535412 test loss: 0.18765447176323083
0    5.620255
dtype: float32
Epoch 16, train loss: 0.27750387920708786 test loss: 0.3668231450738879
0    6.535576
dtype: float32
Epoch 17, train loss: 0.1458994885067258 test loss: 0.1772610523515159
0    6.542001
dtype: float32
Epoch 18, train loss: 0.12874923951436557 test loss: 0.12634917506089144
0    6.847697
dtype: float32
Epoch 19, train loss: 0.11712017601658506 test loss: 0.11400313589339137
0    6.11895
dtype: float32
Epoch 20, train loss: 0.2608443186689413 test loss: 0.27435922941173685
0    6.512173
dtype: float32
Epoch 21, train loss: 0.16494259457782567 test loss: 0.15278861591969692
0    6.819016
dtype: float32
Epoch 22, train loss: 0.12488702889171376 test loss: 0.12346996716521864
0    6.853724
dtype: float32
Epoch 23, train loss: 0.11421358296645426 test loss: 0.10289118298123665
0    7.732483
dtype: float32
Epoch 24, train loss: 0.11404910294254737 test loss: 0.08539177315976496
0    7.756342
dtype: float32
Epoch 25, train loss: 0.11363953909931783 test loss: 0.08265270890133253
0    7.558718
dtype: float32
Epoch 26, train loss: 0.10844082679546059 test loss: 0.0836438038074235
0    7.833996
dtype: float32
Epoch 27, train loss: 0.14561173565818283 test loss: 0.10767217214000102
0    8.274566
dtype: float32
Epoch 28, train loss: 0.15149711900085158 test loss: 0.0922587463951046
0    8.428464
dtype: float32
Epoch 29, train loss: 0.17556272967162845 test loss: 0.10957168447972428
0    8.273169
dtype: float32
Epoch 30, train loss: 0.1777082716403761 test loss: 0.1296308482011115
0    7.841558
dtype: float32
Epoch 31, train loss: 0.1369457866576273 test loss: 0.09342210212694887
0    7.690873
dtype: float32
Epoch 32, train loss: 0.12154417865830784 test loss: 0.0901129871952824
0    8.243544
dtype: float32
Epoch 33, train loss: 0.1500098643489286 test loss: 0.10156137875080876
0    8.178976
dtype: float32
Epoch 34, train loss: 0.14719817350168782 test loss: 0.09609064465240083
0    7.568256
dtype: float32
Epoch 35, train loss: 0.11415055663843762 test loss: 0.09256220135694324
0    8.292161
dtype: float32
Epoch 36, train loss: 0.14401985085032126 test loss: 0.09536854147174945
0    8.854227
dtype: float32
Epoch 37, train loss: 0.19153602535717473 test loss: 0.10980811731846196
0    7.377631
dtype: float32
Epoch 38, train loss: 0.10173625831447933 test loss: 0.08554892414905267
0    6.989148
dtype: float32
Epoch 39, train loss: 0.09605130656757949 test loss: 0.08743957785257922
0    6.74477
dtype: float32
Epoch 40, train loss: 0.10622190334270151 test loss: 0.11105087854805376
0    7.698424
dtype: float32
Epoch 41, train loss: 0.10541626217201525 test loss: 0.08410437612484817
0    6.49927
dtype: float32
Epoch 42, train loss: 0.11572685259505179 test loss: 0.10516317914974847
0    7.055274
dtype: float32
Epoch 43, train loss: 0.09780160787158017 test loss: 0.12102677933422148
0    6.694717
dtype: float32
Epoch 44, train loss: 0.11820972783135944 test loss: 0.12845637961014977
0    7.296057
dtype: float32
Epoch 45, train loss: 0.09056884285721185 test loss: 0.08712535690837123
0    7.456081
dtype: float32
Epoch 46, train loss: 0.0968858741913492 test loss: 0.09172445860419484
0    7.655996
dtype: float32
Epoch 47, train loss: 0.09764166472085341 test loss: 0.08999437498617521
0    7.934513
dtype: float32
Epoch 48, train loss: 0.13237025559716653 test loss: 0.10787753915657054
0    7.820148
dtype: float32
Epoch 49, train loss: 0.11745573698829512 test loss: 0.09002542524197052
0    7.179052
dtype: float32
Epoch 50, train loss: 0.0884646830002401 test loss: 0.0911846114728017
0    7.274031
dtype: float32
Epoch 51, train loss: 0.09003273229278269 test loss: 0.09299960394204501
0    6.653081
dtype: float32
Epoch 52, train loss: 0.11231365386295983 test loss: 0.1204759052627357
0    6.86537
dtype: float32
Epoch 53, train loss: 0.09593501040195695 test loss: 0.1028809441438979
0    6.204106
dtype: float32
Epoch 54, train loss: 0.14646421702035847 test loss: 0.13915443922928786
0    6.324448
dtype: float32
Epoch 55, train loss: 0.13037943363115068 test loss: 0.14342657232415457
0    7.575963
dtype: float32
Epoch 56, train loss: 0.09385356870871853 test loss: 0.08199057658212223
0    6.28054
dtype: float32
Epoch 57, train loss: 0.17299630929963497 test loss: 0.18675558654690208
0    6.858809
dtype: float32
Epoch 58, train loss: 0.11400935468923329 test loss: 0.12651493698219382
0    6.571678
dtype: float32
Epoch 59, train loss: 0.10902692435190563 test loss: 0.10697495646759554
0    7.191785
dtype: float32
Epoch 60, train loss: 0.08455960934107348 test loss: 0.088983290259252
0    6.793684
dtype: float32
Epoch 61, train loss: 0.09415732454505092 test loss: 0.1137934354387463
0    5.577834
dtype: float32
Epoch 62, train loss: 0.223432427532308 test loss: 0.2397551431909719
0    6.13561
dtype: float32
Epoch 63, train loss: 0.1801296773112571 test loss: 0.1967943311485306
0    6.263237
dtype: float32
Epoch 64, train loss: 0.12960658769595718 test loss: 0.1308294773034434
0    7.072046
dtype: float32
Epoch 65, train loss: 0.08388131400461153 test loss: 0.09407009891152629
0    6.940283
dtype: float32
Epoch 66, train loss: 0.08522294774253422 test loss: 0.1050448041467623
0    6.347223
dtype: float32
Epoch 67, train loss: 0.14929800233654597 test loss: 0.166711614637935
0    7.305554
dtype: float32
Epoch 68, train loss: 0.08546726489421637 test loss: 0.08763180822231204
0    7.462029
dtype: float32
Epoch 69, train loss: 0.09728671538492274 test loss: 0.08190725032381153
0    7.437457
dtype: float32
Epoch 70, train loss: 0.08708290560458881 test loss: 0.08595222456511732
0    6.944786
dtype: float32
Epoch 71, train loss: 0.08795338314139178 test loss: 0.10526039408518766
0    6.437973
dtype: float32
Epoch 72, train loss: 0.13269966457958343 test loss: 0.15010142494541062
0    6.570068
dtype: float32
Epoch 73, train loss: 0.12256305772039204 test loss: 0.13137502905657011
0    6.806259
dtype: float32
Epoch 74, train loss: 0.09317073215188522 test loss: 0.10848153385416447
0    6.202682
dtype: float32
Epoch 75, train loss: 0.12999529358997053 test loss: 0.13282262332470077
0    6.861503
dtype: float32
Epoch 76, train loss: 0.0886363343217839 test loss: 0.10870950488369677
0    7.285141
dtype: float32
Epoch 77, train loss: 0.08174773054105672 test loss: 0.09238761328234363
0    6.995643
dtype: float32
Epoch 78, train loss: 0.0873995871643365 test loss: 0.1149067477504365
0    6.227512
dtype: float32
Epoch 79, train loss: 0.1390204051783405 test loss: 0.14362916472442955
0    6.792634
dtype: float32
Epoch 80, train loss: 0.08894618038766929 test loss: 0.11660548723717179
0    6.562369
dtype: float32
Epoch 81, train loss: 0.10333426383894312 test loss: 0.1254293596790861
0    6.393933
dtype: float32
Epoch 82, train loss: 0.13258851713279027 test loss: 0.15839341327909034
0    7.223956
dtype: float32
Epoch 83, train loss: 0.07849221910770794 test loss: 0.08989876605571065
0    7.310247
dtype: float32
Epoch 84, train loss: 0.07949271947410659 test loss: 0.09045710233204193
0    7.252881
dtype: float32
Epoch 85, train loss: 0.07717666871869912 test loss: 0.09184273901501983
0    7.371131
dtype: float32
Epoch 86, train loss: 0.07782555463574779 test loss: 0.09496432770594428
0    7.171826
dtype: float32
Epoch 87, train loss: 0.0772907487166523 test loss: 0.09749424396157451
0    6.938962
dtype: float32
Epoch 88, train loss: 0.08145477883154305 test loss: 0.1076894830845723
0    6.673192
dtype: float32
Epoch 89, train loss: 0.10463834149285804 test loss: 0.1424584247245896
0    6.669247
dtype: float32
Epoch 90, train loss: 0.10830194801135481 test loss: 0.1396863384012128
0    6.494544
dtype: float32
Epoch 91, train loss: 0.09795436610402565 test loss: 0.11799426861505988
0    6.548629
dtype: float32
Epoch 92, train loss: 0.10408157152165794 test loss: 0.13551116199789687
0    6.114997
dtype: float32
Epoch 93, train loss: 0.1650768843763901 test loss: 0.1806556510866396
0    7.212974
dtype: float32
Epoch 94, train loss: 0.07589688102721036 test loss: 0.0976196284643825
0    7.855142
dtype: float32
Epoch 95, train loss: 0.10815599369269366 test loss: 0.09075030406465678
0    7.566921
dtype: float32
Epoch 96, train loss: 0.0917688923013709 test loss: 0.09746756545698015
0    7.408299
dtype: float32
Epoch 97, train loss: 0.0822638557637753 test loss: 0.0979258139660305
0    6.293622
dtype: float32
Epoch 98, train loss: 0.12112752705652652 test loss: 0.14670191837039548
0    7.371578
dtype: float32
Epoch 99, train loss: 0.07950421050866237 test loss: 0.09661315543146483
0    7.579841
dtype: float32
Epoch 100, train loss: 0.09426412651901489 test loss: 0.10053517225733757
0    7.055671
dtype: float32
Epoch 101, train loss: 0.07225533163850606 test loss: 0.0967612442222801
0    7.454292
dtype: float32
Epoch 102, train loss: 0.07477107077031467 test loss: 0.09249026886284673
0    7.029954
dtype: float32
Epoch 103, train loss: 0.0754872680770611 test loss: 0.09973314467279049
0    7.557414
dtype: float32
Epoch 104, train loss: 0.08043420485775565 test loss: 0.09435556155046866
0    7.735476
dtype: float32
Epoch 105, train loss: 0.095819031443299 test loss: 0.10257603487874874
0    7.141646
dtype: float32
Epoch 106, train loss: 0.07062033475721713 test loss: 0.09667666652082527
0    7.135416
dtype: float32
Epoch 107, train loss: 0.07031101872183294 test loss: 0.09541237957014148
0    6.827923
dtype: float32
Epoch 108, train loss: 0.07893885683722554 test loss: 0.10404952707425577
0    7.163
dtype: float32
Epoch 109, train loss: 0.070127549557157 test loss: 0.09227731703816576
0    7.386382
dtype: float32
Epoch 110, train loss: 0.071580800631834 test loss: 0.09238776947845583
0    7.122127
dtype: float32
Epoch 111, train loss: 0.07082968673925115 test loss: 0.09322123065189787
0    7.050467
dtype: float32
Epoch 112, train loss: 0.07325424362808239 test loss: 0.09790280668694801
0    7.305796
dtype: float32
Epoch 113, train loss: 0.06870031477925381 test loss: 0.09307845339954722
0    7.439536
dtype: float32
Epoch 114, train loss: 0.07511229975084353 test loss: 0.09467295694178228
0    6.754323
dtype: float32
Epoch 115, train loss: 0.10884082539198237 test loss: 0.13575410281443864
0    6.927996
dtype: float32
Epoch 116, train loss: 0.08898045572957186 test loss: 0.1015157955134222
0    7.458909
dtype: float32
Epoch 117, train loss: 0.0725769888678886 test loss: 0.0943174023276337
0    7.736251
dtype: float32
Epoch 118, train loss: 0.08222256486333542 test loss: 0.09111148464264786
0    8.137431
dtype: float32
Epoch 119, train loss: 0.1293420558315999 test loss: 0.10765903121086713
0    7.642231
dtype: float32
Epoch 120, train loss: 0.08335811054236206 test loss: 0.08940365545003315
0    7.453192
dtype: float32
Epoch 121, train loss: 0.08131366737200901 test loss: 0.09705881577672551
0    6.820998
dtype: float32
Epoch 122, train loss: 0.08647335851618791 test loss: 0.10611006080684847
0    6.232499
dtype: float32
Epoch 123, train loss: 0.14900258885394607 test loss: 0.16817310466809351
0    6.775093
dtype: float32
Epoch 124, train loss: 0.10086768003269575 test loss: 0.11312112169863843
0    6.37644
dtype: float32
Epoch 125, train loss: 0.11147383772653338 test loss: 0.11273280477579871
0    6.61907
dtype: float32
Epoch 126, train loss: 0.09132444124476957 test loss: 0.10858922946798386
0    7.011281
dtype: float32
Epoch 127, train loss: 0.06990532346875733 test loss: 0.0957534870594191
0    7.82454
dtype: float32
Epoch 128, train loss: 0.09530648252830233 test loss: 0.09340987495645138
0    6.802605
dtype: float32
Epoch 129, train loss: 0.0819693233625244 test loss: 0.11823396013358545
0    7.909675
dtype: float32
Epoch 130, train loss: 0.09342170252761275 test loss: 0.09484389061414197
0    7.527219
dtype: float32
Epoch 131, train loss: 0.07947898093031247 test loss: 0.10307861331320563
0    7.540205
dtype: float32
Epoch 132, train loss: 0.08634110725832181 test loss: 0.09631214193086488
0    7.491941
dtype: float32
Epoch 133, train loss: 0.07719306849306809 test loss: 0.08511713696291691
0    6.916948
dtype: float32
Epoch 134, train loss: 0.07782621973485851 test loss: 0.11326847177426892
0    6.750256
dtype: float32
Epoch 135, train loss: 0.08348108628161811 test loss: 0.11135022057718388
0    6.545942
dtype: float32
Epoch 136, train loss: 0.09485752038492232 test loss: 0.13583512048117377
0    7.231609
dtype: float32
Epoch 137, train loss: 0.06393557499984936 test loss: 0.09945677414749847
0    6.865712
dtype: float32
Epoch 138, train loss: 0.08428117469194792 test loss: 0.11695030970531667
0    7.218048
dtype: float32
Epoch 139, train loss: 0.06351988020943142 test loss: 0.09423981918357496
0    7.354287
dtype: float32
Epoch 140, train loss: 0.07254748663725583 test loss: 0.09567496339190992
0    7.416161
dtype: float32
Epoch 141, train loss: 0.0754019223984378 test loss: 0.09269616625995462
0    7.818402
dtype: float32
Epoch 142, train loss: 0.09993930656282132 test loss: 0.09821606606403653
0    7.804912
dtype: float32
Epoch 143, train loss: 0.10399614196254606 test loss: 0.0961692366657508
0    7.170922
dtype: float32
Epoch 144, train loss: 0.06505829195369893 test loss: 0.10945175460667769
0    6.448545
dtype: float32
Epoch 145, train loss: 0.11985905291933965 test loss: 0.13713917273308354
0    7.104906
dtype: float32
Epoch 146, train loss: 0.06447334276655935 test loss: 0.09401742705395291
0    6.903908
dtype: float32
Epoch 147, train loss: 0.0723819518102456 test loss: 0.10707078424133475
0    7.267223
dtype: float32
Epoch 148, train loss: 0.06343883551570759 test loss: 0.0927807952414745
0    7.267673
dtype: float32
Epoch 149, train loss: 0.06709889203544538 test loss: 0.09752112747866479
0    7.498396
dtype: float32
Epoch 150, train loss: 0.0809691273275347 test loss: 0.10195770591849275
0    7.383061
dtype: float32
Epoch 151, train loss: 0.06673142504490266 test loss: 0.0921564524601152
0    7.344483
dtype: float32
Epoch 152, train loss: 0.0659525367564938 test loss: 0.08672268651905896
0    7.553998
dtype: float32
Epoch 153, train loss: 0.07768537807865854 test loss: 0.09942962521516
0    6.697129
dtype: float32
Epoch 154, train loss: 0.08276147340514715 test loss: 0.1153547762243059
0    6.540721
dtype: float32
Epoch 155, train loss: 0.10378894048523088 test loss: 0.12058515753617442
0    6.763177
dtype: float32
Epoch 156, train loss: 0.08735485587068695 test loss: 0.11743013660867338
0    6.393009
dtype: float32
Epoch 157, train loss: 0.10072689325889182 test loss: 0.11758323907777841
0    6.726231
dtype: float32
Epoch 158, train loss: 0.0713667354976578 test loss: 0.10012890701295982
0    7.361101
dtype: float32
Epoch 159, train loss: 0.07569424151144676 test loss: 0.08733309408629954
0    6.879184
dtype: float32
Epoch 160, train loss: 0.06641464888897457 test loss: 0.10277465983195826
0    7.645071
dtype: float32
Epoch 161, train loss: 0.09522239500673822 test loss: 0.11026423089710799
0    7.710494
dtype: float32
Epoch 162, train loss: 0.1064020220792711 test loss: 0.11013716546256627
0    7.358948
dtype: float32
Epoch 163, train loss: 0.06786011993888029 test loss: 0.08389411100421043
0    6.278059
dtype: float32
Epoch 164, train loss: 0.11179398750528032 test loss: 0.1393172103281165
0    7.024722
dtype: float32
Epoch 165, train loss: 0.06063808442782668 test loss: 0.09376321331402158
0    7.697607
dtype: float32
Epoch 166, train loss: 0.09837351594222758 test loss: 0.10457759580940479
0    7.853867
dtype: float32
Epoch 167, train loss: 0.1068522236542507 test loss: 0.11276486321059247
0    7.005066
dtype: float32
Epoch 168, train loss: 0.05900204467973694 test loss: 0.0949083708207892
0    7.017282
dtype: float32
Epoch 169, train loss: 0.05891687540470623 test loss: 0.09759224812161574
0    7.494772
dtype: float32
Epoch 170, train loss: 0.0652073849718711 test loss: 0.09149730366926992
0    6.960486
dtype: float32
Epoch 171, train loss: 0.05880149287002833 test loss: 0.09907908975088765
0    7.285888
dtype: float32
Epoch 172, train loss: 0.06012620625453069 test loss: 0.09188095974875807
0    7.512525
dtype: float32
Epoch 173, train loss: 0.07859762484179172 test loss: 0.10022648836766453
0    7.577638
dtype: float32
Epoch 174, train loss: 0.07602395793690708 test loss: 0.09136304018504941
0    7.49642
dtype: float32
Epoch 175, train loss: 0.08132478924411873 test loss: 0.10560991681471815
0    7.428885
dtype: float32
Epoch 176, train loss: 0.065035885256484 test loss: 0.08905812232476538
0    7.007791
dtype: float32
Epoch 177, train loss: 0.0615831867370498 test loss: 0.09996395402553818
0    6.856052
dtype: float32
Epoch 178, train loss: 0.06816959511100316 test loss: 0.09872695699746817
0    6.892494
dtype: float32
Epoch 179, train loss: 0.06218314917598554 test loss: 0.09253057503608764
0    7.372422
dtype: float32
Epoch 180, train loss: 0.07163936739780404 test loss: 0.09446434118805826
0    7.421831
dtype: float32
Epoch 181, train loss: 0.06556854257484927 test loss: 0.09885953971705194
0    7.651198
dtype: float32
Epoch 182, train loss: 0.09161636357962202 test loss: 0.10204116211099148
0    6.98575
dtype: float32
Epoch 183, train loss: 0.07375907250033854 test loss: 0.11007394253838552
0    6.814771
dtype: float32
Epoch 184, train loss: 0.09666110260153082 test loss: 0.13947438895228362
0    5.919765
dtype: float32
Epoch 185, train loss: 0.21573830427576363 test loss: 0.22642055710551148
0    6.105373
dtype: float32
Epoch 186, train loss: 0.12721844211806396 test loss: 0.14257041068684187
0    6.76297
dtype: float32
Epoch 187, train loss: 0.0743287557778997 test loss: 0.10395769205235245
0    7.735649
dtype: float32
Epoch 188, train loss: 0.07533223950033602 test loss: 0.09481405439109514
0    7.150244
dtype: float32
Epoch 189, train loss: 0.05864540366449599 test loss: 0.09180600931444745
0    7.076232
dtype: float32
Epoch 190, train loss: 0.06007570048395327 test loss: 0.09743589577040504
0    7.121036
dtype: float32
Epoch 191, train loss: 0.05782122864901875 test loss: 0.09670913629048507
0    7.172537
dtype: float32
Epoch 192, train loss: 0.05574401580082478 test loss: 0.09445822717381405
0    6.708154
dtype: float32
Epoch 193, train loss: 0.10375673309713238 test loss: 0.12904728865574344
0    6.884253
dtype: float32
Epoch 194, train loss: 0.06350655407049652 test loss: 0.09867622728013242
0    7.385542
dtype: float32
Epoch 195, train loss: 0.05963108494441857 test loss: 0.09259986427356157
0    7.10972
dtype: float32
Epoch 196, train loss: 0.06495767139861541 test loss: 0.1014016054602729
0    7.289123
dtype: float32
Epoch 197, train loss: 0.05923569364686932 test loss: 0.09175335406692824
0    7.128142
dtype: float32
Epoch 198, train loss: 0.059998204660325086 test loss: 0.0908843992549592
0    7.071569
dtype: float32
Epoch 199, train loss: 0.05734570918804468 test loss: 0.09316423018995067
0    7.358054
dtype: float32
Epoch 200, train loss: 0.07360819919529583 test loss: 0.09225704962308749
0    7.215809
dtype: float32
Epoch 201, train loss: 0.05714097472546471 test loss: 0.09889536586398054
0    7.281888
dtype: float32
Epoch 202, train loss: 0.059120768839548705 test loss: 0.08807713044667877
0    6.891153
dtype: float32
Epoch 203, train loss: 0.0649000693706859 test loss: 0.09467264877614026
0    6.895269
dtype: float32
Epoch 204, train loss: 0.05452833029487451 test loss: 0.09401127396392095
0    7.223837
dtype: float32
Epoch 205, train loss: 0.05737660908506744 test loss: 0.08963488430527466
0    6.806344
dtype: float32
Epoch 206, train loss: 0.05781585987469592 test loss: 0.0969358191771792
0    6.919794
dtype: float32
Epoch 207, train loss: 0.05527710266618011 test loss: 0.0926643723794002
0    7.16665
dtype: float32
Epoch 208, train loss: 0.05624129244683376 test loss: 0.08576639106150054
0    6.899271
dtype: float32
Epoch 209, train loss: 0.055264141825710184 test loss: 0.09137718572590352
0    7.379788
dtype: float32
Epoch 210, train loss: 0.06828091815774584 test loss: 0.09074015769224097
0    7.091322
dtype: float32
Epoch 211, train loss: 0.0632214517114088 test loss: 0.08883858921618135
0    6.701905
dtype: float32
Epoch 212, train loss: 0.08338260657896855 test loss: 0.12499306308169943
0    6.942958
dtype: float32
Epoch 213, train loss: 0.05406147005674379 test loss: 0.08931090566008644
0    6.949389
dtype: float32
Epoch 214, train loss: 0.0571213827528877 test loss: 0.09303246347518665
0    6.900194
dtype: float32
Epoch 215, train loss: 0.056937724507130714 test loss: 0.09770915636153997
0    7.049074
dtype: float32
Epoch 216, train loss: 0.05407110477089541 test loss: 0.08779645548513286
0    6.789796
dtype: float32
Epoch 217, train loss: 0.07135830839224551 test loss: 0.10168403735737908
0    5.919051
dtype: float32
Epoch 218, train loss: 0.11350834233285374 test loss: 0.13165303353066002
0    6.355506
dtype: float32
Epoch 219, train loss: 0.08381793596749336 test loss: 0.12266264082615085
0    6.845457
dtype: float32
Epoch 220, train loss: 0.07336828680255893 test loss: 0.10817792520370369
0    6.963307
dtype: float32
Epoch 221, train loss: 0.060165741928427406 test loss: 0.09575695978042835
0    6.759553
dtype: float32
Epoch 222, train loss: 0.06992472525319526 test loss: 0.11315252671880562
0    7.006397
dtype: float32
Epoch 223, train loss: 0.05451201772695053 test loss: 0.09587145628309321
0    6.760799
dtype: float32
Epoch 224, train loss: 0.09050599538850135 test loss: 0.1282362272726654
0    6.80692
dtype: float32
Epoch 225, train loss: 0.05972962556650249 test loss: 0.09803496800610947
0    6.599724
dtype: float32
Epoch 226, train loss: 0.062470938802624366 test loss: 0.08705752290046304
0    7.143902
dtype: float32
Epoch 227, train loss: 0.06236888534289215 test loss: 0.09265983240784996
0    7.047165
dtype: float32
Epoch 228, train loss: 0.07142270631480623 test loss: 0.08695399147150724
0    6.810053
dtype: float32
Epoch 229, train loss: 0.061467526939525285 test loss: 0.09519654627136145
0    6.651298
dtype: float32
Epoch 230, train loss: 0.08054047722460586 test loss: 0.09644977136827194
0    6.841606
dtype: float32
Epoch 231, train loss: 0.053718903603335186 test loss: 0.08304434241187868
0    6.377972
dtype: float32
Epoch 232, train loss: 0.07159042851479491 test loss: 0.10716853443591529
0    6.657857
dtype: float32
Epoch 233, train loss: 0.05718217940727158 test loss: 0.09847159755180386
0    7.227952
dtype: float32
Epoch 234, train loss: 0.06734444393685975 test loss: 0.09010212494297372
0    7.184538
dtype: float32
Epoch 235, train loss: 0.05883442755440384 test loss: 0.0812483598180619
0    6.928215
dtype: float32
Epoch 236, train loss: 0.052448507693851856 test loss: 0.08551551484235113
0    7.087106
dtype: float32
Epoch 237, train loss: 0.051986845219361796 test loss: 0.08807273157646008
0    7.494326
dtype: float32
Epoch 238, train loss: 0.06917451543467931 test loss: 0.08750868230781247
0    7.284308
dtype: float32
Epoch 239, train loss: 0.06400825985746644 test loss: 0.08376055136332347
0    7.010394
dtype: float32
Epoch 240, train loss: 0.057658745566538425 test loss: 0.08521259604331607
0    7.144502
dtype: float32
Epoch 241, train loss: 0.06070377764227942 test loss: 0.08212198769868648
0    7.843235
dtype: float32
Epoch 242, train loss: 0.08436810203151505 test loss: 0.08929329904449704
0    7.64225
dtype: float32
Epoch 243, train loss: 0.08158792578280259 test loss: 0.09658274193293621
0    7.356688
dtype: float32
Epoch 244, train loss: 0.057508831240740584 test loss: 0.0892758119441154
0    6.961007
dtype: float32
Epoch 245, train loss: 0.056584934888985264 test loss: 0.09542711490784747
0    6.736535
dtype: float32
Epoch 246, train loss: 0.08345178125100862 test loss: 0.11963371029559138
0    6.071517
dtype: float32
Epoch 247, train loss: 0.09782837806373716 test loss: 0.12800083044372507
0    7.129818
dtype: float32
Epoch 248, train loss: 0.05800211647104489 test loss: 0.08685591346834821
0    6.874126
dtype: float32
Epoch 249, train loss: 0.05862793042591588 test loss: 0.09245744735722637
0    7.053194
dtype: float32
Epoch 250, train loss: 0.06521344647145033 test loss: 0.08174330192152458
0    6.905715
dtype: float32
Epoch 251, train loss: 0.0528343428042887 test loss: 0.08583262857307966
0    6.510336
dtype: float32
Epoch 252, train loss: 0.08671014054791983 test loss: 0.11634452797755668
0    6.828464
dtype: float32
Epoch 253, train loss: 0.05258475451217107 test loss: 0.08566112338129535
0    7.186019
dtype: float32
Epoch 254, train loss: 0.053346259954118326 test loss: 0.07925852371604818
0    6.983175
dtype: float32
Epoch 255, train loss: 0.05892216515501247 test loss: 0.0862601688422432
0    6.961651
dtype: float32
Epoch 256, train loss: 0.061758374551602734 test loss: 0.08706214241885193
0    6.617666
dtype: float32
Epoch 257, train loss: 0.07767983747839655 test loss: 0.10169816319469607
0    7.298572
dtype: float32
Epoch 258, train loss: 0.0569908268363832 test loss: 0.07609221170458365
0    6.971797
dtype: float32
Epoch 259, train loss: 0.05009272441420985 test loss: 0.0867241913348597
0    7.265501
dtype: float32
Epoch 260, train loss: 0.053001083315599745 test loss: 0.08075990550423022
0    6.561942
dtype: float32
Epoch 261, train loss: 0.08122340164649958 test loss: 0.09851779005692846
0    7.490937
dtype: float32
Epoch 262, train loss: 0.09179081912852852 test loss: 0.08762849679925565
0    6.883672
dtype: float32
Epoch 263, train loss: 0.0905927015513199 test loss: 0.09270371963808526
0    6.661975
dtype: float32
Epoch 264, train loss: 0.07177890184502617 test loss: 0.08768706009562668
0    7.592961
dtype: float32
Epoch 265, train loss: 0.07526558065358417 test loss: 0.08497721198295743
0    6.876019
dtype: float32
Epoch 266, train loss: 0.05904873261789331 test loss: 0.07530611209808186
0    6.919469
dtype: float32
Epoch 267, train loss: 0.05459837570730825 test loss: 0.08707234989254276
0    6.961634
dtype: float32
Epoch 268, train loss: 0.057323984525125576 test loss: 0.07549276597690503
0    6.857671
dtype: float32
Epoch 269, train loss: 0.06663129954871429 test loss: 0.08738471517700869
0    6.884863
dtype: float32
Epoch 270, train loss: 0.05059372567353291 test loss: 0.08274995322642413
0    7.4233
dtype: float32
Epoch 271, train loss: 0.06030937725603748 test loss: 0.08075982781498439
0    7.219251
dtype: float32
Epoch 272, train loss: 0.0794209694888707 test loss: 0.08956304909615588
0    7.268172
dtype: float32
Epoch 273, train loss: 0.050848891887742956 test loss: 0.08703717896870486
0    7.158532
dtype: float32
Epoch 274, train loss: 0.06387124606649099 test loss: 0.07875304902180635
0    6.783819
dtype: float32
Epoch 275, train loss: 0.06293019262475835 test loss: 0.08920185180490316
0    6.543371
dtype: float32
Epoch 276, train loss: 0.08294537064650821 test loss: 0.11025246878032731
0    7.009185
dtype: float32
Epoch 277, train loss: 0.04836558133897257 test loss: 0.08871399453788198
0    7.076891
dtype: float32
Epoch 278, train loss: 0.06609286360972759 test loss: 0.08404711244201549
0    7.597857
dtype: float32
Epoch 279, train loss: 0.07106310093862273 test loss: 0.08118791486168041
0    6.93087
dtype: float32
Epoch 280, train loss: 0.058757985481166314 test loss: 0.08721531612621007
0    7.319299
dtype: float32
Epoch 281, train loss: 0.0789476032839176 test loss: 0.08995357757848173
0    6.774042
dtype: float32
Epoch 282, train loss: 0.061198627201524886 test loss: 0.07811784008746121
0    6.862437
dtype: float32
Epoch 283, train loss: 0.049747190562103895 test loss: 0.07670163174925236
0    7.043508
dtype: float32
Epoch 284, train loss: 0.04902787159508094 test loss: 0.0807174255261187
0    6.751261
dtype: float32
Epoch 285, train loss: 0.05230924933172844 test loss: 0.07597995730343302
0    6.768163
dtype: float32
Epoch 286, train loss: 0.057096311921028875 test loss: 0.09411767170340331
0    6.495118
dtype: float32
Epoch 287, train loss: 0.06819930071109406 test loss: 0.09086524011878974
0    6.437589
dtype: float32
Epoch 288, train loss: 0.060573322109319025 test loss: 0.08881646689589784
0    6.727139
dtype: float32
Epoch 289, train loss: 0.0632836924497364 test loss: 0.08516483751703843
0    7.048601
dtype: float32
Epoch 290, train loss: 0.05502586092140752 test loss: 0.08417918887207883
0    7.323305
dtype: float32
Epoch 291, train loss: 0.06845817596466014 test loss: 0.09233282308759445
0    7.246218
dtype: float32
Epoch 292, train loss: 0.050332230187592385 test loss: 0.07244067851181996
0    6.781457
dtype: float32
Epoch 293, train loss: 0.05377087912440908 test loss: 0.08439752006783888
0    7.094583
dtype: float32
Epoch 294, train loss: 0.053751158917748856 test loss: 0.07536919723353341
0    6.803184
dtype: float32
Epoch 295, train loss: 0.04945434236411814 test loss: 0.0787842252799412
0    6.841158
dtype: float32
Epoch 296, train loss: 0.04877375094935818 test loss: 0.09568673719808723
0    6.549824
dtype: float32
Epoch 297, train loss: 0.07418839951548638 test loss: 0.09939784845800732
0    6.604783
dtype: float32
Epoch 298, train loss: 0.05595954671422929 test loss: 0.08403692947395074
0    6.755425
dtype: float32
Epoch 299, train loss: 0.05069613563154061 test loss: 0.08055052191524632
Final train loss is: 0.05069613563154061, Test loss is: 0.08055052191524632
0    6.755425
dtype: float32
round is 3
0    9.192155
dtype: float32
Epoch 6, train loss: 0.2788689371440918 test loss: 0.5672184831017183
0    7.924055
dtype: float32
Epoch 7, train loss: 0.2245032465231279 test loss: 0.6125044514200321
0    8.348998
dtype: float32
Epoch 8, train loss: 0.2013858115685552 test loss: 0.388880071643632
0    7.425935
dtype: float32
Epoch 9, train loss: 0.20905858873879082 test loss: 0.6109127600910158
0    9.852737
dtype: float32
Epoch 10, train loss: 0.2158225219061117 test loss: 0.2423909859322906
0    7.221405
dtype: float32
Epoch 11, train loss: 0.13354533766277402 test loss: 0.40118333804745254
0    7.735905
dtype: float32
Epoch 12, train loss: 0.16645519911913648 test loss: 0.3135692573846041
0    8.212805
dtype: float32
Epoch 13, train loss: 0.13602725814022312 test loss: 0.21185121494844827
0    8.005103
dtype: float32
Epoch 14, train loss: 0.14678841288758238 test loss: 0.2193652113679581
0    7.943511
dtype: float32
Epoch 15, train loss: 0.1543023074805659 test loss: 0.1958441827779566
0    7.476027
dtype: float32
Epoch 16, train loss: 0.14934263408380638 test loss: 0.22656364094469408
0    7.660775
dtype: float32
Epoch 17, train loss: 0.14832745221384877 test loss: 0.24159685269962056
0    9.693387
dtype: float32
Epoch 18, train loss: 0.21879157338149663 test loss: 0.26046764102432696
0    8.116188
dtype: float32
Epoch 19, train loss: 0.12664850298482888 test loss: 0.20904784432634255
0    8.421656
dtype: float32
Epoch 20, train loss: 0.14641024885719872 test loss: 0.20988285774709442
0    6.352916
dtype: float32
Epoch 21, train loss: 0.10160501493727524 test loss: 0.32576924458032036
0    8.895425
dtype: float32
Epoch 22, train loss: 0.15958798313185918 test loss: 0.20596123638935648
0    7.531742
dtype: float32
Epoch 23, train loss: 0.09546797531987376 test loss: 0.18436938370003803
0    7.44108
dtype: float32
Epoch 24, train loss: 0.10358514657830584 test loss: 0.1917446926238148
0    7.472395
dtype: float32
Epoch 25, train loss: 0.09546361468591638 test loss: 0.15649969127285251
0    4.973458
dtype: float32
Epoch 26, train loss: 0.12472219214245696 test loss: 0.390482730054027
0    3.5402
dtype: float32
Epoch 27, train loss: 0.2572127037825902 test loss: 0.5517099693247932
0    4.579452
dtype: float32
Epoch 28, train loss: 0.18131559400057656 test loss: 0.4306153773091633
0    5.55488
dtype: float32
Epoch 29, train loss: 0.11499764101764602 test loss: 0.2759749947284314
0    8.073942
dtype: float32
Epoch 30, train loss: 0.12337069498542609 test loss: 0.17333440705660513
0    7.812145
dtype: float32
Epoch 31, train loss: 0.14333076098486694 test loss: 0.18036752340238607
0    8.033425
dtype: float32
Epoch 32, train loss: 0.11189260759795885 test loss: 0.1795016377207526
0    7.9558
dtype: float32
Epoch 33, train loss: 0.11064160860076803 test loss: 0.17161452711267067
0    5.986539
dtype: float32
Epoch 34, train loss: 0.09735913503707644 test loss: 0.28188468304804454
0    5.642667
dtype: float32
Epoch 35, train loss: 0.11707800317227796 test loss: 0.26934557585517527
0    5.409794
dtype: float32
Epoch 36, train loss: 0.15008071601608688 test loss: 0.3022337255873788
0    4.330611
dtype: float32
Epoch 37, train loss: 0.1593824386829079 test loss: 0.41773597701582954
0    4.491374
dtype: float32
Epoch 38, train loss: 0.14985298849703532 test loss: 0.4021655889476935
0    6.271939
dtype: float32
Epoch 39, train loss: 0.0761669945022069 test loss: 0.2026376352428545
0    7.437748
dtype: float32
Epoch 40, train loss: 0.09470084343672795 test loss: 0.1508677113778187
0    8.179591
dtype: float32
Epoch 41, train loss: 0.1407155197330839 test loss: 0.19478326992866218
0    7.860119
dtype: float32
Epoch 42, train loss: 0.13454660969346469 test loss: 0.1877499637506145
0    7.448723
dtype: float32
Epoch 43, train loss: 0.09305453419364162 test loss: 0.15300410135215928
0    6.293277
dtype: float32
Epoch 44, train loss: 0.09142890817514766 test loss: 0.1908341360692651
0    6.687193
dtype: float32
Epoch 45, train loss: 0.08399184157613263 test loss: 0.17469351468382238
0    5.684935
dtype: float32
Epoch 46, train loss: 0.10415029363618039 test loss: 0.23278470373682741
0    5.624418
dtype: float32
Epoch 47, train loss: 0.10081089849006233 test loss: 0.22749292092371237
0    6.008631
dtype: float32
Epoch 48, train loss: 0.07622516122189107 test loss: 0.2055800488601023
0    5.597235
dtype: float32
Epoch 49, train loss: 0.0973184851947124 test loss: 0.27250708128285583
0    6.041059
dtype: float32
Epoch 50, train loss: 0.11328990093229688 test loss: 0.2055429583783803
0    5.778102
dtype: float32
Epoch 51, train loss: 0.08704149321647998 test loss: 0.2390231125977269
0    5.822085
dtype: float32
Epoch 52, train loss: 0.09710479514901964 test loss: 0.2293564018610398
0    4.277103
dtype: float32
Epoch 53, train loss: 0.21778946710167185 test loss: 0.47675859368198037
0    6.154747
dtype: float32
Epoch 54, train loss: 0.07370162830603978 test loss: 0.18833518487677256
0    5.808701
dtype: float32
Epoch 55, train loss: 0.09022899932389035 test loss: 0.21360266438241218
0    6.105149
dtype: float32
Epoch 56, train loss: 0.09655607799603068 test loss: 0.19886523868647957
0    5.968482
dtype: float32
Epoch 57, train loss: 0.0798638234476863 test loss: 0.21785676472547721
0    6.082561
dtype: float32
Epoch 58, train loss: 0.08032225781374942 test loss: 0.2288678692970055
0    7.457222
dtype: float32
Epoch 59, train loss: 0.09838783968259295 test loss: 0.15463442340541816
0    6.984871
dtype: float32
Epoch 60, train loss: 0.10779749855407514 test loss: 0.16710495456709748
0    7.925716
dtype: float32
Epoch 61, train loss: 0.11419057991556268 test loss: 0.16509760480940253
0    6.416294
dtype: float32
Epoch 62, train loss: 0.07004044531326821 test loss: 0.183651003395217
0    7.502289
dtype: float32
Epoch 63, train loss: 0.10488921552235357 test loss: 0.1559869660377836
0    6.971688
dtype: float32
Epoch 64, train loss: 0.07101160469754947 test loss: 0.1434036963205347
0    7.073366
dtype: float32
Epoch 65, train loss: 0.07396964751793218 test loss: 0.1475373680019884
0    6.505786
dtype: float32
Epoch 66, train loss: 0.0761654335006204 test loss: 0.18149313430223027
0    5.971272
dtype: float32
Epoch 67, train loss: 0.11976014049043661 test loss: 0.19179666040526908
0    5.69249
dtype: float32
Epoch 68, train loss: 0.0960537038205565 test loss: 0.22707636276198087
0    6.127674
dtype: float32
Epoch 69, train loss: 0.07388859489679984 test loss: 0.19097012207888267
0    5.752397
dtype: float32
Epoch 70, train loss: 0.12106186037216206 test loss: 0.21986835246040146
0    6.244954
dtype: float32
Epoch 71, train loss: 0.06885956151877635 test loss: 0.17518383924826536
0    6.548092
dtype: float32
Epoch 72, train loss: 0.06608437635309611 test loss: 0.1628504368312516
0    6.961768
dtype: float32
Epoch 73, train loss: 0.08614258456359165 test loss: 0.15741025102835546
0    6.341099
dtype: float32
Epoch 74, train loss: 0.06715343783871379 test loss: 0.18636596120434204
0    6.926664
dtype: float32
Epoch 75, train loss: 0.06861272229601592 test loss: 0.15217748055106278
0    6.597932
dtype: float32
Epoch 76, train loss: 0.06361917267518723 test loss: 0.16455131505652915
0    6.975776
dtype: float32
Epoch 77, train loss: 0.06801768558848413 test loss: 0.14927939273039528
0    6.154525
dtype: float32
Epoch 78, train loss: 0.08116015126654103 test loss: 0.196887499827542
0    6.447593
dtype: float32
Epoch 79, train loss: 0.08495980762208091 test loss: 0.17814542278178333
0    5.228995
dtype: float32
Epoch 80, train loss: 0.13034836209798983 test loss: 0.2844233615717175
0    5.113267
dtype: float32
Epoch 81, train loss: 0.13100125636428991 test loss: 0.32585194234904913
0    6.549256
dtype: float32
Epoch 82, train loss: 0.06934631586696516 test loss: 0.20255710428711093
0    7.089859
dtype: float32
Epoch 83, train loss: 0.07563944903804497 test loss: 0.14813392430987152
0    7.64613
dtype: float32
Epoch 84, train loss: 0.0842565712952421 test loss: 0.14275350531107733
0    6.519184
dtype: float32
Epoch 85, train loss: 0.06612247028622352 test loss: 0.19351869516215098
0    7.317629
dtype: float32
Epoch 86, train loss: 0.09060175644346596 test loss: 0.15904331394894494
0    7.510631
dtype: float32
Epoch 87, train loss: 0.0987305888565908 test loss: 0.15395936082675912
0    6.938299
dtype: float32
Epoch 88, train loss: 0.069997660375518 test loss: 0.15187759638453474
0    6.397436
dtype: float32
Epoch 89, train loss: 0.06545705889518191 test loss: 0.1892525798009373
0    6.380807
dtype: float32
Epoch 90, train loss: 0.06561878385239514 test loss: 0.18813385485190348
0    6.553347
dtype: float32
Epoch 91, train loss: 0.07174718477933711 test loss: 0.1781602495280004
0    5.912331
dtype: float32
Epoch 92, train loss: 0.11144029878268778 test loss: 0.23071642727160854
0    6.364797
dtype: float32
Epoch 93, train loss: 0.06580796609280994 test loss: 0.17375659339351476
0    6.256829
dtype: float32
Epoch 94, train loss: 0.09254330143831938 test loss: 0.1881935210156023
0    4.694362
dtype: float32
Epoch 95, train loss: 0.1952115603167039 test loss: 0.44851966215758154
0    5.35501
dtype: float32
Epoch 96, train loss: 0.14718235062703042 test loss: 0.33287930771251156
0    6.198848
dtype: float32
Epoch 97, train loss: 0.1109433556461253 test loss: 0.22358980460096967
0    5.248811
dtype: float32
Epoch 98, train loss: 0.15188630443505113 test loss: 0.3376129615721915
0    5.919232
dtype: float32
Epoch 99, train loss: 0.09289777459990031 test loss: 0.2415035934555006
0    5.045295
dtype: float32
Epoch 100, train loss: 0.15510512279702876 test loss: 0.3933495903682317
0    5.118943
dtype: float32
Epoch 101, train loss: 0.1857169988675606 test loss: 0.3856811686623587
0    6.692392
dtype: float32
Epoch 102, train loss: 0.07000221587739532 test loss: 0.18180445141259516
0    7.773071
dtype: float32
Epoch 103, train loss: 0.10962460939884566 test loss: 0.16022811276363444
0    7.031489
dtype: float32
Epoch 104, train loss: 0.08622059167230436 test loss: 0.18018541986324801
0    7.3254
dtype: float32
Epoch 105, train loss: 0.08087160360872044 test loss: 0.1644696988074658
0    6.890219
dtype: float32
Epoch 106, train loss: 0.0637179042342237 test loss: 0.1610232819018825
0    6.691373
dtype: float32
Epoch 107, train loss: 0.06398302419901265 test loss: 0.18113181108366966
0    7.238651
dtype: float32
Epoch 108, train loss: 0.06939228954811322 test loss: 0.15390324305563458
0    7.453433
dtype: float32
Epoch 109, train loss: 0.09418372496185816 test loss: 0.16412214758048002
0    7.599507
dtype: float32
Epoch 110, train loss: 0.10435116808087477 test loss: 0.17455607734605114
0    6.906709
dtype: float32
Epoch 111, train loss: 0.06566795004861863 test loss: 0.17266145222751458
0    6.405756
dtype: float32
Epoch 112, train loss: 0.06504051818231538 test loss: 0.19819248596118458
0    6.884229
dtype: float32
Epoch 113, train loss: 0.06092331704509126 test loss: 0.16523186735267822
0    8.008677
dtype: float32
Epoch 114, train loss: 0.10686477100268167 test loss: 0.17195805637258715
0    7.091567
dtype: float32
Epoch 115, train loss: 0.10544643351900142 test loss: 0.16502584750794638
0    7.341744
dtype: float32
Epoch 116, train loss: 0.08163697372183396 test loss: 0.15716540770606555
0    6.497953
dtype: float32
Epoch 117, train loss: 0.06288690521722311 test loss: 0.18237102568973965
0    6.941267
dtype: float32
Epoch 118, train loss: 0.05992594848599845 test loss: 0.1604783703261262
0    7.245502
dtype: float32
Epoch 119, train loss: 0.06798261257622104 test loss: 0.15797303876645724
0    6.151559
dtype: float32
Epoch 120, train loss: 0.070008489570796 test loss: 0.21667053100805234
0    6.097239
dtype: float32
Epoch 121, train loss: 0.08322243170750984 test loss: 0.21549870730147574
0    6.312273
dtype: float32
Epoch 122, train loss: 0.09973342147468589 test loss: 0.1892004504521773
0    4.091122
dtype: float32
Epoch 123, train loss: 0.2528478144579494 test loss: 0.518300045035746
0    5.635662
dtype: float32
Epoch 124, train loss: 0.17494444718260418 test loss: 0.2646388120488119
0    6.556154
dtype: float32
Epoch 125, train loss: 0.06742558871035423 test loss: 0.17102435299099553
0    6.388358
dtype: float32
Epoch 126, train loss: 0.0666015092743833 test loss: 0.1836437674094341
0    6.485611
dtype: float32
Epoch 127, train loss: 0.06627658668504079 test loss: 0.17636373816350673
0    6.974296
dtype: float32
Epoch 128, train loss: 0.05988970127912654 test loss: 0.15240129009669867
0    6.889586
dtype: float32
Epoch 129, train loss: 0.0599522038035245 test loss: 0.16283729852233458
0    7.128425
dtype: float32
Epoch 130, train loss: 0.06532769175644303 test loss: 0.15208344041251715
0    6.671558
dtype: float32
Epoch 131, train loss: 0.059948794637754314 test loss: 0.17025247250023479
0    6.984771
dtype: float32
Epoch 132, train loss: 0.05851906014784741 test loss: 0.1493680491423187
0    6.65049
dtype: float32
Epoch 133, train loss: 0.067772443692619 test loss: 0.17370764438903338
0    6.353255
dtype: float32
Epoch 134, train loss: 0.0733017421663012 test loss: 0.2003228392760645
0    6.218844
dtype: float32
Epoch 135, train loss: 0.1252219889220426 test loss: 0.21811097388920017
0    5.878767
dtype: float32
Epoch 136, train loss: 0.10352938881582467 test loss: 0.2508211703596886
0    5.495492
dtype: float32
Epoch 137, train loss: 0.13271245347441807 test loss: 0.29117565652972266
0    7.174018
dtype: float32
Epoch 138, train loss: 0.06652950740770035 test loss: 0.14827031153869394
0    6.029059
dtype: float32
Epoch 139, train loss: 0.08054333224083789 test loss: 0.22505134309031055
0    6.13992
dtype: float32
Epoch 140, train loss: 0.07924687829757886 test loss: 0.22258148487931653
0    6.529714
dtype: float32
Epoch 141, train loss: 0.07097401771108239 test loss: 0.1898910717960506
0    5.071759
dtype: float32
Epoch 142, train loss: 0.20002616033622722 test loss: 0.3604449861512942
0    6.536088
dtype: float32
Epoch 143, train loss: 0.06337482159879623 test loss: 0.17339603223168312
0    7.2698
dtype: float32
Epoch 144, train loss: 0.07295774244611755 test loss: 0.14270312846527256
0    6.955601
dtype: float32
Epoch 145, train loss: 0.05872791389886971 test loss: 0.1468601266265393
0    6.98909
dtype: float32
Epoch 146, train loss: 0.06185949290441542 test loss: 0.1475346463133083
0    7.234216
dtype: float32
Epoch 147, train loss: 0.06486363949526608 test loss: 0.14537129359654832
0    6.806658
dtype: float32
Epoch 148, train loss: 0.05737913229729768 test loss: 0.1593635972296898
0    6.92608
dtype: float32
Epoch 149, train loss: 0.058088994210899934 test loss: 0.1537220249017989
0    6.237651
dtype: float32
Epoch 150, train loss: 0.09063446078617698 test loss: 0.2009712478038778
0    6.477144
dtype: float32
Epoch 151, train loss: 0.06752410205542916 test loss: 0.19251286816299962
0    6.461221
dtype: float32
Epoch 152, train loss: 0.08951235480252143 test loss: 0.1761607858972066
0    6.203072
dtype: float32
Epoch 153, train loss: 0.07604344051229278 test loss: 0.21193407599376607
0    5.583862
dtype: float32
Epoch 154, train loss: 0.12764389834505438 test loss: 0.2591846316563533
0    5.593258
dtype: float32
Epoch 155, train loss: 0.1483960799232113 test loss: 0.22588079394740204
0    6.22699
dtype: float32
Epoch 156, train loss: 0.083698112614083 test loss: 0.2382882855276051
0    7.691066
dtype: float32
Epoch 157, train loss: 0.11707048429824853 test loss: 0.172481747206417
0    7.256435
dtype: float32
Epoch 158, train loss: 0.08798319977230885 test loss: 0.14888800312200615
0    6.88234
dtype: float32
Epoch 159, train loss: 0.06493372990685585 test loss: 0.155747660191434
0    6.348826
dtype: float32
Epoch 160, train loss: 0.0716568681157592 test loss: 0.17463800233128962
0    6.909688
dtype: float32
Epoch 161, train loss: 0.0652900998799203 test loss: 0.15728827590629418
0    7.2912
dtype: float32
Epoch 162, train loss: 0.06801758642690611 test loss: 0.15329130424542203
0    7.456706
dtype: float32
Epoch 163, train loss: 0.08235895005711583 test loss: 0.15562347888707098
0    6.85684
dtype: float32
Epoch 164, train loss: 0.06750667544589951 test loss: 0.162063226317599
0    5.947845
dtype: float32
Epoch 165, train loss: 0.09148148954896329 test loss: 0.23138331210347873
0    6.37439
dtype: float32
Epoch 166, train loss: 0.0623833521447581 test loss: 0.18247776866951929
0    7.187778
dtype: float32
Epoch 167, train loss: 0.07246663123555229 test loss: 0.14315639904550337
0    6.702748
dtype: float32
Epoch 168, train loss: 0.05850278251180729 test loss: 0.1533526620168608
0    6.912262
dtype: float32
Epoch 169, train loss: 0.05674067970014693 test loss: 0.1464990398361128
0    6.827902
dtype: float32
Epoch 170, train loss: 0.06044886222184764 test loss: 0.14731751491296297
0    6.503854
dtype: float32
Epoch 171, train loss: 0.07293707865443347 test loss: 0.1726927727491737
0    6.669206
dtype: float32
Epoch 172, train loss: 0.05743917552185708 test loss: 0.16477794251892125
0    5.636651
dtype: float32
Epoch 173, train loss: 0.12269885467451608 test loss: 0.26698063115378645
0    6.79607
dtype: float32
Epoch 174, train loss: 0.05680724351260886 test loss: 0.15834800426815537
0    7.054682
dtype: float32
Epoch 175, train loss: 0.06340073229879674 test loss: 0.1486505390342029
0    7.781203
dtype: float32
Epoch 176, train loss: 0.10472191711582049 test loss: 0.1595137394782645
0    6.930834
dtype: float32
Epoch 177, train loss: 0.0606787316071381 test loss: 0.14478591037002883
0    6.917361
dtype: float32
Epoch 178, train loss: 0.05556868874069152 test loss: 0.1358902273812845
0    6.818692
dtype: float32
Epoch 179, train loss: 0.05525066125687078 test loss: 0.14493394212383276
0    6.66105
dtype: float32
Epoch 180, train loss: 0.0588678873761473 test loss: 0.157421506732073
0    7.729215
dtype: float32
Epoch 181, train loss: 0.08635635150722941 test loss: 0.14075873635630795
0    7.317739
dtype: float32
Epoch 182, train loss: 0.07926006337987809 test loss: 0.13762491383767086
0    7.386406
dtype: float32
Epoch 183, train loss: 0.07497186216597107 test loss: 0.13472416499694162
0    6.920859
dtype: float32
Epoch 184, train loss: 0.06117356838726883 test loss: 0.13869451814445663
0    6.735405
dtype: float32
Epoch 185, train loss: 0.05792626843826262 test loss: 0.15555432095272745
0    5.726397
dtype: float32
Epoch 186, train loss: 0.12299346146937495 test loss: 0.2445830489621316
0    7.275118
dtype: float32
Epoch 187, train loss: 0.059300684189211895 test loss: 0.12817811366974022
0    7.154677
dtype: float32
Epoch 188, train loss: 0.05876823812873229 test loss: 0.13725975439783986
0    6.494239
dtype: float32
Epoch 189, train loss: 0.0740170599371737 test loss: 0.170041148930627
0    7.325655
dtype: float32
Epoch 190, train loss: 0.08147848027583557 test loss: 0.14356889992414504
0    7.556388
dtype: float32
Epoch 191, train loss: 0.07226025926358991 test loss: 0.1336651292894323
0    7.039729
dtype: float32
Epoch 192, train loss: 0.056605868051597376 test loss: 0.1385884276379733
0    7.807921
dtype: float32
Epoch 193, train loss: 0.1061134547524907 test loss: 0.16375576016819066
0    7.461048
dtype: float32
Epoch 194, train loss: 0.0743382472017504 test loss: 0.1428754438960826
0    6.520298
dtype: float32
Epoch 195, train loss: 0.06077045035569221 test loss: 0.16274016544106754
0    7.174681
dtype: float32
Epoch 196, train loss: 0.07016854077139104 test loss: 0.14458407959952063
0    7.575202
dtype: float32
Epoch 197, train loss: 0.07590922221809687 test loss: 0.14558975030929316
0    7.044839
dtype: float32
Epoch 198, train loss: 0.06003530342093966 test loss: 0.13424679582991894
0    6.916724
dtype: float32
Epoch 199, train loss: 0.05394339020375776 test loss: 0.13840533997545615
0    6.965971
dtype: float32
Epoch 200, train loss: 0.05376784235116911 test loss: 0.1379516630272352
0    6.495029
dtype: float32
Epoch 201, train loss: 0.06540873177709523 test loss: 0.1639298517051359
0    6.576487
dtype: float32
Epoch 202, train loss: 0.06302208182265394 test loss: 0.1552500965161108
0    5.956274
dtype: float32
Epoch 203, train loss: 0.09484975486380569 test loss: 0.19091978936194448
0    5.929092
dtype: float32
Epoch 204, train loss: 0.08306083757119885 test loss: 0.2126929927325348
0    6.989202
dtype: float32
Epoch 205, train loss: 0.05628940640827973 test loss: 0.13476423761859754
0    7.125947
dtype: float32
Epoch 206, train loss: 0.056195507089389515 test loss: 0.13163958883763938
0    6.655887
dtype: float32
Epoch 207, train loss: 0.055519509472825926 test loss: 0.14835406465521508
0    7.443853
dtype: float32
Epoch 208, train loss: 0.07584609405103022 test loss: 0.14050198355426874
0    7.602107
dtype: float32
Epoch 209, train loss: 0.09032458864809906 test loss: 0.13845669145997896
0    7.376561
dtype: float32
Epoch 210, train loss: 0.07042226199303162 test loss: 0.13487398285470853
0    7.29967
dtype: float32
Epoch 211, train loss: 0.06074491279441802 test loss: 0.12733456286263078
0    7.549845
dtype: float32
Epoch 212, train loss: 0.08655226722175806 test loss: 0.14450664283657522
0    7.317019
dtype: float32
Epoch 213, train loss: 0.06937180504059781 test loss: 0.13146997532012183
0    7.274403
dtype: float32
Epoch 214, train loss: 0.0645111212432319 test loss: 0.13484796704384855
0    7.071088
dtype: float32
Epoch 215, train loss: 0.05400064846489735 test loss: 0.12733109891410896
0    6.076059
dtype: float32
Epoch 216, train loss: 0.07635468696326943 test loss: 0.1898208865484718
0    6.682835
dtype: float32
Epoch 217, train loss: 0.055410428276602315 test loss: 0.1489735063601749
0    6.933132
dtype: float32
Epoch 218, train loss: 0.054373572942950504 test loss: 0.13274617147998244
0    7.263048
dtype: float32
Epoch 219, train loss: 0.06861629992150521 test loss: 0.13124782206704996
0    7.392654
dtype: float32
Epoch 220, train loss: 0.07913770735983315 test loss: 0.12984526332596918
0    7.321927
dtype: float32
Epoch 221, train loss: 0.057097677257361444 test loss: 0.1135380598078939
0    6.525488
dtype: float32
Epoch 222, train loss: 0.06307362285062118 test loss: 0.16255546735146265
0    7.178918
dtype: float32
Epoch 223, train loss: 0.0561596367680636 test loss: 0.11849439062218116
0    7.177212
dtype: float32
Epoch 224, train loss: 0.057306896661608916 test loss: 0.1257709919243537
0    7.185769
dtype: float32
Epoch 225, train loss: 0.06435554089438193 test loss: 0.13373584839446487
0    7.009966
dtype: float32
Epoch 226, train loss: 0.06628438201367602 test loss: 0.13692222655078723
0    7.788917
dtype: float32
Epoch 227, train loss: 0.0981767935515377 test loss: 0.13852953438169402
0    6.767284
dtype: float32
Epoch 228, train loss: 0.05516875337315914 test loss: 0.14072370132743167
0    7.708784
dtype: float32
Epoch 229, train loss: 0.08776606785276907 test loss: 0.15020358174025003
0    8.182148
dtype: float32
Epoch 230, train loss: 0.11106847633850582 test loss: 0.16577614911551197
0    7.773544
dtype: float32
Epoch 231, train loss: 0.09159872063273988 test loss: 0.1535047842765051
0    6.884975
dtype: float32
Epoch 232, train loss: 0.05262273679669749 test loss: 0.13323134288127902
0    7.21674
dtype: float32
Epoch 233, train loss: 0.05734768126281377 test loss: 0.1251705161095846
0    6.709596
dtype: float32
Epoch 234, train loss: 0.05238781652575905 test loss: 0.1342004536509074
0    7.097367
dtype: float32
Epoch 235, train loss: 0.05625499011654035 test loss: 0.12071824197607567
0    6.359127
dtype: float32
Epoch 236, train loss: 0.06463404668309038 test loss: 0.1578027051278377
0    6.695888
dtype: float32
Epoch 237, train loss: 0.05225613221318466 test loss: 0.13772679474867697
0    6.67688
dtype: float32
Epoch 238, train loss: 0.05309363641050504 test loss: 0.1380405223835632
0    7.451079
dtype: float32
Epoch 239, train loss: 0.0648202107143897 test loss: 0.12923156962133983
0    6.953077
dtype: float32
Epoch 240, train loss: 0.07170585571525614 test loss: 0.13048898159527306
0    7.624242
dtype: float32
Epoch 241, train loss: 0.09113745246923803 test loss: 0.1406423814527691
0    6.99556
dtype: float32
Epoch 242, train loss: 0.05417104380344326 test loss: 0.1288953031184097
0    7.039461
dtype: float32
Epoch 243, train loss: 0.05351423099796439 test loss: 0.12557238983223876
0    7.670871
dtype: float32
Epoch 244, train loss: 0.0905824751872015 test loss: 0.1438033897365624
0    7.03821
dtype: float32
Epoch 245, train loss: 0.05588893957428364 test loss: 0.13513896797993016
0    7.312494
dtype: float32
Epoch 246, train loss: 0.06317167753903866 test loss: 0.1344355564637323
0    6.852755
dtype: float32
Epoch 247, train loss: 0.053523706330846 test loss: 0.14626252732054565
0    6.882926
dtype: float32
Epoch 248, train loss: 0.05273275688916115 test loss: 0.13577811976349105
0    7.433903
dtype: float32
Epoch 249, train loss: 0.0687701784299984 test loss: 0.12939116124118202
0    7.154848
dtype: float32
Epoch 250, train loss: 0.05363114412050784 test loss: 0.12623087047786136
0    7.199954
dtype: float32
Epoch 251, train loss: 0.06068909139002829 test loss: 0.12647781662118115
0    6.618071
dtype: float32
Epoch 252, train loss: 0.05804639037442635 test loss: 0.14283108428759986
0    6.334791
dtype: float32
Epoch 253, train loss: 0.06367183656971566 test loss: 0.1685331650635686
0    7.849027
dtype: float32
Epoch 254, train loss: 0.089081639058869 test loss: 0.15511390852754273
0    7.315766
dtype: float32
Epoch 255, train loss: 0.05993381346502124 test loss: 0.1279314824948147
0    7.222933
dtype: float32
Epoch 256, train loss: 0.058422161293453255 test loss: 0.14688512547225294
0    6.455193
dtype: float32
Epoch 257, train loss: 0.07116982761818766 test loss: 0.15694133204861543
0    6.931002
dtype: float32
Epoch 258, train loss: 0.05622863475317642 test loss: 0.13726390025189386
0    6.865676
dtype: float32
Epoch 259, train loss: 0.05073532158814123 test loss: 0.12943162464072394
0    6.483625
dtype: float32
Epoch 260, train loss: 0.05407165883805101 test loss: 0.13655757266195612
0    6.936892
dtype: float32
Epoch 261, train loss: 0.05751074317416126 test loss: 0.12641907832660573
0    6.894133
dtype: float32
Epoch 262, train loss: 0.055778713627002485 test loss: 0.13769669313155125
0    6.736207
dtype: float32
Epoch 263, train loss: 0.05627353744616702 test loss: 0.12958330069740734
0    6.766472
dtype: float32
Epoch 264, train loss: 0.053004309023540364 test loss: 0.12144783724267853
0    7.034313
dtype: float32
Epoch 265, train loss: 0.053719458383245024 test loss: 0.12534041981279587
0    6.751024
dtype: float32
Epoch 266, train loss: 0.053954758339951954 test loss: 0.118892935536339
0    5.731995
dtype: float32
Epoch 267, train loss: 0.12073070462491944 test loss: 0.20249617381505913
0    5.883826
dtype: float32
Epoch 268, train loss: 0.09950168957671841 test loss: 0.19058003327228007
0    7.005311
dtype: float32
Epoch 269, train loss: 0.052624888841922 test loss: 0.11444909356076631
0    6.480815
dtype: float32
Epoch 270, train loss: 0.05999603996677195 test loss: 0.14268495590728306
0    5.962326
dtype: float32
Epoch 271, train loss: 0.09520231630433827 test loss: 0.19794248516438828
0    7.08904
dtype: float32
Epoch 272, train loss: 0.06685903796836443 test loss: 0.12881027128648564
0    7.23073
dtype: float32
Epoch 273, train loss: 0.05502366594908426 test loss: 0.11827976291912268
0    6.687178
dtype: float32
Epoch 274, train loss: 0.05424303406360046 test loss: 0.13671135215534963
0    7.101619
dtype: float32
Epoch 275, train loss: 0.05331335071942497 test loss: 0.12115834817169616
0    6.170637
dtype: float32
Epoch 276, train loss: 0.09985706252849107 test loss: 0.15762058852229724
0    6.277282
dtype: float32
Epoch 277, train loss: 0.0632071742517198 test loss: 0.16217932005531893
0    6.053472
dtype: float32
Epoch 278, train loss: 0.09439208683435384 test loss: 0.16376556065069806
0    6.364428
dtype: float32
Epoch 279, train loss: 0.06009267705829276 test loss: 0.14807796313436394
0    6.931357
dtype: float32
Epoch 280, train loss: 0.05442278475258752 test loss: 0.12957160236400653
0    6.863582
dtype: float32
Epoch 281, train loss: 0.050202521392999355 test loss: 0.12523424886956466
0    7.699788
dtype: float32
Epoch 282, train loss: 0.09384499137692912 test loss: 0.15065019465561222
0    7.030583
dtype: float32
Epoch 283, train loss: 0.06111978353877379 test loss: 0.12526741535606312
0    6.724298
dtype: float32
Epoch 284, train loss: 0.05656191693288581 test loss: 0.12310712035818944
0    6.712379
dtype: float32
Epoch 285, train loss: 0.05711013684673377 test loss: 0.12759892951114746
0    6.089246
dtype: float32
Epoch 286, train loss: 0.09395916009525039 test loss: 0.20895451878007143
0    5.996108
dtype: float32
Epoch 287, train loss: 0.11259534710423783 test loss: 0.16407640441255783
0    5.685351
dtype: float32
Epoch 288, train loss: 0.1228031098967851 test loss: 0.22455941279631106
0    6.776485
dtype: float32
Epoch 289, train loss: 0.054697715550882105 test loss: 0.14526929747441178
0    6.560957
dtype: float32
Epoch 290, train loss: 0.054506429478108666 test loss: 0.14812248808992592
0    7.315287
dtype: float32
Epoch 291, train loss: 0.07025306599012662 test loss: 0.14498906130645667
0    7.310791
dtype: float32
Epoch 292, train loss: 0.06920798721201946 test loss: 0.15160144754637012
0    7.226567
dtype: float32
Epoch 293, train loss: 0.06685566427017865 test loss: 0.14791393989178034
0    6.9049
dtype: float32
Epoch 294, train loss: 0.061588087031063575 test loss: 0.1484259772649559
0    7.325825
dtype: float32
Epoch 295, train loss: 0.06533730480886331 test loss: 0.1365584456190994
0    6.339921
dtype: float32
Epoch 296, train loss: 0.07539608084955071 test loss: 0.1615740911066921
0    7.371343
dtype: float32
Epoch 297, train loss: 0.06590767882344478 test loss: 0.13680067318362935
0    7.119208
dtype: float32
Epoch 298, train loss: 0.05553346426135657 test loss: 0.13404978006986248
0    6.974061
dtype: float32
Epoch 299, train loss: 0.051259048652280204 test loss: 0.1281542243976133
Final train loss is: 0.051259048652280204, Test loss is: 0.1281542243976133
0    6.974061
dtype: float32
round is 4
0    8.98967
dtype: float32
Epoch 6, train loss: 0.2153779873702392 test loss: 0.2999689822307466
0    13.263667
dtype: float32
Epoch 7, train loss: 0.22137082378753162 test loss: 0.5003867209816788
0    11.776226
dtype: float32
Epoch 8, train loss: 0.16779889374716436 test loss: 0.42264042177167244
0    10.188046
dtype: float32
Epoch 9, train loss: 0.14445965704387848 test loss: 0.30403080853347836
0    10.317472
dtype: float32
Epoch 10, train loss: 0.12686770140484252 test loss: 0.30188556527534216
0    11.229329
dtype: float32
Epoch 11, train loss: 0.0985666980774297 test loss: 0.33367683714108753
0    10.692234
dtype: float32
Epoch 12, train loss: 0.12594928173699582 test loss: 0.3212932961697146
0    11.594415
dtype: float32
Epoch 13, train loss: 0.11091371228907325 test loss: 0.34854176707662393
0    11.756639
dtype: float32
Epoch 14, train loss: 0.10394731682986429 test loss: 0.3584393715195858
0    11.609283
dtype: float32
Epoch 15, train loss: 0.09958721658471371 test loss: 0.3487213152905156
0    10.73548
dtype: float32
Epoch 16, train loss: 0.09480499812188545 test loss: 0.3064953338642552
0    11.385718
dtype: float32
Epoch 17, train loss: 0.10190916627219807 test loss: 0.3396803890771924
0    12.343328
dtype: float32
Epoch 18, train loss: 0.159006321831559 test loss: 0.4111647366379489
0    11.399786
dtype: float32
Epoch 19, train loss: 0.09756648063584085 test loss: 0.33669221815214495
0    10.47723
dtype: float32
Epoch 20, train loss: 0.09355827268507137 test loss: 0.2820568090376319
0    11.334574
dtype: float32
Epoch 21, train loss: 0.09401792088537027 test loss: 0.3310427853831979
0    11.34514
dtype: float32
Epoch 22, train loss: 0.09895394721486087 test loss: 0.33300039663181163
0    10.703707
dtype: float32
Epoch 23, train loss: 0.08489679868315761 test loss: 0.2944472867863655
0    10.539113
dtype: float32
Epoch 24, train loss: 0.08450363050874948 test loss: 0.2880701779113798
0    9.808418
dtype: float32
Epoch 25, train loss: 0.13547414005329056 test loss: 0.28004298288945756
0    10.245616
dtype: float32
Epoch 26, train loss: 0.10890052389179555 test loss: 0.27065914385186013
0    11.362634
dtype: float32
Epoch 27, train loss: 0.09339644035040191 test loss: 0.33102560615941523
0    11.358308
dtype: float32
Epoch 28, train loss: 0.0935749360238194 test loss: 0.33087767328365614
0    10.98993
dtype: float32
Epoch 29, train loss: 0.08166515526498057 test loss: 0.3043242024795986
0    10.764041
dtype: float32
Epoch 30, train loss: 0.077681182281396 test loss: 0.2926445060151096
0    9.949147
dtype: float32
Epoch 31, train loss: 0.11571331422741983 test loss: 0.26056178924779144
0    10.479715
dtype: float32
Epoch 32, train loss: 0.07899971615144996 test loss: 0.278095765836108
0    10.505444
dtype: float32
Epoch 33, train loss: 0.07999900660399993 test loss: 0.27740002874833763
0    9.66044
dtype: float32
Epoch 34, train loss: 0.1266495879072707 test loss: 0.2568174198628909
0    10.343653
dtype: float32
Epoch 35, train loss: 0.07893121830233958 test loss: 0.26798235402294374
0    10.21575
dtype: float32
Epoch 36, train loss: 0.08484337918562043 test loss: 0.2620538692123555
0    11.142769
dtype: float32
Epoch 37, train loss: 0.09343117156485636 test loss: 0.31630581754618237
0    11.702527
dtype: float32
Epoch 38, train loss: 0.12712222061944844 test loss: 0.37231667165942767
0    9.463357
dtype: float32
Epoch 39, train loss: 0.16934342324662036 test loss: 0.2626046624587099
0    10.011409
dtype: float32
Epoch 40, train loss: 0.08733635923843144 test loss: 0.24942308415954537
0    9.330776
dtype: float32
Epoch 41, train loss: 0.16150945470496023 test loss: 0.2569681410204864
0    8.835817
dtype: float32
Epoch 42, train loss: 0.2772565225193596 test loss: 0.3032947249338461
0    10.208591
dtype: float32
Epoch 43, train loss: 0.088436280906012 test loss: 0.26401487649864075
0    10.190078
dtype: float32
Epoch 44, train loss: 0.08079083930714934 test loss: 0.26171571021101436
0    10.814025
dtype: float32
Epoch 45, train loss: 0.08514365817351681 test loss: 0.30656327267220984
0    10.055387
dtype: float32
Epoch 46, train loss: 0.08592717962033286 test loss: 0.24781114148097794
0    9.678741
dtype: float32
Epoch 47, train loss: 0.1051633760318904 test loss: 0.23610939101362582
0    10.105063
dtype: float32
Epoch 48, train loss: 0.07580995642107279 test loss: 0.25228389722003275
0    10.053345
dtype: float32
Epoch 49, train loss: 0.07618242569105174 test loss: 0.24277216184973638
0    9.903435
dtype: float32
Epoch 50, train loss: 0.07724420853706054 test loss: 0.24091260283629998
0    9.965436
dtype: float32
Epoch 51, train loss: 0.0851637876997567 test loss: 0.24438925456723998
0    10.705538
dtype: float32
Epoch 52, train loss: 0.07882981248254921 test loss: 0.2901206043032986
0    11.19712
dtype: float32
Epoch 53, train loss: 0.09982362112422186 test loss: 0.32676748673723505
0    10.507475
dtype: float32
Epoch 54, train loss: 0.0726366743174361 test loss: 0.2804011513015112
0    10.103153
dtype: float32
Epoch 55, train loss: 0.06997326221928908 test loss: 0.25191945505083685
0    10.156183
dtype: float32
Epoch 56, train loss: 0.06875281442238507 test loss: 0.25114671828313706
0    9.583665
dtype: float32
Epoch 57, train loss: 0.10189050073055492 test loss: 0.2278664618010761
0    9.852617
dtype: float32
Epoch 58, train loss: 0.0821556658390217 test loss: 0.2335784547186734
0    10.537382
dtype: float32
Epoch 59, train loss: 0.07522569461084189 test loss: 0.2846417439692582
0    10.613481
dtype: float32
Epoch 60, train loss: 0.0908936114627665 test loss: 0.28986604009286077
0    10.974394
dtype: float32
Epoch 61, train loss: 0.10216985867361468 test loss: 0.3196024201720819
0    11.074782
dtype: float32
Epoch 62, train loss: 0.11787156003606045 test loss: 0.3465692582647555
0    10.396899
dtype: float32
Epoch 63, train loss: 0.0711537524377256 test loss: 0.27235299868631185
0    10.414088
dtype: float32
Epoch 64, train loss: 0.07006187835722767 test loss: 0.27162818667372185
0    9.994104
dtype: float32
Epoch 65, train loss: 0.0676205396646251 test loss: 0.24490281928068378
0    9.411729
dtype: float32
Epoch 66, train loss: 0.10261560475336737 test loss: 0.22236141786622748
0    9.585791
dtype: float32
Epoch 67, train loss: 0.09425755021101238 test loss: 0.222408443497632
0    10.112729
dtype: float32
Epoch 68, train loss: 0.06591107010760913 test loss: 0.24983654702047703
0    9.90231
dtype: float32
Epoch 69, train loss: 0.06625907343352085 test loss: 0.2456004259694063
0    10.117884
dtype: float32
Epoch 70, train loss: 0.06482848602785536 test loss: 0.2537780685270381
0    9.570028
dtype: float32
Epoch 71, train loss: 0.07726573832632856 test loss: 0.2272434089769
0    9.458596
dtype: float32
Epoch 72, train loss: 0.09558370742557772 test loss: 0.2233389211906043
0    10.029007
dtype: float32
Epoch 73, train loss: 0.0663406425906084 test loss: 0.2516407780291594
0    10.112933
dtype: float32
Epoch 74, train loss: 0.06918740506288769 test loss: 0.2547556740626558
0    10.235575
dtype: float32
Epoch 75, train loss: 0.07216074510529431 test loss: 0.26411121908590335
0    10.692112
dtype: float32
Epoch 76, train loss: 0.0953134011727124 test loss: 0.30699946462609723
0    9.967146
dtype: float32
Epoch 77, train loss: 0.06238794822913609 test loss: 0.24769402142619973
0    10.589087
dtype: float32
Epoch 78, train loss: 0.09279112079350924 test loss: 0.29009236791136545
0    10.454765
dtype: float32
Epoch 79, train loss: 0.08098151678470132 test loss: 0.2820492191599621
0    9.76194
dtype: float32
Epoch 80, train loss: 0.06971841320503738 test loss: 0.23719739365977882
0    9.628163
dtype: float32
Epoch 81, train loss: 0.0685294400684597 test loss: 0.22593155253737582
0    9.862432
dtype: float32
Epoch 82, train loss: 0.062464327419640996 test loss: 0.237262877973679
0    10.229792
dtype: float32
Epoch 83, train loss: 0.07054622686534949 test loss: 0.2668019865336661
0    9.610853
dtype: float32
Epoch 84, train loss: 0.06384354366618315 test loss: 0.23631068725765764
0    10.173732
dtype: float32
Epoch 85, train loss: 0.07136684099501794 test loss: 0.26302664947307813
0    9.331946
dtype: float32
Epoch 86, train loss: 0.09058779802738727 test loss: 0.22625107312648168
0    9.480999
dtype: float32
Epoch 87, train loss: 0.06813669749891799 test loss: 0.22406786975699988
0    9.91109
dtype: float32
Epoch 88, train loss: 0.06387577192598584 test loss: 0.24707084070049634
0    9.756938
dtype: float32
Epoch 89, train loss: 0.06078331059320519 test loss: 0.23803850238922694
0    9.299352
dtype: float32
Epoch 90, train loss: 0.08401738502104186 test loss: 0.22417601796076303
0    9.412547
dtype: float32
Epoch 91, train loss: 0.07385575986445467 test loss: 0.22696286254970272
0    9.521119
dtype: float32
Epoch 92, train loss: 0.06626099090928723 test loss: 0.22421005962522145
0    9.359917
dtype: float32
Epoch 93, train loss: 0.0815984951070466 test loss: 0.22620793063778571
0    9.864873
dtype: float32
Epoch 94, train loss: 0.06103270194489798 test loss: 0.2456831921349165
0    9.540698
dtype: float32
Epoch 95, train loss: 0.06239421324300751 test loss: 0.2285329217580911
0    9.823171
dtype: float32
Epoch 96, train loss: 0.05986721248300386 test loss: 0.24635418183433605
0    10.044039
dtype: float32
Epoch 97, train loss: 0.06763837523259453 test loss: 0.26171960343598577
0    9.367889
dtype: float32
Epoch 98, train loss: 0.06373584995760073 test loss: 0.22551928822186046
0    9.074941
dtype: float32
Epoch 99, train loss: 0.088834704788594 test loss: 0.22014028119585646
0    9.334892
dtype: float32
Epoch 100, train loss: 0.06673103015441269 test loss: 0.2269579086815525
0    9.124547
dtype: float32
Epoch 101, train loss: 0.0783710179914809 test loss: 0.2200823257496104
0    9.774702
dtype: float32
Epoch 102, train loss: 0.06440258082440187 test loss: 0.2449209568836145
0    10.074028
dtype: float32
Epoch 103, train loss: 0.07682418436529549 test loss: 0.25925574309584043
0    9.377651
dtype: float32
Epoch 104, train loss: 0.06930145469457523 test loss: 0.229101580027033
0    9.203869
dtype: float32
Epoch 105, train loss: 0.08937392308917015 test loss: 0.22040735404913953
0    9.06004
dtype: float32
Epoch 106, train loss: 0.09211505626300648 test loss: 0.21861921717536556
0    9.401434
dtype: float32
Epoch 107, train loss: 0.0697375183631436 test loss: 0.22016760606272892
0    10.000134
dtype: float32
Epoch 108, train loss: 0.06969210327012701 test loss: 0.26498850807948443
0    10.278072
dtype: float32
Epoch 109, train loss: 0.08144366315514699 test loss: 0.27488192528551486
0    9.789572
dtype: float32
Epoch 110, train loss: 0.060286228043185494 test loss: 0.23576312264303298
0    10.00759
dtype: float32
Epoch 111, train loss: 0.06913358599777902 test loss: 0.2550504704969327
0    9.60233
dtype: float32
Epoch 112, train loss: 0.056183908350745645 test loss: 0.2325655399123237
0    9.759813
dtype: float32
Epoch 113, train loss: 0.05840872479416134 test loss: 0.23704891322060886
0    9.467562
dtype: float32
Epoch 114, train loss: 0.055025992046852656 test loss: 0.22194802882989903
0    9.694346
dtype: float32
Epoch 115, train loss: 0.05650975778019649 test loss: 0.23654616868094622
0    9.065845
dtype: float32
Epoch 116, train loss: 0.07465299759075913 test loss: 0.20974741954590947
0    9.858406
dtype: float32
Epoch 117, train loss: 0.06484189124578864 test loss: 0.2517935513293968
0    9.829718
dtype: float32
Epoch 118, train loss: 0.07009061637898828 test loss: 0.24529245149517115
0    9.427645
dtype: float32
Epoch 119, train loss: 0.055399622163457195 test loss: 0.22563379266415912
0    9.468927
dtype: float32
Epoch 120, train loss: 0.05620924103146484 test loss: 0.22689822155138079
0    9.920691
dtype: float32
Epoch 121, train loss: 0.06626002981108611 test loss: 0.25590973814731266
0    9.363345
dtype: float32
Epoch 122, train loss: 0.05911870998475647 test loss: 0.22221176571811724
0    9.246119
dtype: float32
Epoch 123, train loss: 0.06084846808642416 test loss: 0.22270652647182124
0    9.268534
dtype: float32
Epoch 124, train loss: 0.06465750964383268 test loss: 0.21332536678330088
0    9.292074
dtype: float32
Epoch 125, train loss: 0.06060379280415397 test loss: 0.22495925712900897
0    9.598308
dtype: float32
Epoch 126, train loss: 0.05888623502695297 test loss: 0.23873712937537736
0    9.602481
dtype: float32
Epoch 127, train loss: 0.06044295351242016 test loss: 0.24098491959584878
0    9.56008
dtype: float32
Epoch 128, train loss: 0.05228119593680599 test loss: 0.23165795276743548
0    9.095773
dtype: float32
Epoch 129, train loss: 0.062471315427000136 test loss: 0.2116789459785504
0    9.901562
dtype: float32
Epoch 130, train loss: 0.07163691073772456 test loss: 0.26253962014619825
0    9.734211
dtype: float32
Epoch 131, train loss: 0.06701372616040766 test loss: 0.24287779896087403
0    9.080081
dtype: float32
Epoch 132, train loss: 0.06390260616562073 test loss: 0.21504946556368001
0    9.633753
dtype: float32
Epoch 133, train loss: 0.05832509876631583 test loss: 0.2424341574588939
0    9.209546
dtype: float32
Epoch 134, train loss: 0.058191663879578324 test loss: 0.21793470535995757
0    9.688808
dtype: float32
Epoch 135, train loss: 0.061920741755071014 test loss: 0.24696037143003138
0    9.330433
dtype: float32
Epoch 136, train loss: 0.05370384644055217 test loss: 0.22399413602008458
0    9.173668
dtype: float32
Epoch 137, train loss: 0.05085854150232679 test loss: 0.21760446143418896
0    9.32988
dtype: float32
Epoch 138, train loss: 0.052798256653732216 test loss: 0.22277269919852832
0    9.52542
dtype: float32
Epoch 139, train loss: 0.060797914747687226 test loss: 0.23361652990410076
0    9.046263
dtype: float32
Epoch 140, train loss: 0.06828978244343029 test loss: 0.22152266412647834
0    9.723777
dtype: float32
Epoch 141, train loss: 0.07128893708518506 test loss: 0.24584939627981345
0    9.797802
dtype: float32
Epoch 142, train loss: 0.0898451047747183 test loss: 0.2703673963564758
0    9.247826
dtype: float32
Epoch 143, train loss: 0.06065183392359476 test loss: 0.22916557761972403
0    8.876005
dtype: float32
Epoch 144, train loss: 0.057469602118074274 test loss: 0.20275537629456902
0    8.769847
dtype: float32
Epoch 145, train loss: 0.05936053831710607 test loss: 0.20596998514366285
0    9.092984
dtype: float32
Epoch 146, train loss: 0.0524847506363264 test loss: 0.22357267545685788
0    8.828982
dtype: float32
Epoch 147, train loss: 0.05335734375630195 test loss: 0.20912295961436198
0    9.133073
dtype: float32
Epoch 148, train loss: 0.05511769478452874 test loss: 0.23015786538579633
0    9.072763
dtype: float32
Epoch 149, train loss: 0.05828713216335413 test loss: 0.22423461656450502
0    8.753786
dtype: float32
Epoch 150, train loss: 0.05015541567579943 test loss: 0.20855299094427424
0    9.339518
dtype: float32
Epoch 151, train loss: 0.06588504437486303 test loss: 0.23979362959473122
0    8.435671
dtype: float32
Epoch 152, train loss: 0.08094735401665944 test loss: 0.205516741943719
0    8.545712
dtype: float32
Epoch 153, train loss: 0.069614073672347 test loss: 0.20109100665656124
0    9.006951
dtype: float32
Epoch 154, train loss: 0.05791095094210847 test loss: 0.21722985302090211
0    9.345032
dtype: float32
Epoch 155, train loss: 0.06268914613485593 test loss: 0.23370594566143948
0    8.996444
dtype: float32
Epoch 156, train loss: 0.05257017214344351 test loss: 0.22219023822924425
0    9.267063
dtype: float32
Epoch 157, train loss: 0.06215988524699289 test loss: 0.2399200563967091
0    9.295928
dtype: float32
Epoch 158, train loss: 0.06348524026589787 test loss: 0.240957122447421
0    9.115358
dtype: float32
Epoch 159, train loss: 0.05615728500588226 test loss: 0.2243687368519037
0    9.375685
dtype: float32
Epoch 160, train loss: 0.07263647564895247 test loss: 0.23984119264157125
0    8.821238
dtype: float32
Epoch 161, train loss: 0.054886768953678715 test loss: 0.21214195061217125
0    8.598292
dtype: float32
Epoch 162, train loss: 0.06554406321035487 test loss: 0.21026428944533443
0    8.450725
dtype: float32
Epoch 163, train loss: 0.06563869993002405 test loss: 0.20936406324999007
0    9.018129
dtype: float32
Epoch 164, train loss: 0.05244824451733582 test loss: 0.22470254253355113
0    8.485027
dtype: float32
Epoch 165, train loss: 0.05726540920501498 test loss: 0.19846391055501464
0    8.927702
dtype: float32
Epoch 166, train loss: 0.049352417838595244 test loss: 0.22103999120859227
0    8.689092
dtype: float32
Epoch 167, train loss: 0.04918037008064835 test loss: 0.2097089957780078
0    8.336607
dtype: float32
Epoch 168, train loss: 0.06698084160496881 test loss: 0.20018315210981288
0    8.452033
dtype: float32
Epoch 169, train loss: 0.06288129045760546 test loss: 0.19615701337629823
0    8.419864
dtype: float32
Epoch 170, train loss: 0.06824841665207762 test loss: 0.20072587073894727
0    8.828982
dtype: float32
Epoch 171, train loss: 0.05249758796122543 test loss: 0.2133816643184842
0    8.626884
dtype: float32
Epoch 172, train loss: 0.05466189824912319 test loss: 0.20459597094086154
0    8.875958
dtype: float32
Epoch 173, train loss: 0.050599570899375564 test loss: 0.2159680138415703
0    9.058016
dtype: float32
Epoch 174, train loss: 0.05738793670079158 test loss: 0.22837562133293104
0    8.461492
dtype: float32
Epoch 175, train loss: 0.0623370329732137 test loss: 0.20257597327848706
0    8.073545
dtype: float32
Epoch 176, train loss: 0.09946309815976948 test loss: 0.2215136459188026
0    8.361216
dtype: float32
Epoch 177, train loss: 0.07163504519625291 test loss: 0.20388328698336972
0    8.556506
dtype: float32
Epoch 178, train loss: 0.07566249274766002 test loss: 0.19872830926345134
0    9.393543
dtype: float32
Epoch 179, train loss: 0.06684699697988644 test loss: 0.2483781407144832
0    9.039636
dtype: float32
Epoch 180, train loss: 0.052320291996811374 test loss: 0.2222398522282431
0    9.163598
dtype: float32
Epoch 181, train loss: 0.06921083150998276 test loss: 0.22950448988931782
0    9.298577
dtype: float32
Epoch 182, train loss: 0.06350101139102615 test loss: 0.23418885451651383
0    9.166035
dtype: float32
Epoch 183, train loss: 0.06176978992734211 test loss: 0.23146428778671366
0    9.489474
dtype: float32
Epoch 184, train loss: 0.07270899241599413 test loss: 0.24646540139290532
0    9.037231
dtype: float32
Epoch 185, train loss: 0.050301658569677464 test loss: 0.22193481001132415
0    9.010898
dtype: float32
Epoch 186, train loss: 0.04990113705107181 test loss: 0.22321056850464527
0    9.0858
dtype: float32
Epoch 187, train loss: 0.06708612720316104 test loss: 0.2255185871314571
0    9.185265
dtype: float32
Epoch 188, train loss: 0.06032398173883376 test loss: 0.2360264894522319
0    9.37476
dtype: float32
Epoch 189, train loss: 0.07899155133312208 test loss: 0.2540642398930974
0    8.928279
dtype: float32
Epoch 190, train loss: 0.053655337526664786 test loss: 0.22205994450305747
0    8.589799
dtype: float32
Epoch 191, train loss: 0.05602836837478069 test loss: 0.2086099508180196
0    8.765201
dtype: float32
Epoch 192, train loss: 0.05075422023220581 test loss: 0.21477143015005903
0    8.838065
dtype: float32
Epoch 193, train loss: 0.04818206135556382 test loss: 0.221065660919691
0    8.973077
dtype: float32
Epoch 194, train loss: 0.05279439741230417 test loss: 0.2292861420178404
0    8.526245
dtype: float32
Epoch 195, train loss: 0.05446232493964241 test loss: 0.2077181409785038
0    8.632729
dtype: float32
Epoch 196, train loss: 0.050383308218733394 test loss: 0.20964063887520645
0    8.644489
dtype: float32
Epoch 197, train loss: 0.05059673129829026 test loss: 0.20978789390319524
0    9.064868
dtype: float32
Epoch 198, train loss: 0.05836379049623065 test loss: 0.23049715872593377
0    8.70725
dtype: float32
Epoch 199, train loss: 0.04590179670286289 test loss: 0.21231159798693072
0    8.927669
dtype: float32
Epoch 200, train loss: 0.05333662076018376 test loss: 0.22081934263629804
0    8.485106
dtype: float32
Epoch 201, train loss: 0.04836252786565728 test loss: 0.20392715276192003
0    8.819901
dtype: float32
Epoch 202, train loss: 0.055436270036330296 test loss: 0.21939998803001665
0    8.682505
dtype: float32
Epoch 203, train loss: 0.05010018256711512 test loss: 0.21115399826457407
0    8.499203
dtype: float32
Epoch 204, train loss: 0.04789297768057707 test loss: 0.20020057759443594
0    8.166128
dtype: float32
Epoch 205, train loss: 0.06193680995350325 test loss: 0.19581876973289739
0    8.429519
dtype: float32
Epoch 206, train loss: 0.044869501935024585 test loss: 0.20062642249738122
0    8.510857
dtype: float32
Epoch 207, train loss: 0.045800009314181676 test loss: 0.20461301448365862
0    8.736294
dtype: float32
Epoch 208, train loss: 0.06574407830862362 test loss: 0.21574373678710798
0    9.057797
dtype: float32
Epoch 209, train loss: 0.07172291156919229 test loss: 0.22651573847838977
0    8.55998
dtype: float32
Epoch 210, train loss: 0.05196263868132939 test loss: 0.19985177294427675
0    8.499617
dtype: float32
Epoch 211, train loss: 0.05197112628632426 test loss: 0.20200311755964634
0    8.910451
dtype: float32
Epoch 212, train loss: 0.05280480691434663 test loss: 0.21851959714743993
0    8.725488
dtype: float32
Epoch 213, train loss: 0.04659281166793763 test loss: 0.213529783154113
0    8.669702
dtype: float32
Epoch 214, train loss: 0.04572683723942976 test loss: 0.21247914923539918
0    8.614622
dtype: float32
Epoch 215, train loss: 0.0447641567572143 test loss: 0.20914114022761943
0    8.583969
dtype: float32
Epoch 216, train loss: 0.04397550560682342 test loss: 0.21082384642991484
0    8.249174
dtype: float32
Epoch 217, train loss: 0.059222884031877705 test loss: 0.19954615597770486
0    8.483573
dtype: float32
Epoch 218, train loss: 0.04592040114198789 test loss: 0.20523212664196924
0    8.566536
dtype: float32
Epoch 219, train loss: 0.042447909727866856 test loss: 0.20486243969073126
0    8.558848
dtype: float32
Epoch 220, train loss: 0.04511706373293787 test loss: 0.20426923809242395
0    8.779104
dtype: float32
Epoch 221, train loss: 0.05977840332907547 test loss: 0.21907963976472533
0    8.277006
dtype: float32
Epoch 222, train loss: 0.05371196253040297 test loss: 0.19996629104635427
0    9.037272
dtype: float32
Epoch 223, train loss: 0.08070669417317346 test loss: 0.24007761210635842
0    8.439779
dtype: float32
Epoch 224, train loss: 0.04364998794355874 test loss: 0.1993145376799709
0    8.954393
dtype: float32
Epoch 225, train loss: 0.06506484467100242 test loss: 0.23600891245161018
0    8.259419
dtype: float32
Epoch 226, train loss: 0.05008447437861225 test loss: 0.19929444063074797
0    8.649409
dtype: float32
Epoch 227, train loss: 0.05227565726418376 test loss: 0.21275401095227883
0    8.127133
dtype: float32
Epoch 228, train loss: 0.06897918337842916 test loss: 0.21075816124876157
0    7.943139
dtype: float32
Epoch 229, train loss: 0.08053938270996483 test loss: 0.20819772958380145
0    8.288636
dtype: float32
Epoch 230, train loss: 0.04954094750205164 test loss: 0.20190363342296566
0    8.423371
dtype: float32
Epoch 231, train loss: 0.04655562233803943 test loss: 0.21025883472104923
0    8.488226
dtype: float32
Epoch 232, train loss: 0.04249713107071816 test loss: 0.2082388305483873
0    7.836126
dtype: float32
Epoch 233, train loss: 0.09304637207693707 test loss: 0.21790151460408252
0    8.519265
dtype: float32
Epoch 234, train loss: 0.050815561417304936 test loss: 0.2075360444764995
0    8.323903
dtype: float32
Epoch 235, train loss: 0.04922125514386586 test loss: 0.20867340173324225
0    8.563239
dtype: float32
Epoch 236, train loss: 0.04849864584687694 test loss: 0.21620611568920278
0    8.848869
dtype: float32
Epoch 237, train loss: 0.0635518949810371 test loss: 0.2307113255633877
0    8.863441
dtype: float32
Epoch 238, train loss: 0.06072381271524466 test loss: 0.2307228450385761
0    8.706512
dtype: float32
Epoch 239, train loss: 0.049683837402071614 test loss: 0.21561784652378232
0    8.20379
dtype: float32
Epoch 240, train loss: 0.054144467825629 test loss: 0.1942456665072478
0    8.780008
dtype: float32
Epoch 241, train loss: 0.05694773471621507 test loss: 0.21888746947084411
0    8.726976
dtype: float32
Epoch 242, train loss: 0.05851536376328679 test loss: 0.22522508394210675
0    8.20314
dtype: float32
Epoch 243, train loss: 0.050968385976452646 test loss: 0.19909333335164087
0    8.609458
dtype: float32
Epoch 244, train loss: 0.046172701744744776 test loss: 0.21259555380770548
0    8.756547
dtype: float32
Epoch 245, train loss: 0.05625911103462864 test loss: 0.21839935192514304
0    8.38225
dtype: float32
Epoch 246, train loss: 0.048844084691299416 test loss: 0.19852915045274094
0    8.476734
dtype: float32
Epoch 247, train loss: 0.04470408564636631 test loss: 0.20576055881500235
0    8.078892
dtype: float32
Epoch 248, train loss: 0.05873692470602119 test loss: 0.2025712778762873
0    8.153564
dtype: float32
Epoch 249, train loss: 0.05490277876189938 test loss: 0.20867207878316468
0    8.548077
dtype: float32
Epoch 250, train loss: 0.05067097509020808 test loss: 0.21471325283179854
0    8.900395
dtype: float32
Epoch 251, train loss: 0.0836169081779367 test loss: 0.23406766316300978
0    8.776942
dtype: float32
Epoch 252, train loss: 0.05670779861004742 test loss: 0.2204841312608158
0    8.460148
dtype: float32
Epoch 253, train loss: 0.046623863942185144 test loss: 0.20752655149696694
0    8.71732
dtype: float32
Epoch 254, train loss: 0.04928782212665523 test loss: 0.22214976406581283
0    8.446693
dtype: float32
Epoch 255, train loss: 0.041921150699791535 test loss: 0.20750441968005098
0    8.211851
dtype: float32
Epoch 256, train loss: 0.04707679978748991 test loss: 0.20502273614675126
0    8.555417
dtype: float32
Epoch 257, train loss: 0.046307848719210044 test loss: 0.21357667347930825
0    8.817744
dtype: float32
Epoch 258, train loss: 0.062052259855884175 test loss: 0.22828412876384266
0    8.432136
dtype: float32
Epoch 259, train loss: 0.04479664471782975 test loss: 0.20689965832518956
0    8.370479
dtype: float32
Epoch 260, train loss: 0.042413106819903124 test loss: 0.19937314879642581
0    8.439844
dtype: float32
Epoch 261, train loss: 0.04386996049720831 test loss: 0.20722154132189355
0    8.233938
dtype: float32
Epoch 262, train loss: 0.041846207656259946 test loss: 0.1973758900216299
0    8.397455
dtype: float32
Epoch 263, train loss: 0.04160389480104536 test loss: 0.20455238968339215
0    8.474566
dtype: float32
Epoch 264, train loss: 0.04288156233176839 test loss: 0.20712505439132606
0    8.213845
dtype: float32
Epoch 265, train loss: 0.04132764490175293 test loss: 0.19754266810419632
0    8.268544
dtype: float32
Epoch 266, train loss: 0.04107633414407241 test loss: 0.19827158726975633
0    8.133277
dtype: float32
Epoch 267, train loss: 0.04256727484691112 test loss: 0.1917434950133323
0    8.17067
dtype: float32
Epoch 268, train loss: 0.03936877992685459 test loss: 0.1946363579185418
0    8.087312
dtype: float32
Epoch 269, train loss: 0.040337603521840265 test loss: 0.19205901944565532
0    8.128625
dtype: float32
Epoch 270, train loss: 0.04089387496499187 test loss: 0.1947772141576206
0    8.033449
dtype: float32
Epoch 271, train loss: 0.04664740606552578 test loss: 0.19768831529808936
0    7.975151
dtype: float32
Epoch 272, train loss: 0.05117073042475755 test loss: 0.20145233517985497
0    7.920721
dtype: float32
Epoch 273, train loss: 0.045598461860052224 test loss: 0.19402860419012233
0    8.109619
dtype: float32
Epoch 274, train loss: 0.04077994532035702 test loss: 0.19601866583852032
0    8.725697
dtype: float32
Epoch 275, train loss: 0.07481934641131884 test loss: 0.2150749517599029
0    8.393383
dtype: float32
Epoch 276, train loss: 0.04510515130252952 test loss: 0.19955091627227264
0    8.721514
dtype: float32
Epoch 277, train loss: 0.061885657865432375 test loss: 0.2186793162939614
0    8.551656
dtype: float32
Epoch 278, train loss: 0.04978864035320742 test loss: 0.2095794566464755
0    8.407446
dtype: float32
Epoch 279, train loss: 0.043233662631325095 test loss: 0.19996969846764293
0    8.366601
dtype: float32
Epoch 280, train loss: 0.04205006004810015 test loss: 0.20337489891179306
0    7.993088
dtype: float32
Epoch 281, train loss: 0.04976534081480103 test loss: 0.197487135537427
0    8.274462
dtype: float32
Epoch 282, train loss: 0.057344180168005625 test loss: 0.19522216635298034
0    8.587293
dtype: float32
Epoch 283, train loss: 0.051915058883139895 test loss: 0.20804682790604642
0    8.232589
dtype: float32
Epoch 284, train loss: 0.04226096710894036 test loss: 0.19514944236905435
0    8.093238
dtype: float32
Epoch 285, train loss: 0.04290400834127552 test loss: 0.18773515912305855
0    8.263756
dtype: float32
Epoch 286, train loss: 0.04369561177668809 test loss: 0.19932520239622561
0    8.012719
dtype: float32
Epoch 287, train loss: 0.05823425032052154 test loss: 0.18525027421364307
0    7.983284
dtype: float32
Epoch 288, train loss: 0.053877055441166034 test loss: 0.1957855150565231
0    8.356894
dtype: float32
Epoch 289, train loss: 0.04053425751072642 test loss: 0.20230379475629295
0    8.132076
dtype: float32
Epoch 290, train loss: 0.04191569688824789 test loss: 0.19435227312078387
0    8.000295
dtype: float32
Epoch 291, train loss: 0.04612895495710131 test loss: 0.1939333373736138
0    8.198701
dtype: float32
Epoch 292, train loss: 0.0396513059852811 test loss: 0.19436682551740564
0    7.784624
dtype: float32
Epoch 293, train loss: 0.053384875717980826 test loss: 0.18397326570689612
0    8.639925
dtype: float32
Epoch 294, train loss: 0.07300740191964115 test loss: 0.22688368723286553
0    8.036593
dtype: float32
Epoch 295, train loss: 0.050300902382672555 test loss: 0.19540709443454005
0    7.112439
dtype: float32
Epoch 296, train loss: 0.1476043992558524 test loss: 0.22569187933338875
0    8.051817
dtype: float32
Epoch 297, train loss: 0.04867111339522691 test loss: 0.19338827774000833
0    8.038468
dtype: float32
Epoch 298, train loss: 0.04797424095323161 test loss: 0.1909272030825556
0    8.058907
dtype: float32
Epoch 299, train loss: 0.04166718762891909 test loss: 0.1936577530380882
Final train loss is: 0.04166718762891909, Test loss is: 0.1936577530380882
0    8.058907
dtype: float32
low
round is 0
0    10.738013
dtype: float32
Epoch 5, train loss: 0.28618124183181193 test loss: 0.2649982818275066
0    9.967712
dtype: float32
Epoch 6, train loss: 0.304767123589372 test loss: 0.27026683954419195
0    8.341341
dtype: float32
Epoch 7, train loss: 0.1919864371616541 test loss: 0.24591257665379695
0    8.702208
dtype: float32
Epoch 8, train loss: 0.19822005093179892 test loss: 0.17481912285800386
0    8.985646
dtype: float32
Epoch 9, train loss: 0.2262777709777783 test loss: 0.22905041728853814
0    8.04926
dtype: float32
Epoch 10, train loss: 0.2133820642060516 test loss: 0.26616761143394585
0    8.304148
dtype: float32
Epoch 11, train loss: 0.1579703697793968 test loss: 0.18464069262164412
0    8.794383
dtype: float32
Epoch 12, train loss: 0.18830010877218478 test loss: 0.2025971817603862
0    9.023043
dtype: float32
Epoch 13, train loss: 0.21473969052160707 test loss: 0.2324404790452039
0    9.046759
dtype: float32
Epoch 14, train loss: 0.21307972347752238 test loss: 0.22207847862378088
0    8.220986
dtype: float32
Epoch 15, train loss: 0.1783922524106655 test loss: 0.182726389398292
0    8.539116
dtype: float32
Epoch 16, train loss: 0.18342634302736727 test loss: 0.19232306932446966
0    8.475625
dtype: float32
Epoch 17, train loss: 0.18428434241034863 test loss: 0.22161692547445724
0    8.14104
dtype: float32
Epoch 18, train loss: 0.1772924237944173 test loss: 0.20770617936509075
0    7.833967
dtype: float32
Epoch 19, train loss: 0.15953418352419022 test loss: 0.19275433934910494
0    7.555285
dtype: float32
Epoch 20, train loss: 0.15840260284015223 test loss: 0.18962341702650892
0    7.753284
dtype: float32
Epoch 21, train loss: 0.17215734042960593 test loss: 0.1926411033483179
0    7.761585
dtype: float32
Epoch 22, train loss: 0.15489187980568542 test loss: 0.21949017575062627
0    7.569436
dtype: float32
Epoch 23, train loss: 0.15420638143081972 test loss: 0.19012132643757543
0    7.695319
dtype: float32
Epoch 24, train loss: 0.144868221841742 test loss: 0.18069838478651573
0    7.525875
dtype: float32
Epoch 25, train loss: 0.12651135140442243 test loss: 0.17919681689152944
0    7.161731
dtype: float32
Epoch 26, train loss: 0.08363167371147812 test loss: 0.19024188007196913
0    7.152041
dtype: float32
Epoch 27, train loss: 0.08150398387662511 test loss: 0.17224886446540572
0    7.464606
dtype: float32
Epoch 28, train loss: 0.10231073873213407 test loss: 0.17264747606420267
0    7.525218
dtype: float32
Epoch 29, train loss: 0.10185213989725438 test loss: 0.17505439974009002
0    7.597662
dtype: float32
Epoch 30, train loss: 0.12933162125892628 test loss: 0.16418683305202547
0    7.381714
dtype: float32
Epoch 31, train loss: 0.08901176099259483 test loss: 0.16445734605452192
0    7.329601
dtype: float32
Epoch 32, train loss: 0.07934797646667402 test loss: 0.16769567772131036
0    7.331104
dtype: float32
Epoch 33, train loss: 0.08009629637150899 test loss: 0.1813393235998548
0    8.170317
dtype: float32
Epoch 34, train loss: 0.1482069004851052 test loss: 0.17228613054312772
0    7.707503
dtype: float32
Epoch 35, train loss: 0.10915220701530884 test loss: 0.15807052121400444
0    7.066405
dtype: float32
Epoch 36, train loss: 0.06157821982494912 test loss: 0.1890531360884206
0    6.319611
dtype: float32
Epoch 37, train loss: 0.11925623027037262 test loss: 0.3061082587758694
0    6.581943
dtype: float32
Epoch 38, train loss: 0.08198006163386044 test loss: 0.23841425793267482
0    5.715683
dtype: float32
Epoch 39, train loss: 0.21816616304485753 test loss: 0.37796249050147057
0    6.134268
dtype: float32
Epoch 40, train loss: 0.1475964247870561 test loss: 0.33863796661145534
0    6.645626
dtype: float32
Epoch 41, train loss: 0.08046142747530909 test loss: 0.2759667192204814
0    6.299119
dtype: float32
Epoch 42, train loss: 0.11038273804941176 test loss: 0.2521115623930344
0    6.575016
dtype: float32
Epoch 43, train loss: 0.08582284387979817 test loss: 0.23615943891755967
0    6.447009
dtype: float32
Epoch 44, train loss: 0.09673859881622625 test loss: 0.2567066574926847
0    6.782362
dtype: float32
Epoch 45, train loss: 0.06557396551158538 test loss: 0.23259883927772398
0    7.065664
dtype: float32
Epoch 46, train loss: 0.05688549357522139 test loss: 0.19084543906195373
0    6.301772
dtype: float32
Epoch 47, train loss: 0.11939010238667085 test loss: 0.27946591616295163
0    6.368052
dtype: float32
Epoch 48, train loss: 0.12368831579650975 test loss: 0.31472685199253586
0    6.078947
dtype: float32
Epoch 49, train loss: 0.170937172536941 test loss: 0.37095107952567596
0    6.464919
dtype: float32
Epoch 50, train loss: 0.10405232495068596 test loss: 0.28658861133383
0    6.600533
dtype: float32
Epoch 51, train loss: 0.08478573401702223 test loss: 0.2702583613898907
0    7.135944
dtype: float32
Epoch 52, train loss: 0.054955461300818506 test loss: 0.2164679095697777
0    7.297617
dtype: float32
Epoch 53, train loss: 0.05879589880842767 test loss: 0.194689622786727
0    7.878846
dtype: float32
Epoch 54, train loss: 0.1230883892397332 test loss: 0.17065110009370754
0    7.607566
dtype: float32
Epoch 55, train loss: 0.10653874870473126 test loss: 0.1748366001770642
0    8.034334
dtype: float32
Epoch 56, train loss: 0.13713135834072332 test loss: 0.16668562948533858
0    7.518778
dtype: float32
Epoch 57, train loss: 0.09186069367579215 test loss: 0.1581294532055169
0    7.299858
dtype: float32
Epoch 58, train loss: 0.06763282560480335 test loss: 0.1772926007385266
0    6.909086
dtype: float32
Epoch 59, train loss: 0.058872715278104226 test loss: 0.22615492588793953
0    6.987941
dtype: float32
Epoch 60, train loss: 0.06736321648085553 test loss: 0.26314950578268304
0    7.010432
dtype: float32
Epoch 61, train loss: 0.058626943187682114 test loss: 0.23921851600625824
0    7.687172
dtype: float32
Epoch 62, train loss: 0.08649135056723162 test loss: 0.1780063716688733
0    7.421268
dtype: float32
Epoch 63, train loss: 0.06684370715102682 test loss: 0.18604880792827297
0    7.791389
dtype: float32
Epoch 64, train loss: 0.11010963561474428 test loss: 0.17001676500402377
0    8.189113
dtype: float32
Epoch 65, train loss: 0.12717970177582547 test loss: 0.19963313134330737
0    7.584976
dtype: float32
Epoch 66, train loss: 0.08239816242239166 test loss: 0.20841895234724364
0    8.242407
dtype: float32
Epoch 67, train loss: 0.13724941435732751 test loss: 0.20104187832833242
0    7.805946
dtype: float32
Epoch 68, train loss: 0.09879525361896635 test loss: 0.19739435795131668
0    7.884528
dtype: float32
Epoch 69, train loss: 0.11047912530758726 test loss: 0.18292327832932553
0    7.697381
dtype: float32
Epoch 70, train loss: 0.0958027093115038 test loss: 0.18047163416273743
0    7.749105
dtype: float32
Epoch 71, train loss: 0.09023896677393972 test loss: 0.20591819393007563
0    7.804403
dtype: float32
Epoch 72, train loss: 0.09550109911948645 test loss: 0.21813629797663237
0    7.6347
dtype: float32
Epoch 73, train loss: 0.08646053689564694 test loss: 0.1832829457874371
0    7.70508
dtype: float32
Epoch 74, train loss: 0.08358366493076182 test loss: 0.19834420405654424
0    7.791092
dtype: float32
Epoch 75, train loss: 0.10282719030104845 test loss: 0.18686550600403753
0    7.515532
dtype: float32
Epoch 76, train loss: 0.08322019635187289 test loss: 0.19140630900282724
0    7.496124
dtype: float32
Epoch 77, train loss: 0.07971171039854442 test loss: 0.1832009619412936
0    7.593542
dtype: float32
Epoch 78, train loss: 0.07405413603057992 test loss: 0.2348820712321012
0    8.023096
dtype: float32
Epoch 79, train loss: 0.12140688862871969 test loss: 0.21785294011389306
0    7.880155
dtype: float32
Epoch 80, train loss: 0.11896967764840273 test loss: 0.19047406254860877
0    8.06671
dtype: float32
Epoch 81, train loss: 0.14132915679243352 test loss: 0.19686169240746693
0    7.620785
dtype: float32
Epoch 82, train loss: 0.1005935938927443 test loss: 0.2052604213074002
0    7.577355
dtype: float32
Epoch 83, train loss: 0.10088886070572918 test loss: 0.17818535005184785
0    7.097843
dtype: float32
Epoch 84, train loss: 0.05933633427688674 test loss: 0.18924638020463674
0    7.393241
dtype: float32
Epoch 85, train loss: 0.07422082110867595 test loss: 0.1980432621521297
0    7.448267
dtype: float32
Epoch 86, train loss: 0.07416868766920139 test loss: 0.20677638195849396
0    7.461115
dtype: float32
Epoch 87, train loss: 0.07427925750105518 test loss: 0.2118814447444715
0    7.559057
dtype: float32
Epoch 88, train loss: 0.09871566338149187 test loss: 0.1735932462546615
0    7.434364
dtype: float32
Epoch 89, train loss: 0.08513773335089846 test loss: 0.17221583835087492
0    7.274954
dtype: float32
Epoch 90, train loss: 0.06648786035617606 test loss: 0.18630816813570752
0    7.644513
dtype: float32
Epoch 91, train loss: 0.09970354130824254 test loss: 0.1851558311706726
0    7.579561
dtype: float32
Epoch 92, train loss: 0.0895662784878517 test loss: 0.23186282139580053
0    7.120345
dtype: float32
Epoch 93, train loss: 0.052579140421020215 test loss: 0.2289482219377821
0    6.948336
dtype: float32
Epoch 94, train loss: 0.05045895093941394 test loss: 0.25547579944854937
0    6.899921
dtype: float32
Epoch 95, train loss: 0.04898800024039303 test loss: 0.24228776757055778
0    6.642504
dtype: float32
Epoch 96, train loss: 0.06517403905387806 test loss: 0.26135742945132595
0    6.835105
dtype: float32
Epoch 97, train loss: 0.05128307651191229 test loss: 0.24942073972664627
0    7.122538
dtype: float32
Epoch 98, train loss: 0.04826437673322574 test loss: 0.23687832482887294
0    7.200266
dtype: float32
Epoch 99, train loss: 0.05256988272244464 test loss: 0.2264691446091203
0    7.565523
dtype: float32
Epoch 100, train loss: 0.07557049576299273 test loss: 0.21596470195658848
0    7.576863
dtype: float32
Epoch 101, train loss: 0.08517533866128231 test loss: 0.21116780875517308
0    7.667486
dtype: float32
Epoch 102, train loss: 0.08901399540285526 test loss: 0.2004766005642999
0    7.41899
dtype: float32
Epoch 103, train loss: 0.061010631894516706 test loss: 0.2231240104598236
0    7.072783
dtype: float32
Epoch 104, train loss: 0.0465262557154763 test loss: 0.2454371106108876
0    7.02691
dtype: float32
Epoch 105, train loss: 0.04707035881951597 test loss: 0.24679670521887018
0    6.877014
dtype: float32
Epoch 106, train loss: 0.052701681907892345 test loss: 0.262161319393034
0    7.224756
dtype: float32
Epoch 107, train loss: 0.04838486419985326 test loss: 0.24052157261938528
0    7.151866
dtype: float32
Epoch 108, train loss: 0.047268437737014904 test loss: 0.24148073030203349
0    7.124363
dtype: float32
Epoch 109, train loss: 0.04683086090619703 test loss: 0.24736207289629178
0    6.916056
dtype: float32
Epoch 110, train loss: 0.05399391210362983 test loss: 0.26227913649949836
0    7.023722
dtype: float32
Epoch 111, train loss: 0.04650701336844111 test loss: 0.2470674683240705
0    6.870629
dtype: float32
Epoch 112, train loss: 0.0485941321654438 test loss: 0.23016471307202802
0    6.773309
dtype: float32
Epoch 113, train loss: 0.05813835526008563 test loss: 0.27166972363806674
0    6.490142
dtype: float32
Epoch 114, train loss: 0.08704151123711662 test loss: 0.3032486645223111
0    6.710565
dtype: float32
Epoch 115, train loss: 0.05914694135367556 test loss: 0.2508148265952199
0    6.76778
dtype: float32
Epoch 116, train loss: 0.05344800043423149 test loss: 0.24944940469200363
0    6.567829
dtype: float32
Epoch 117, train loss: 0.07519604675393395 test loss: 0.3011272867447678
0    6.012903
dtype: float32
Epoch 118, train loss: 0.14671590289666617 test loss: 0.33715061894642434
0    6.116727
dtype: float32
Epoch 119, train loss: 0.1509217817475939 test loss: 0.39498114605051377
0    5.879709
dtype: float32
Epoch 120, train loss: 0.16856491765996592 test loss: 0.40395879783267835
0    5.705961
dtype: float32
Epoch 121, train loss: 0.18589146958339323 test loss: 0.37736818189402677
0    5.934675
dtype: float32
Epoch 122, train loss: 0.1480295508851017 test loss: 0.33873594158944226
0    5.748892
dtype: float32
Epoch 123, train loss: 0.17248759634668898 test loss: 0.38386745937020067
0    6.523733
dtype: float32
Epoch 124, train loss: 0.08177470386572241 test loss: 0.3290456604920997
0    6.894708
dtype: float32
Epoch 125, train loss: 0.047399103917066705 test loss: 0.2693793595548549
0    7.036602
dtype: float32
Epoch 126, train loss: 0.04642622261520885 test loss: 0.23245524892727634
0    7.284092
dtype: float32
Epoch 127, train loss: 0.06122855102845658 test loss: 0.22894260946175168
0    7.190247
dtype: float32
Epoch 128, train loss: 0.05179309419026084 test loss: 0.24367551296106993
0    7.056429
dtype: float32
Epoch 129, train loss: 0.045382849746742594 test loss: 0.24838289976006925
0    7.33469
dtype: float32
Epoch 130, train loss: 0.064791587405184 test loss: 0.22255534723843698
0    7.437077
dtype: float32
Epoch 131, train loss: 0.06982030762805701 test loss: 0.2121409450477766
0    7.450809
dtype: float32
Epoch 132, train loss: 0.07159998500064467 test loss: 0.19515892013800656
0    7.524206
dtype: float32
Epoch 133, train loss: 0.0789331458899783 test loss: 0.1954614139855628
0    7.418968
dtype: float32
Epoch 134, train loss: 0.07645785743473729 test loss: 0.21183231913524037
0    7.432431
dtype: float32
Epoch 135, train loss: 0.07502378036547877 test loss: 0.24132735610826167
0    7.688039
dtype: float32
Epoch 136, train loss: 0.08478081285160213 test loss: 0.24801755210926338
0    7.333753
dtype: float32
Epoch 137, train loss: 0.06676682641429678 test loss: 0.2382819662009297
0    7.479091
dtype: float32
Epoch 138, train loss: 0.07949329564382625 test loss: 0.2235147678855165
0    7.153449
dtype: float32
Epoch 139, train loss: 0.050488131815236675 test loss: 0.2576681557395409
0    7.042218
dtype: float32
Epoch 140, train loss: 0.045401343811236915 test loss: 0.2409077899756884
0    7.241882
dtype: float32
Epoch 141, train loss: 0.04956993941737467 test loss: 0.25292625432667937
0    7.298058
dtype: float32
Epoch 142, train loss: 0.06153581665220185 test loss: 0.22118917672172803
0    7.371988
dtype: float32
Epoch 143, train loss: 0.06847231376643369 test loss: 0.21637607938926462
0    7.60203
dtype: float32
Epoch 144, train loss: 0.08179243695212021 test loss: 0.22119946753747408
0    7.305596
dtype: float32
Epoch 145, train loss: 0.06401748544791082 test loss: 0.19291527797946026
0    7.591755
dtype: float32
Epoch 146, train loss: 0.08692833655217672 test loss: 0.2385303265205205
0    7.508496
dtype: float32
Epoch 147, train loss: 0.0730946207370398 test loss: 0.25824088929034844
0    7.604276
dtype: float32
Epoch 148, train loss: 0.09318054652762546 test loss: 0.2503545255077089
0    7.110285
dtype: float32
Epoch 149, train loss: 0.046863870805366706 test loss: 0.25997490070600277
0    7.183882
dtype: float32
Epoch 150, train loss: 0.04932130567615485 test loss: 0.26704197916004135
0    6.970684
dtype: float32
Epoch 151, train loss: 0.0434567713715618 test loss: 0.2780928870125728
0    7.113546
dtype: float32
Epoch 152, train loss: 0.04647141773309744 test loss: 0.24736383824732883
0    7.204568
dtype: float32
Epoch 153, train loss: 0.0520356766692946 test loss: 0.2395743303622409
0    7.085139
dtype: float32
Epoch 154, train loss: 0.04344786418145034 test loss: 0.2712465734679423
0    6.935558
dtype: float32
Epoch 155, train loss: 0.042464088009433076 test loss: 0.2567882286650048
0    6.479438
dtype: float32
Epoch 156, train loss: 0.07915662171663376 test loss: 0.32578867304764947
0    6.517066
dtype: float32
Epoch 157, train loss: 0.0744359607728725 test loss: 0.3257930485299225
0    6.577996
dtype: float32
Epoch 158, train loss: 0.07589296250671335 test loss: 0.2961636545911854
0    6.737237
dtype: float32
Epoch 159, train loss: 0.061264016343384374 test loss: 0.3108041626229069
0    6.46731
dtype: float32
Epoch 160, train loss: 0.07928637948674773 test loss: 0.30186814006797963
0    6.409944
dtype: float32
Epoch 161, train loss: 0.08259613653651349 test loss: 0.3176086304445923
0    6.38745
dtype: float32
Epoch 162, train loss: 0.09053082358454939 test loss: 0.34038828052468945
0    6.080083
dtype: float32
Epoch 163, train loss: 0.13871979447511393 test loss: 0.31828237901355355
0    6.116883
dtype: float32
Epoch 164, train loss: 0.11404585163317121 test loss: 0.32192522143493085
0    6.314075
dtype: float32
Epoch 165, train loss: 0.09572630702906847 test loss: 0.326951976678877
0    6.296353
dtype: float32
Epoch 166, train loss: 0.11156541328163823 test loss: 0.344716020647297
0    6.122399
dtype: float32
Epoch 167, train loss: 0.12717534558558274 test loss: 0.3135243862366365
0    6.156999
dtype: float32
Epoch 168, train loss: 0.10286924049632579 test loss: 0.304544738188979
0    5.994404
dtype: float32
Epoch 169, train loss: 0.1515882448466739 test loss: 0.38048469677417773
0    6.555385
dtype: float32
Epoch 170, train loss: 0.07556932096270816 test loss: 0.34730630742142
0    6.287426
dtype: float32
Epoch 171, train loss: 0.09878318340905781 test loss: 0.3424693513831131
0    6.620174
dtype: float32
Epoch 172, train loss: 0.07926084309539634 test loss: 0.3357644203719947
0    6.05053
dtype: float32
Epoch 173, train loss: 0.13887398528284453 test loss: 0.36273443046071335
0    6.554546
dtype: float32
Epoch 174, train loss: 0.08555997213315182 test loss: 0.3438028541341587
0    6.822032
dtype: float32
Epoch 175, train loss: 0.047291330629235837 test loss: 0.2834394130399838
0    6.696851
dtype: float32
Epoch 176, train loss: 0.054918775334630875 test loss: 0.29607144390813245
0    6.732786
dtype: float32
Epoch 177, train loss: 0.05261688529247406 test loss: 0.2762584856314889
0    6.926929
dtype: float32
Epoch 178, train loss: 0.044943712107676316 test loss: 0.279204981417824
0    6.62494
dtype: float32
Epoch 179, train loss: 0.06575274307959796 test loss: 0.3067743289318739
0    6.876864
dtype: float32
Epoch 180, train loss: 0.043536904517378495 test loss: 0.2626864562223875
0    7.176499
dtype: float32
Epoch 181, train loss: 0.04744892790512349 test loss: 0.24888443254980383
0    7.104803
dtype: float32
Epoch 182, train loss: 0.043531258579212515 test loss: 0.2567885609571034
0    7.513194
dtype: float32
Epoch 183, train loss: 0.07410015659349597 test loss: 0.21531703672320313
0    7.520549
dtype: float32
Epoch 184, train loss: 0.07882637008043539 test loss: 0.22060696017507142
0    7.449849
dtype: float32
Epoch 185, train loss: 0.06399966526257665 test loss: 0.2389975549790805
0    7.330773
dtype: float32
Epoch 186, train loss: 0.05583532585779954 test loss: 0.24952800767106653
0    7.375396
dtype: float32
Epoch 187, train loss: 0.056240001146712494 test loss: 0.2564025973001072
0    7.550816
dtype: float32
Epoch 188, train loss: 0.07721966651772838 test loss: 0.23045093423278715
0    7.435315
dtype: float32
Epoch 189, train loss: 0.0589834298942002 test loss: 0.25848582073671683
0    7.210767
dtype: float32
Epoch 190, train loss: 0.04722131159307572 test loss: 0.2648906275982486
0    7.332724
dtype: float32
Epoch 191, train loss: 0.05738429319190629 test loss: 0.2586851788452803
0    7.077667
dtype: float32
Epoch 192, train loss: 0.04096383288129113 test loss: 0.27532595978436286
0    6.863536
dtype: float32
Epoch 193, train loss: 0.046004069778419664 test loss: 0.31021885346912326
0    6.71953
dtype: float32
Epoch 194, train loss: 0.05523670601396991 test loss: 0.3016284081033549
0    6.974187
dtype: float32
Epoch 195, train loss: 0.040170323649515664 test loss: 0.2840373358337789
0    6.944148
dtype: float32
Epoch 196, train loss: 0.03990677807714048 test loss: 0.27829952708338923
0    7.002797
dtype: float32
Epoch 197, train loss: 0.039743557706891135 test loss: 0.2712236914319452
0    6.832716
dtype: float32
Epoch 198, train loss: 0.04468198749966997 test loss: 0.2969724542747868
0    6.679831
dtype: float32
Epoch 199, train loss: 0.060425392646910187 test loss: 0.311728671979879
0    6.400765
dtype: float32
Epoch 200, train loss: 0.07760969371600257 test loss: 0.3366068452952566
0    6.646882
dtype: float32
Epoch 201, train loss: 0.05831490269719138 test loss: 0.31072022222456075
0    6.327433
dtype: float32
Epoch 202, train loss: 0.08967164969003376 test loss: 0.3704152302967004
0    6.626275
dtype: float32
Epoch 203, train loss: 0.05793193835104101 test loss: 0.3171761567844686
0    6.915993
dtype: float32
Epoch 204, train loss: 0.03886617413531277 test loss: 0.27669331805434627
0    6.650168
dtype: float32
Epoch 205, train loss: 0.05293279132347639 test loss: 0.30695951979497743
0    6.764797
dtype: float32
Epoch 206, train loss: 0.04552501407650526 test loss: 0.29092129950937534
0    7.134994
dtype: float32
Epoch 207, train loss: 0.04785823427229785 test loss: 0.2530735610540125
0    6.813061
dtype: float32
Epoch 208, train loss: 0.04103244063924113 test loss: 0.28496897295202694
0    6.261137
dtype: float32
Epoch 209, train loss: 0.10025929476218268 test loss: 0.33098247980184414
0    6.829387
dtype: float32
Epoch 210, train loss: 0.053098073577986696 test loss: 0.3310403594215419
0    6.567025
dtype: float32
Epoch 211, train loss: 0.07780196211049951 test loss: 0.3279959900675787
0    5.933358
dtype: float32
Epoch 212, train loss: 0.15062932791556008 test loss: 0.418162912584612
0    6.393712
dtype: float32
Epoch 213, train loss: 0.0917234325624517 test loss: 0.37793408353301444
0    6.718558
dtype: float32
Epoch 214, train loss: 0.048535369222994396 test loss: 0.3237427831107803
0    7.180523
dtype: float32
Epoch 215, train loss: 0.04717051729963836 test loss: 0.2728736513517763
0    6.864137
dtype: float32
Epoch 216, train loss: 0.03907469308184565 test loss: 0.29650705630491336
0    6.657954
dtype: float32
Epoch 217, train loss: 0.04770428275100984 test loss: 0.29755618914932536
0    6.644407
dtype: float32
Epoch 218, train loss: 0.05524616984213985 test loss: 0.3023391978537104
0    6.48532
dtype: float32
Epoch 219, train loss: 0.06342723582405561 test loss: 0.3083878614993093
0    6.579193
dtype: float32
Epoch 220, train loss: 0.05929009768304047 test loss: 0.3224087912156161
0    6.452366
dtype: float32
Epoch 221, train loss: 0.07052778780562947 test loss: 0.3143571780211272
0    6.773526
dtype: float32
Epoch 222, train loss: 0.04135480144839056 test loss: 0.2934214909117871
0    6.562066
dtype: float32
Epoch 223, train loss: 0.053973084779389696 test loss: 0.3044690789408603
0    6.572897
dtype: float32
Epoch 224, train loss: 0.05438512226743483 test loss: 0.30771942810661457
0    6.891521
dtype: float32
Epoch 225, train loss: 0.03815151854081647 test loss: 0.2859294549020337
0    6.861109
dtype: float32
Epoch 226, train loss: 0.03862318048689482 test loss: 0.2953948001595446
0    7.137008
dtype: float32
Epoch 227, train loss: 0.04845387355307996 test loss: 0.2585315078069788
0    6.993431
dtype: float32
Epoch 228, train loss: 0.03874926208544772 test loss: 0.2719376027517348
0    6.546575
dtype: float32
Epoch 229, train loss: 0.05719670756713187 test loss: 0.3067217380357577
0    6.416555
dtype: float32
Epoch 230, train loss: 0.07663429737192215 test loss: 0.3587687881057925
0    6.215981
dtype: float32
Epoch 231, train loss: 0.10642304751714754 test loss: 0.37115723465799505
0    6.511026
dtype: float32
Epoch 232, train loss: 0.06548381044249156 test loss: 0.33914222566408203
0    6.58088
dtype: float32
Epoch 233, train loss: 0.05881434359110058 test loss: 0.32072381188188037
0    6.354831
dtype: float32
Epoch 234, train loss: 0.08617204846233943 test loss: 0.3551726078987852
0    6.189332
dtype: float32
Epoch 235, train loss: 0.10041044790663199 test loss: 0.3779504851988589
0    5.926108
dtype: float32
Epoch 236, train loss: 0.1337775021342293 test loss: 0.37281823171907535
0    6.026703
dtype: float32
Epoch 237, train loss: 0.11888679803820539 test loss: 0.3803345162584584
0    6.373327
dtype: float32
Epoch 238, train loss: 0.0764991309526997 test loss: 0.36150748737704147
0    6.062532
dtype: float32
Epoch 239, train loss: 0.12508240041765323 test loss: 0.38635870535549355
0    5.94331
dtype: float32
Epoch 240, train loss: 0.14073282313283825 test loss: 0.3922738893388668
0    6.398981
dtype: float32
Epoch 241, train loss: 0.08383267357797368 test loss: 0.36563512845581664
0    6.522388
dtype: float32
Epoch 242, train loss: 0.06832759491319101 test loss: 0.3040258887196453
0    6.684603
dtype: float32
Epoch 243, train loss: 0.05223020057604421 test loss: 0.2979421777605128
0    6.62612
dtype: float32
Epoch 244, train loss: 0.057517760325120945 test loss: 0.32072971189036786
0    7.068401
dtype: float32
Epoch 245, train loss: 0.041797056633985724 test loss: 0.3019757180090216
0    6.889385
dtype: float32
Epoch 246, train loss: 0.037981682917776836 test loss: 0.2956868666172389
0    6.978014
dtype: float32
Epoch 247, train loss: 0.03898068543658001 test loss: 0.2856799234076649
0    6.686847
dtype: float32
Epoch 248, train loss: 0.04889193731935184 test loss: 0.31900732402893606
0    6.514156
dtype: float32
Epoch 249, train loss: 0.062385660286349114 test loss: 0.32270932063127894
0    6.687621
dtype: float32
Epoch 250, train loss: 0.05095688412564607 test loss: 0.30772547958112667
0    6.815519
dtype: float32
Epoch 251, train loss: 0.04049518593835985 test loss: 0.2955778318922645
0    6.452549
dtype: float32
Epoch 252, train loss: 0.0735824444644688 test loss: 0.35939392459021213
0    6.239047
dtype: float32
Epoch 253, train loss: 0.11166153257943065 test loss: 0.4139488268742396
0    6.753015
dtype: float32
Epoch 254, train loss: 0.045188052362122214 test loss: 0.33903912730388364
0    6.898801
dtype: float32
Epoch 255, train loss: 0.03780150258151308 test loss: 0.3031920352194258
0    6.659793
dtype: float32
Epoch 256, train loss: 0.06272690641980565 test loss: 0.34835974892937405
0    6.592713
dtype: float32
Epoch 257, train loss: 0.07428193506825716 test loss: 0.3468182317912459
0    6.697918
dtype: float32
Epoch 258, train loss: 0.05658057988471846 test loss: 0.30990507800150585
0    7.064023
dtype: float32
Epoch 259, train loss: 0.037783462820971545 test loss: 0.2769404256266704
0    7.071729
dtype: float32
Epoch 260, train loss: 0.038000501593055805 test loss: 0.2775499712544648
0    7.1192
dtype: float32
Epoch 261, train loss: 0.04234649893764519 test loss: 0.2733317831939761
0    6.848375
dtype: float32
Epoch 262, train loss: 0.03757763405748501 test loss: 0.29099175325969656
0    6.758739
dtype: float32
Epoch 263, train loss: 0.04134591374553389 test loss: 0.305194929497956
0    7.180042
dtype: float32
Epoch 264, train loss: 0.04950663349304022 test loss: 0.26125288597401514
0    7.328943
dtype: float32
Epoch 265, train loss: 0.06292544670089208 test loss: 0.2730352899773414
0    7.130535
dtype: float32
Epoch 266, train loss: 0.042927648425459514 test loss: 0.28282019007666426
0    7.589025
dtype: float32
Epoch 267, train loss: 0.08310780835401742 test loss: 0.23921026984678065
0    7.187896
dtype: float32
Epoch 268, train loss: 0.049312945667405995 test loss: 0.2713269830083365
0    7.379593
dtype: float32
Epoch 269, train loss: 0.07059835362147787 test loss: 0.25629093102805167
0    7.214098
dtype: float32
Epoch 270, train loss: 0.05142666021120473 test loss: 0.2852070450320735
0    6.944265
dtype: float32
Epoch 271, train loss: 0.03691568947342798 test loss: 0.30477361247273915
0    7.193532
dtype: float32
Epoch 272, train loss: 0.050686529368726724 test loss: 0.27559708747703116
0    7.28995
dtype: float32
Epoch 273, train loss: 0.066828964288778 test loss: 0.25844710758548856
0    7.490954
dtype: float32
Epoch 274, train loss: 0.08259778109885937 test loss: 0.24845504218973288
0    7.384138
dtype: float32
Epoch 275, train loss: 0.07481088469787292 test loss: 0.2538664529476703
0    7.377437
dtype: float32
Epoch 276, train loss: 0.06950373722819522 test loss: 0.26482748293479796
0    7.273104
dtype: float32
Epoch 277, train loss: 0.05573474626556931 test loss: 0.2762356916893407
0    7.073348
dtype: float32
Epoch 278, train loss: 0.03949080710714543 test loss: 0.2845505004640207
0    7.04305
dtype: float32
Epoch 279, train loss: 0.03703997137190556 test loss: 0.30016350556913995
0    6.788612
dtype: float32
Epoch 280, train loss: 0.04135252185699346 test loss: 0.31228898804595173
0    6.875365
dtype: float32
Epoch 281, train loss: 0.038614531310619114 test loss: 0.30584313134821484
0    6.830822
dtype: float32
Epoch 282, train loss: 0.04166540700279937 test loss: 0.32023034664337857
0    6.864209
dtype: float32
Epoch 283, train loss: 0.03691361165973101 test loss: 0.29780796367164886
0    7.151763
dtype: float32
Epoch 284, train loss: 0.0453764967204871 test loss: 0.26719141305938743
0    7.432466
dtype: float32
Epoch 285, train loss: 0.07126593843880939 test loss: 0.24487332487513408
0    7.313653
dtype: float32
Epoch 286, train loss: 0.06127618424614756 test loss: 0.25804888096240375
0    7.420382
dtype: float32
Epoch 287, train loss: 0.07084351954525504 test loss: 0.24612990952626976
0    6.900288
dtype: float32
Epoch 288, train loss: 0.035895086221268586 test loss: 0.29083407124323285
0    6.849515
dtype: float32
Epoch 289, train loss: 0.03787710825300581 test loss: 0.3034658964778291
0    6.835475
dtype: float32
Epoch 290, train loss: 0.03798184604200382 test loss: 0.3063510551857377
0    6.685831
dtype: float32
Epoch 291, train loss: 0.04918093459565169 test loss: 0.32094504270935564
0    6.760167
dtype: float32
Epoch 292, train loss: 0.04187999291031943 test loss: 0.30990517517973387
0    6.69098
dtype: float32
Epoch 293, train loss: 0.047155705919992456 test loss: 0.31063559665478924
0    6.592116
dtype: float32
Epoch 294, train loss: 0.06070380089764737 test loss: 0.3388157263177297
0    6.903828
dtype: float32
Epoch 295, train loss: 0.03725319885955566 test loss: 0.2968573652191799
0    6.425178
dtype: float32
Epoch 296, train loss: 0.08026797080235919 test loss: 0.3348029749476846
0    6.482124
dtype: float32
Epoch 297, train loss: 0.07394067550189433 test loss: 0.34753009982109634
0    6.910249
dtype: float32
Epoch 298, train loss: 0.036162257779035915 test loss: 0.3111338094846005
0    6.593927
dtype: float32
Epoch 299, train loss: 0.06135607704885974 test loss: 0.3459802003260522
Final train loss is: 0.06135607704885974, Test loss is: 0.3459802003260522
0    6.593927
dtype: float32
round is 1
0    9.311562
dtype: float32
Epoch 6, train loss: 0.3040461122775841 test loss: 0.7165518872264505
0    7.958203
dtype: float32
Epoch 7, train loss: 0.23870411856413878 test loss: 0.5886931841609949
0    7.370447
dtype: float32
Epoch 8, train loss: 0.24289823688048126 test loss: 0.48540073457958094
0    7.693976
dtype: float32
Epoch 9, train loss: 0.21695556042359831 test loss: 0.42912523488427473
0    6.768801
dtype: float32
Epoch 10, train loss: 0.1994912566068071 test loss: 0.4080481514364476
0    7.404716
dtype: float32
Epoch 11, train loss: 0.22235180160968052 test loss: 0.35684644201042354
0    7.736271
dtype: float32
Epoch 12, train loss: 0.18816426048419693 test loss: 0.3531761214160533
0    6.758502
dtype: float32
Epoch 13, train loss: 0.16741090213315746 test loss: 0.35727450360930646
0    7.25212
dtype: float32
Epoch 14, train loss: 0.16598810965866548 test loss: 0.3188901138600824
0    8.473137
dtype: float32
Epoch 15, train loss: 0.2031027468951323 test loss: 0.27587436226317197
0    8.01899
dtype: float32
Epoch 16, train loss: 0.18319914681532518 test loss: 0.2721785164828767
0    5.550797
dtype: float32
Epoch 17, train loss: 0.18271349904521844 test loss: 0.3346535771431727
0    6.529714
dtype: float32
Epoch 18, train loss: 0.14256993540461135 test loss: 0.29064984822547024
0    7.798793
dtype: float32
Epoch 19, train loss: 0.15948848561584394 test loss: 0.22785313474724747
0    5.827922
dtype: float32
Epoch 20, train loss: 0.16052602993377696 test loss: 0.2248332694159986
0    8.082
dtype: float32
Epoch 21, train loss: 0.16810319765491116 test loss: 0.2151947570945807
0    6.894984
dtype: float32
Epoch 22, train loss: 0.13172933868052603 test loss: 0.25016476070704785
0    6.631038
dtype: float32
Epoch 23, train loss: 0.12127509277136242 test loss: 0.2243560298007932
0    8.276002
dtype: float32
Epoch 24, train loss: 0.14406741558407296 test loss: 0.20157681946956937
0    6.689094
dtype: float32
Epoch 25, train loss: 0.11520493715830009 test loss: 0.22219063355869906
0    5.621241
dtype: float32
Epoch 26, train loss: 0.1916578039103224 test loss: 0.22856655608626988
0    6.525417
dtype: float32
Epoch 27, train loss: 0.11146678514110853 test loss: 0.1838729597779192
0    6.545491
dtype: float32
Epoch 28, train loss: 0.13384746342288656 test loss: 0.2189406173935527
0    6.334231
dtype: float32
Epoch 29, train loss: 0.11163429434788805 test loss: 0.19350713329741145
0    6.237494
dtype: float32
Epoch 30, train loss: 0.09782784895276384 test loss: 0.17090913529722174
0    6.737621
dtype: float32
Epoch 31, train loss: 0.10281187397521085 test loss: 0.16436362870942764
0    6.47426
dtype: float32
Epoch 32, train loss: 0.10128056858532106 test loss: 0.16517858414164452
0    6.583769
dtype: float32
Epoch 33, train loss: 0.09875731688248228 test loss: 0.16542459919918884
0    6.900532
dtype: float32
Epoch 34, train loss: 0.09798479888731865 test loss: 0.16282939961526255
0    6.942611
dtype: float32
Epoch 35, train loss: 0.1300012686123127 test loss: 0.14386156322767155
0    3.859797
dtype: float32
Epoch 36, train loss: 0.21478057954748372 test loss: 0.15716692469019047
0    6.788399
dtype: float32
Epoch 37, train loss: 0.14464049897289516 test loss: 0.13921299601337642
0    6.832305
dtype: float32
Epoch 38, train loss: 0.09323017157581613 test loss: 0.1486254571996545
0    7.027896
dtype: float32
Epoch 39, train loss: 0.10061805302064274 test loss: 0.13518384205598816
0    7.015371
dtype: float32
Epoch 40, train loss: 0.0897924211123879 test loss: 0.13783744035459813
0    7.233638
dtype: float32
Epoch 41, train loss: 0.10036930542980708 test loss: 0.14534910784711352
0    2.409586
dtype: float32
Epoch 42, train loss: 0.3731952673781059 test loss: 0.22883550757829488
0    5.865085
dtype: float32
Epoch 43, train loss: 0.11239560844193337 test loss: 0.17212420198033718
0    6.233194
dtype: float32
Epoch 44, train loss: 0.1366616862821526 test loss: 0.17524740613788817
0    6.725554
dtype: float32
Epoch 45, train loss: 0.09578848698059851 test loss: 0.12430166629563252
0    6.115185
dtype: float32
Epoch 46, train loss: 0.09387949315725128 test loss: 0.13569908858964025
0    7.146632
dtype: float32
Epoch 47, train loss: 0.09869452171665412 test loss: 0.12415903190803027
0    6.849631
dtype: float32
Epoch 48, train loss: 0.10231593893269303 test loss: 0.12608911473792994
0    6.191021
dtype: float32
Epoch 49, train loss: 0.12229219657541208 test loss: 0.15609199967902015
0    5.536434
dtype: float32
Epoch 50, train loss: 0.1303370020059895 test loss: 0.1417152040160022
0    6.59719
dtype: float32
Epoch 51, train loss: 0.07695227787367892 test loss: 0.1183479593804015
0    6.84646
dtype: float32
Epoch 52, train loss: 0.07774022969916504 test loss: 0.11908669226091681
0    6.551611
dtype: float32
Epoch 53, train loss: 0.07906323074882393 test loss: 0.12294832264929391
0    7.505123
dtype: float32
Epoch 54, train loss: 0.10038552569129963 test loss: 0.12317114142514113
0    6.83154
dtype: float32
Epoch 55, train loss: 0.0944823388678151 test loss: 0.11987435275460447
0    7.192542
dtype: float32
Epoch 56, train loss: 0.09046998170781051 test loss: 0.12442872863122342
0    6.668934
dtype: float32
Epoch 57, train loss: 0.09868601546393686 test loss: 0.12116469165607546
0    7.568245
dtype: float32
Epoch 58, train loss: 0.11675454453542493 test loss: 0.12162887390111425
0    6.675752
dtype: float32
Epoch 59, train loss: 0.0795345361807938 test loss: 0.12273456197612773
0    7.013855
dtype: float32
Epoch 60, train loss: 0.07729529445297253 test loss: 0.1283811054067187
0    7.017065
dtype: float32
Epoch 61, train loss: 0.08165415274967791 test loss: 0.12506014732054904
0    6.89961
dtype: float32
Epoch 62, train loss: 0.08316001142689923 test loss: 0.12351351334719171
0    6.354538
dtype: float32
Epoch 63, train loss: 0.07164654202699244 test loss: 0.1240951008540582
0    6.347553
dtype: float32
Epoch 64, train loss: 0.08263808353186675 test loss: 0.12490999093138659
0    6.832527
dtype: float32
Epoch 65, train loss: 0.06975040514615491 test loss: 0.11656869907616316
0    6.87594
dtype: float32
Epoch 66, train loss: 0.06799769814923745 test loss: 0.11625457443796508
0    6.827106
dtype: float32
Epoch 67, train loss: 0.068261451281206 test loss: 0.11636159478932234
0    6.667645
dtype: float32
Epoch 68, train loss: 0.09021576215539276 test loss: 0.1282459241744435
0    6.762135
dtype: float32
Epoch 69, train loss: 0.07069791711970627 test loss: 0.11252261598146683
0    7.281718
dtype: float32
Epoch 70, train loss: 0.08234032554748107 test loss: 0.11474656398629851
0    6.499545
dtype: float32
Epoch 71, train loss: 0.07503146130745662 test loss: 0.12371744412102573
0    6.793825
dtype: float32
Epoch 72, train loss: 0.0991721716203034 test loss: 0.12235544926098531
0    6.166574
dtype: float32
Epoch 73, train loss: 0.10051839253548701 test loss: 0.13561842453491388
0    6.695321
dtype: float32
Epoch 74, train loss: 0.0703638279828603 test loss: 0.12118950831849404
0    7.156528
dtype: float32
Epoch 75, train loss: 0.06480603618071017 test loss: 0.1171665534322392
0    6.760325
dtype: float32
Epoch 76, train loss: 0.08392727613937065 test loss: 0.123578542379993
0    6.934584
dtype: float32
Epoch 77, train loss: 0.062427250031587805 test loss: 0.12253079778075539
0    6.660075
dtype: float32
Epoch 78, train loss: 0.07476486943311117 test loss: 0.12858860236589845
0    7.077868
dtype: float32
Epoch 79, train loss: 0.08425444901345899 test loss: 0.12048425311542794
0    6.985463
dtype: float32
Epoch 80, train loss: 0.06312569827060825 test loss: 0.11714454265083546
0    6.798157
dtype: float32
Epoch 81, train loss: 0.06070217300037524 test loss: 0.12209808483416583
0    6.41593
dtype: float32
Epoch 82, train loss: 0.07233513735184549 test loss: 0.11864516790320426
0    5.933614
dtype: float32
Epoch 83, train loss: 0.08111525493866321 test loss: 0.12266678900716226
0    5.948043
dtype: float32
Epoch 84, train loss: 0.09550048156200602 test loss: 0.11790771820279375
0    6.969799
dtype: float32
Epoch 85, train loss: 0.07679554987503175 test loss: 0.12302414661087373
0    7.509629
dtype: float32
Epoch 86, train loss: 0.09493533562228908 test loss: 0.12185251437804102
0    7.093858
dtype: float32
Epoch 87, train loss: 0.08681527450317988 test loss: 0.11809832057862954
0    5.769537
dtype: float32
Epoch 88, train loss: 0.10959969865630757 test loss: 0.13145456935572064
0    5.541272
dtype: float32
Epoch 89, train loss: 0.1425232796220689 test loss: 0.15589577124483028
0    6.774664
dtype: float32
Epoch 90, train loss: 0.06437820874902629 test loss: 0.11735004061445277
0    6.351494
dtype: float32
Epoch 91, train loss: 0.06370108614590256 test loss: 0.12039359352462005
0    6.890748
dtype: float32
Epoch 92, train loss: 0.060795417324723953 test loss: 0.11796851917668415
0    6.10085
dtype: float32
Epoch 93, train loss: 0.09043550081290805 test loss: 0.12636194133675466
0    6.445562
dtype: float32
Epoch 94, train loss: 0.06891068339241745 test loss: 0.1192194232920346
0    6.469213
dtype: float32
Epoch 95, train loss: 0.06364579718313254 test loss: 0.12501322525733727
0    7.320127
dtype: float32
Epoch 96, train loss: 0.07748957367921752 test loss: 0.12089233227333476
0    6.780713
dtype: float32
Epoch 97, train loss: 0.061845588345707136 test loss: 0.1179913759389469
0    7.045199
dtype: float32
Epoch 98, train loss: 0.0732909736778979 test loss: 0.11922430698737166
0    7.006973
dtype: float32
Epoch 99, train loss: 0.06343248327197909 test loss: 0.12023766172360204
0    6.458653
dtype: float32
Epoch 100, train loss: 0.06557086059430801 test loss: 0.12189909353212777
0    6.62219
dtype: float32
Epoch 101, train loss: 0.07056413429049617 test loss: 0.13090247607864658
0    6.451356
dtype: float32
Epoch 102, train loss: 0.0691355417261946 test loss: 0.13188687357422776
0    6.721152
dtype: float32
Epoch 103, train loss: 0.0659470854881054 test loss: 0.11835956901466804
0    7.070864
dtype: float32
Epoch 104, train loss: 0.057726867439775426 test loss: 0.1176155277639126
0    7.191391
dtype: float32
Epoch 105, train loss: 0.056611584316583564 test loss: 0.1255605176841285
0    7.470562
dtype: float32
Epoch 106, train loss: 0.07147368032101936 test loss: 0.1260789832291433
0    7.071033
dtype: float32
Epoch 107, train loss: 0.05434876129079013 test loss: 0.11943864519081426
0    6.773743
dtype: float32
Epoch 108, train loss: 0.054557329872723964 test loss: 0.11216912719091442
0    6.608963
dtype: float32
Epoch 109, train loss: 0.08194072958656641 test loss: 0.12000440886412507
0    6.358904
dtype: float32
Epoch 110, train loss: 0.060459297714522096 test loss: 0.11878662706888264
0    6.692053
dtype: float32
Epoch 111, train loss: 0.06574683627261159 test loss: 0.11498992063927337
0    6.517166
dtype: float32
Epoch 112, train loss: 0.05837334387682889 test loss: 0.11868999264784696
0    6.665149
dtype: float32
Epoch 113, train loss: 0.06201741982412145 test loss: 0.12125088869908605
0    6.916783
dtype: float32
Epoch 114, train loss: 0.06049938573936122 test loss: 0.12373308831780995
0    6.411105
dtype: float32
Epoch 115, train loss: 0.07390103798979447 test loss: 0.13159551817298915
0    6.835489
dtype: float32
Epoch 116, train loss: 0.05219362760938341 test loss: 0.1257315211587883
0    6.793778
dtype: float32
Epoch 117, train loss: 0.06328139723375827 test loss: 0.12909098017686946
0    6.677858
dtype: float32
Epoch 118, train loss: 0.08947768368506973 test loss: 0.15581876172530962
0    6.697819
dtype: float32
Epoch 119, train loss: 0.06087033151708206 test loss: 0.1344568085245371
0    6.65159
dtype: float32
Epoch 120, train loss: 0.05636465200291326 test loss: 0.12879165349879707
0    6.931331
dtype: float32
Epoch 121, train loss: 0.06195034716363715 test loss: 0.13102718360589216
0    7.140922
dtype: float32
Epoch 122, train loss: 0.057970697676265205 test loss: 0.12516014982865534
0    7.409582
dtype: float32
Epoch 123, train loss: 0.0898888586009778 test loss: 0.13766398712534694
0    6.675368
dtype: float32
Epoch 124, train loss: 0.05841766132334996 test loss: 0.13725754657661104
0    6.810508
dtype: float32
Epoch 125, train loss: 0.0494955351041291 test loss: 0.1288768387967639
0    6.823337
dtype: float32
Epoch 126, train loss: 0.051605190509919165 test loss: 0.12319189718109115
0    6.845266
dtype: float32
Epoch 127, train loss: 0.0653882395077665 test loss: 0.13669916686728464
0    6.453445
dtype: float32
Epoch 128, train loss: 0.0830026007276877 test loss: 0.1265006188603074
0    7.331671
dtype: float32
Epoch 129, train loss: 0.07441123875892253 test loss: 0.12323052159153264
0    7.325725
dtype: float32
Epoch 130, train loss: 0.06464223906283699 test loss: 0.13316370113776263
0    6.621629
dtype: float32
Epoch 131, train loss: 0.07653404551152007 test loss: 0.14416809038001405
0    6.245323
dtype: float32
Epoch 132, train loss: 0.07535208410556254 test loss: 0.1439998010067931
0    6.511418
dtype: float32
Epoch 133, train loss: 0.056041278421043214 test loss: 0.12843489673705513
0    6.002323
dtype: float32
Epoch 134, train loss: 0.12995369731393971 test loss: 0.1565733364910255
0    6.867566
dtype: float32
Epoch 135, train loss: 0.06185850906247755 test loss: 0.12123366143874963
0    6.857221
dtype: float32
Epoch 136, train loss: 0.0576675915992548 test loss: 0.1236158786137291
0    6.821947
dtype: float32
Epoch 137, train loss: 0.05736490189682713 test loss: 0.12383765333296202
0    6.490511
dtype: float32
Epoch 138, train loss: 0.06549704561356307 test loss: 0.12765989688008125
0    7.102324
dtype: float32
Epoch 139, train loss: 0.056296191295464905 test loss: 0.12474527002691502
0    6.506999
dtype: float32
Epoch 140, train loss: 0.06945221174313931 test loss: 0.1271473351220377
0    6.653784
dtype: float32
Epoch 141, train loss: 0.05097407284730405 test loss: 0.12663435355622868
0    7.015821
dtype: float32
Epoch 142, train loss: 0.05130807140291495 test loss: 0.12709000224097203
0    6.574174
dtype: float32
Epoch 143, train loss: 0.08356727297124238 test loss: 0.15349348661382264
0    6.735975
dtype: float32
Epoch 144, train loss: 0.05288226117470477 test loss: 0.12728107549518927
0    7.192098
dtype: float32
Epoch 145, train loss: 0.05052302106210814 test loss: 0.1268050419720366
0    7.020113
dtype: float32
Epoch 146, train loss: 0.063635859590113 test loss: 0.13499015534256353
0    6.676497
dtype: float32
Epoch 147, train loss: 0.04861008962515637 test loss: 0.13407580101309777
0    7.020565
dtype: float32
Epoch 148, train loss: 0.048697648645778795 test loss: 0.12434980543360859
0    6.711245
dtype: float32
Epoch 149, train loss: 0.0543987048726066 test loss: 0.12034806347135751
0    6.616417
dtype: float32
Epoch 150, train loss: 0.05581872926367508 test loss: 0.12638392550526795
0    7.113538
dtype: float32
Epoch 151, train loss: 0.05738677506703925 test loss: 0.1253470071490215
0    6.972219
dtype: float32
Epoch 152, train loss: 0.04573454435405401 test loss: 0.12522039559185563
0    7.121765
dtype: float32
Epoch 153, train loss: 0.04765725517364864 test loss: 0.1243942389934904
0    7.262069
dtype: float32
Epoch 154, train loss: 0.06528885060887868 test loss: 0.13158887650019022
0    7.311007
dtype: float32
Epoch 155, train loss: 0.08513024935688325 test loss: 0.14429744296516112
0    6.958331
dtype: float32
Epoch 156, train loss: 0.0531314733712581 test loss: 0.14937424892025855
0    6.786963
dtype: float32
Epoch 157, train loss: 0.05372963027928984 test loss: 0.14417958786494028
0    6.90974
dtype: float32
Epoch 158, train loss: 0.07281308046587373 test loss: 0.14072593502066438
0    6.899784
dtype: float32
Epoch 159, train loss: 0.06004181653252568 test loss: 0.12717385566520772
0    7.253651
dtype: float32
Epoch 160, train loss: 0.0819471229030783 test loss: 0.13732858586800104
0    6.827228
dtype: float32
Epoch 161, train loss: 0.049432389328890006 test loss: 0.14061569718492675
0    6.697274
dtype: float32
Epoch 162, train loss: 0.054938364788558354 test loss: 0.14732759975146356
0    6.926543
dtype: float32
Epoch 163, train loss: 0.04431955276669502 test loss: 0.13550393899810576
0    7.021131
dtype: float32
Epoch 164, train loss: 0.048429041190276856 test loss: 0.1330882089429957
0    6.51721
dtype: float32
Epoch 165, train loss: 0.078089334478255 test loss: 0.14946265596705108
0    6.555604
dtype: float32
Epoch 166, train loss: 0.07778809433391932 test loss: 0.1558422671490644
0    6.898782
dtype: float32
Epoch 167, train loss: 0.04431155175596275 test loss: 0.13595088239777636
0    6.915046
dtype: float32
Epoch 168, train loss: 0.04453622362253724 test loss: 0.1375487181948501
0    6.731764
dtype: float32
Epoch 169, train loss: 0.06428629381751957 test loss: 0.1417292821664264
0    6.363488
dtype: float32
Epoch 170, train loss: 0.10036631423985318 test loss: 0.14290144276503378
0    6.507702
dtype: float32
Epoch 171, train loss: 0.08871675271543603 test loss: 0.15383239001122484
0    7.000879
dtype: float32
Epoch 172, train loss: 0.044753592653984715 test loss: 0.12540562720243367
0    7.127941
dtype: float32
Epoch 173, train loss: 0.04948051464889907 test loss: 0.12724214219417965
0    7.463413
dtype: float32
Epoch 174, train loss: 0.09049746128946255 test loss: 0.1329709410040121
0    6.935908
dtype: float32
Epoch 175, train loss: 0.054378880629438395 test loss: 0.12793224266262296
0    7.155139
dtype: float32
Epoch 176, train loss: 0.061665393351345715 test loss: 0.12370114365416525
0    6.926873
dtype: float32
Epoch 177, train loss: 0.04840771029453271 test loss: 0.1317080466730363
0    7.219885
dtype: float32
Epoch 178, train loss: 0.05853540828757693 test loss: 0.13462725882617546
0    7.191635
dtype: float32
Epoch 179, train loss: 0.04842123331651649 test loss: 0.14110646062042664
0    7.228466
dtype: float32
Epoch 180, train loss: 0.05370617713092661 test loss: 0.12815576656499417
0    6.762117
dtype: float32
Epoch 181, train loss: 0.042824800653585855 test loss: 0.15074149118099975
0    6.554131
dtype: float32
Epoch 182, train loss: 0.07114556907802078 test loss: 0.15874994175985369
0    7.210866
dtype: float32
Epoch 183, train loss: 0.053957281683167116 test loss: 0.13888209465764445
0    6.430915
dtype: float32
Epoch 184, train loss: 0.08914200324251141 test loss: 0.15448167523880305
0    7.006526
dtype: float32
Epoch 185, train loss: 0.050481621187344734 test loss: 0.14669072978948033
0    6.818459
dtype: float32
Epoch 186, train loss: 0.04550366965532179 test loss: 0.14287685351524881
0    6.959082
dtype: float32
Epoch 187, train loss: 0.04227052330849446 test loss: 0.12632162212407672
0    7.243473
dtype: float32
Epoch 188, train loss: 0.060651120143869294 test loss: 0.12999302995969683
0    7.373743
dtype: float32
Epoch 189, train loss: 0.06248144828121574 test loss: 0.137148391130511
0    6.927725
dtype: float32
Epoch 190, train loss: 0.04075621407020904 test loss: 0.14659949560822977
0    7.076715
dtype: float32
Epoch 191, train loss: 0.04765745594253138 test loss: 0.15053971384700793
0    6.907173
dtype: float32
Epoch 192, train loss: 0.04137920341060325 test loss: 0.1445019145512919
0    6.939381
dtype: float32
Epoch 193, train loss: 0.042834914001021164 test loss: 0.15794614824896752
0    7.046429
dtype: float32
Epoch 194, train loss: 0.06342039271738421 test loss: 0.17720458108863704
0    7.166368
dtype: float32
Epoch 195, train loss: 0.06431488105050392 test loss: 0.1514477697617693
0    6.770949
dtype: float32
Epoch 196, train loss: 0.04133155586106248 test loss: 0.16985374418693128
0    6.93119
dtype: float32
Epoch 197, train loss: 0.044341085140874585 test loss: 0.14606026701415217
0    7.209334
dtype: float32
Epoch 198, train loss: 0.05352753936352412 test loss: 0.1408247928253346
0    7.433757
dtype: float32
Epoch 199, train loss: 0.07526675185888027 test loss: 0.1437556939994176
0    7.213163
dtype: float32
Epoch 200, train loss: 0.05495262699898563 test loss: 0.15424406913061714
0    7.513672
dtype: float32
Epoch 201, train loss: 0.06235844241618096 test loss: 0.13365235644365198
0    7.275556
dtype: float32
Epoch 202, train loss: 0.05269859245117463 test loss: 0.14394303461490127
0    7.317719
dtype: float32
Epoch 203, train loss: 0.057516497682925716 test loss: 0.1424359922991974
0    6.892548
dtype: float32
Epoch 204, train loss: 0.03947992055969777 test loss: 0.14837827901278908
0    6.704128
dtype: float32
Epoch 205, train loss: 0.05390885824706713 test loss: 0.14086236830458268
0    7.417215
dtype: float32
Epoch 206, train loss: 0.08152739781629269 test loss: 0.15546495482931005
0    6.742321
dtype: float32
Epoch 207, train loss: 0.043683970609591484 test loss: 0.15782302892884723
0    7.06673
dtype: float32
Epoch 208, train loss: 0.047197507380150175 test loss: 0.18516034471836992
0    6.960745
dtype: float32
Epoch 209, train loss: 0.04091891021852934 test loss: 0.17970176657600032
0    6.907564
dtype: float32
Epoch 210, train loss: 0.04005642711486437 test loss: 0.1819789221005025
0    7.273444
dtype: float32
Epoch 211, train loss: 0.056163837295367704 test loss: 0.14641553686804004
0    7.418881
dtype: float32
Epoch 212, train loss: 0.06719290759434665 test loss: 0.16390586010459404
0    7.517712
dtype: float32
Epoch 213, train loss: 0.07335381176691909 test loss: 0.1495560870270992
0    7.219287
dtype: float32
Epoch 214, train loss: 0.04796786980595574 test loss: 0.15546514854507262
0    6.633999
dtype: float32
Epoch 215, train loss: 0.05993322984313055 test loss: 0.1745697138137508
0    6.59023
dtype: float32
Epoch 216, train loss: 0.06585920603563092 test loss: 0.13383782077542028
0    6.694965
dtype: float32
Epoch 217, train loss: 0.04691726719764139 test loss: 0.1349716322914613
0    6.746608
dtype: float32
Epoch 218, train loss: 0.04971978792350618 test loss: 0.1540793698529794
0    7.067234
dtype: float32
Epoch 219, train loss: 0.04196626944270684 test loss: 0.14632379664863998
0    7.342765
dtype: float32
Epoch 220, train loss: 0.05952382812523611 test loss: 0.14691652605876607
0    6.956656
dtype: float32
Epoch 221, train loss: 0.03859031996897359 test loss: 0.14530690241223831
0    6.712314
dtype: float32
Epoch 222, train loss: 0.058919119679873753 test loss: 0.16313651208704855
0    6.78561
dtype: float32
Epoch 223, train loss: 0.07264352804740204 test loss: 0.170780585245413
0    7.139975
dtype: float32
Epoch 224, train loss: 0.05489693599441678 test loss: 0.1646315874745953
0    7.127141
dtype: float32
Epoch 225, train loss: 0.047012327042346654 test loss: 0.1523054355312493
0    6.968345
dtype: float32
Epoch 226, train loss: 0.0401606621819179 test loss: 0.1495026810185246
0    6.957259
dtype: float32
Epoch 227, train loss: 0.03933537191667155 test loss: 0.15215539652804852
0    6.958432
dtype: float32
Epoch 228, train loss: 0.038913267071684327 test loss: 0.16138176821622013
0    7.072313
dtype: float32
Epoch 229, train loss: 0.03868238112709331 test loss: 0.16065311558460996
0    7.007613
dtype: float32
Epoch 230, train loss: 0.03806321963347905 test loss: 0.15353852516699398
0    6.799958
dtype: float32
Epoch 231, train loss: 0.0407977962139595 test loss: 0.17703052989313361
0    6.83322
dtype: float32
Epoch 232, train loss: 0.03781921645650929 test loss: 0.19048384541113472
0    6.759053
dtype: float32
Epoch 233, train loss: 0.05074937414594908 test loss: 0.18916962099823426
0    7.204893
dtype: float32
Epoch 234, train loss: 0.04737861538242583 test loss: 0.16322697486943838
0    7.09411
dtype: float32
Epoch 235, train loss: 0.045877318099534846 test loss: 0.15229114030766322
0    7.105172
dtype: float32
Epoch 236, train loss: 0.039933160822474806 test loss: 0.1621400638382801
0    6.942041
dtype: float32
Epoch 237, train loss: 0.05024995128792047 test loss: 0.1474646816795484
0    6.888565
dtype: float32
Epoch 238, train loss: 0.0496612309424775 test loss: 0.1334084241841124
0    6.218726
dtype: float32
Epoch 239, train loss: 0.08941578490110541 test loss: 0.1393929523919203
0    6.233009
dtype: float32
Epoch 240, train loss: 0.09253025295471892 test loss: 0.1650866520358538
0    6.922384
dtype: float32
Epoch 241, train loss: 0.042912893174876704 test loss: 0.1487913442229246
0    6.8429
dtype: float32
Epoch 242, train loss: 0.03817467281703739 test loss: 0.14873823730985766
0    6.966877
dtype: float32
Epoch 243, train loss: 0.03657874298688591 test loss: 0.15342240344240907
0    7.242088
dtype: float32
Epoch 244, train loss: 0.04742498988429345 test loss: 0.16234488400518832
0    7.171669
dtype: float32
Epoch 245, train loss: 0.044700085521271686 test loss: 0.15386609983875957
0    6.923947
dtype: float32
Epoch 246, train loss: 0.03927463950987574 test loss: 0.15475617931903135
0    6.910196
dtype: float32
Epoch 247, train loss: 0.03980395097939251 test loss: 0.14227757863157545
0    6.552821
dtype: float32
Epoch 248, train loss: 0.07901005598462656 test loss: 0.13746930377493716
0    6.849642
dtype: float32
Epoch 249, train loss: 0.038288833162101056 test loss: 0.15907862518717664
0    7.042119
dtype: float32
Epoch 250, train loss: 0.051583489947593084 test loss: 0.15066349621448458
0    7.230324
dtype: float32
Epoch 251, train loss: 0.0465851573196106 test loss: 0.17886753456823146
0    7.135268
dtype: float32
Epoch 252, train loss: 0.04774845376694948 test loss: 0.19548246998743313
0    7.078715
dtype: float32
Epoch 253, train loss: 0.041030167986695246 test loss: 0.19642399347776113
0    7.318706
dtype: float32
Epoch 254, train loss: 0.05576699444932129 test loss: 0.16675034396716215
0    6.821215
dtype: float32
Epoch 255, train loss: 0.06186935074533044 test loss: 0.20063419679351788
0    7.497913
dtype: float32
Epoch 256, train loss: 0.07652336702117826 test loss: 0.1920507673459265
0    7.212802
dtype: float32
Epoch 257, train loss: 0.043078604269481194 test loss: 0.21549663432720428
0    6.93038
dtype: float32
Epoch 258, train loss: 0.03587416079945925 test loss: 0.1892973567365631
0    6.810795
dtype: float32
Epoch 259, train loss: 0.041205863231082086 test loss: 0.17967564873272748
0    6.677368
dtype: float32
Epoch 260, train loss: 0.05571991292766453 test loss: 0.2003890394698163
0    6.804773
dtype: float32
Epoch 261, train loss: 0.041887241366237914 test loss: 0.19884414332213904
0    7.171649
dtype: float32
Epoch 262, train loss: 0.046699938217405104 test loss: 0.17977724256656366
0    7.266708
dtype: float32
Epoch 263, train loss: 0.04730192153897039 test loss: 0.1976663642836522
0    7.416623
dtype: float32
Epoch 264, train loss: 0.0747596411132212 test loss: 0.1660949781931222
0    7.196633
dtype: float32
Epoch 265, train loss: 0.05056688879903046 test loss: 0.1647254875501016
0    7.333376
dtype: float32
Epoch 266, train loss: 0.06649125507538098 test loss: 0.15855862518065414
0    7.227758
dtype: float32
Epoch 267, train loss: 0.04910918607652616 test loss: 0.16069418750423817
0    7.386211
dtype: float32
Epoch 268, train loss: 0.06295702130173694 test loss: 0.14288748888508082
0    7.025505
dtype: float32
Epoch 269, train loss: 0.03924796197352793 test loss: 0.18568034689309862
0    6.935785
dtype: float32
Epoch 270, train loss: 0.03944811369222494 test loss: 0.18206249009489606
0    6.863646
dtype: float32
Epoch 271, train loss: 0.0403362755640492 test loss: 0.16025527811100962
0    7.006556
dtype: float32
Epoch 272, train loss: 0.03414892662438575 test loss: 0.2104535535504991
0    7.118331
dtype: float32
Epoch 273, train loss: 0.0418367888611308 test loss: 0.21929961260988587
0    7.227284
dtype: float32
Epoch 274, train loss: 0.04756832355148018 test loss: 0.19510482508556956
0    7.061854
dtype: float32
Epoch 275, train loss: 0.038203284403183366 test loss: 0.21864250811816344
0    7.205119
dtype: float32
Epoch 276, train loss: 0.04655917163515694 test loss: 0.2518538155975086
0    6.999547
dtype: float32
Epoch 277, train loss: 0.03891544368071443 test loss: 0.2373256476624352
0    7.074328
dtype: float32
Epoch 278, train loss: 0.03882261604575994 test loss: 0.22943587241222885
0    7.20491
dtype: float32
Epoch 279, train loss: 0.044955065444644886 test loss: 0.2598306952533254
0    6.712193
dtype: float32
Epoch 280, train loss: 0.05002751220898502 test loss: 0.2544667692557639
0    6.518709
dtype: float32
Epoch 281, train loss: 0.059067908379092975 test loss: 0.2544239625631675
0    6.64567
dtype: float32
Epoch 282, train loss: 0.04974866931066877 test loss: 0.2486468486504274
0    7.137822
dtype: float32
Epoch 283, train loss: 0.04500177814919062 test loss: 0.19855264294413977
0    7.12232
dtype: float32
Epoch 284, train loss: 0.047821397625999795 test loss: 0.1564924186613685
0    7.123262
dtype: float32
Epoch 285, train loss: 0.042191451707439744 test loss: 0.2012611031438951
0    7.080594
dtype: float32
Epoch 286, train loss: 0.04814129074559863 test loss: 0.17851276265808147
0    7.179839
dtype: float32
Epoch 287, train loss: 0.04196520233617822 test loss: 0.16103550066939565
0    7.082683
dtype: float32
Epoch 288, train loss: 0.046808183465269035 test loss: 0.16675817754718955
0    6.976434
dtype: float32
Epoch 289, train loss: 0.03556679497896706 test loss: 0.16578183367660643
0    7.045629
dtype: float32
Epoch 290, train loss: 0.037509368679863195 test loss: 0.1727919363129542
0    7.066555
dtype: float32
Epoch 291, train loss: 0.03915789951040814 test loss: 0.15550712267266087
0    6.862274
dtype: float32
Epoch 292, train loss: 0.04204520493744937 test loss: 0.172692867210832
0    6.993198
dtype: float32
Epoch 293, train loss: 0.036085134770030204 test loss: 0.15182492434287773
0    7.131201
dtype: float32
Epoch 294, train loss: 0.049419476264310966 test loss: 0.1540807950602885
0    6.719519
dtype: float32
Epoch 295, train loss: 0.05796328344179225 test loss: 0.15741460354180103
0    6.853693
dtype: float32
Epoch 296, train loss: 0.03355230952778549 test loss: 0.17372857056631433
0    6.927137
dtype: float32
Epoch 297, train loss: 0.037855609646148654 test loss: 0.16615557272546388
0    6.262338
dtype: float32
Epoch 298, train loss: 0.10227790636377668 test loss: 0.19397510605634372
0    6.410328
dtype: float32
Epoch 299, train loss: 0.08875538294298337 test loss: 0.20421092615228134
Final train loss is: 0.08875538294298337, Test loss is: 0.20421092615228134
0    6.410328
dtype: float32
round is 2
0    7.977249
dtype: float32
Epoch 2, train loss: 0.3610737263439499 test loss: 0.31393477486440763
0    5.965741
dtype: float32
Epoch 4, train loss: 0.33990409301499297 test loss: 0.2565566631117578
0    8.312339
dtype: float32
Epoch 5, train loss: 0.3257672878028911 test loss: 0.17671999114890963
0    8.231128
dtype: float32
Epoch 6, train loss: 0.22726728478444855 test loss: 0.14651273539880288
0    8.659945
dtype: float32
Epoch 7, train loss: 0.23896143994555202 test loss: 0.15658607078656783
0    6.747996
dtype: float32
Epoch 8, train loss: 0.2685799180731736 test loss: 0.26530650977694487
0    8.301219
dtype: float32
Epoch 9, train loss: 0.14567574229868974 test loss: 0.09993106636982235
0    8.678078
dtype: float32
Epoch 10, train loss: 0.20289534586467972 test loss: 0.0776063831389663
0    8.463028
dtype: float32
Epoch 11, train loss: 0.13920606424780588 test loss: 0.10443559231337919
0    8.570551
dtype: float32
Epoch 12, train loss: 0.15479910767224253 test loss: 0.06170759055687021
0    8.585972
dtype: float32
Epoch 13, train loss: 0.16425598514026718 test loss: 0.10263964927593387
0    7.496473
dtype: float32
Epoch 14, train loss: 0.11875013420118531 test loss: 0.09733967434716387
0    8.118478
dtype: float32
Epoch 15, train loss: 0.14523815418494393 test loss: 0.05924547179232345
0    7.735116
dtype: float32
Epoch 16, train loss: 0.10961599545566364 test loss: 0.08087868264779666
0    7.968913
dtype: float32
Epoch 17, train loss: 0.11991085405357443 test loss: 0.0630155631117374
0    7.348385
dtype: float32
Epoch 18, train loss: 0.1116934097861642 test loss: 0.11255526941783808
0    6.746125
dtype: float32
Epoch 19, train loss: 0.1776969239208124 test loss: 0.18638648952424863
0    6.636562
dtype: float32
Epoch 20, train loss: 0.17698356408276422 test loss: 0.15282927248119627
0    6.67311
dtype: float32
Epoch 21, train loss: 0.20324289089998668 test loss: 0.20987795512463675
0    6.822803
dtype: float32
Epoch 22, train loss: 0.13653235557512833 test loss: 0.13224023408577365
0    5.790728
dtype: float32
Epoch 23, train loss: 0.2924792889097875 test loss: 0.2121034755036108
0    7.13897
dtype: float32
Epoch 24, train loss: 0.11198737037767678 test loss: 0.11194585883002217
0    7.293487
dtype: float32
Epoch 25, train loss: 0.10354541096220342 test loss: 0.07236434466457625
0    7.369086
dtype: float32
Epoch 26, train loss: 0.10100763078501457 test loss: 0.07112387376937529
0    8.086772
dtype: float32
Epoch 27, train loss: 0.17082415855232386 test loss: 0.07924679120778569
0    7.646689
dtype: float32
Epoch 28, train loss: 0.10618841908174938 test loss: 0.06728075155979547
0    7.361187
dtype: float32
Epoch 29, train loss: 0.09910771163635616 test loss: 0.09028966656376822
0    6.393136
dtype: float32
Epoch 30, train loss: 0.19950783681528833 test loss: 0.1949445804809851
0    6.862876
dtype: float32
Epoch 31, train loss: 0.13078101269841322 test loss: 0.1306533041966636
0    6.549412
dtype: float32
Epoch 32, train loss: 0.1405338147875408 test loss: 0.12104660696798586
0    6.297692
dtype: float32
Epoch 33, train loss: 0.20874444386096805 test loss: 0.21233178676292142
0    6.513741
dtype: float32
Epoch 34, train loss: 0.1371694744558088 test loss: 0.1249956130211622
0    6.941858
dtype: float32
Epoch 35, train loss: 0.10229123869236764 test loss: 0.09183403535980784
0    6.890059
dtype: float32
Epoch 36, train loss: 0.10540235783240683 test loss: 0.08836800124456504
0    5.676113
dtype: float32
Epoch 37, train loss: 0.3281120737536528 test loss: 0.2799480889894538
0    7.228986
dtype: float32
Epoch 38, train loss: 0.09591587565217105 test loss: 0.06913425077014088
0    7.251116
dtype: float32
Epoch 39, train loss: 0.09476430206361901 test loss: 0.0766145719629896
0    7.02753
dtype: float32
Epoch 40, train loss: 0.10382316235168347 test loss: 0.10436563930139942
0    7.091691
dtype: float32
Epoch 41, train loss: 0.09544287676748536 test loss: 0.07618809989250631
0    7.355135
dtype: float32
Epoch 42, train loss: 0.09720343079133713 test loss: 0.0637375677168511
0    6.833561
dtype: float32
Epoch 43, train loss: 0.11917111234640754 test loss: 0.12020560761662177
0    6.498269
dtype: float32
Epoch 44, train loss: 0.13766452036345106 test loss: 0.10832744677634377
0    7.327206
dtype: float32
Epoch 45, train loss: 0.09704591540854494 test loss: 0.059683212710748466
0    6.511773
dtype: float32
Epoch 46, train loss: 0.12816400093514418 test loss: 0.11027136608364302
0    6.434072
dtype: float32
Epoch 47, train loss: 0.17072367562252497 test loss: 0.16700305286962872
0    7.13987
dtype: float32
Epoch 48, train loss: 0.09322036578991091 test loss: 0.0655084464097552
0    6.444722
dtype: float32
Epoch 49, train loss: 0.13656670627412673 test loss: 0.12772400361251401
0    7.056118
dtype: float32
Epoch 50, train loss: 0.09368943382863879 test loss: 0.06934449953867691
0    7.36262
dtype: float32
Epoch 51, train loss: 0.09900685403856885 test loss: 0.05988403337927301
0    7.633032
dtype: float32
Epoch 52, train loss: 0.11096458924380545 test loss: 0.060372643028925956
0    7.350797
dtype: float32
Epoch 53, train loss: 0.09972542536503222 test loss: 0.059448710519827266
0    7.109459
dtype: float32
Epoch 54, train loss: 0.09261811926067205 test loss: 0.06894168733320248
0    6.841272
dtype: float32
Epoch 55, train loss: 0.10517260521444032 test loss: 0.07940672865152697
0    6.143187
dtype: float32
Epoch 56, train loss: 0.17210324842353433 test loss: 0.14109060382798233
0    6.777612
dtype: float32
Epoch 57, train loss: 0.10381426043323082 test loss: 0.09082846397169413
0    7.317943
dtype: float32
Epoch 58, train loss: 0.0962756184493782 test loss: 0.0613093245997071
0    6.992199
dtype: float32
Epoch 59, train loss: 0.09293039670471766 test loss: 0.06849763812823194
0    6.408319
dtype: float32
Epoch 60, train loss: 0.13568318249857889 test loss: 0.11121632324004618
0    6.13333
dtype: float32
Epoch 61, train loss: 0.22036306748520146 test loss: 0.19940175881227595
0    6.663583
dtype: float32
Epoch 62, train loss: 0.11468105681556964 test loss: 0.088564539298405
0    7.316188
dtype: float32
Epoch 63, train loss: 0.09926513144261144 test loss: 0.05999540727588714
0    8.111259
dtype: float32
Epoch 64, train loss: 0.15647484913924725 test loss: 0.08548747601633343
0    7.308107
dtype: float32
Epoch 65, train loss: 0.09744212879704561 test loss: 0.05862758529574041
0    6.624995
dtype: float32
Epoch 66, train loss: 0.12532241299422514 test loss: 0.11665725407119959
0    6.244744
dtype: float32
Epoch 67, train loss: 0.19331806396607334 test loss: 0.15766876179014894
0    7.193785
dtype: float32
Epoch 68, train loss: 0.09079396373519641 test loss: 0.07675903368384993
0    7.498771
dtype: float32
Epoch 69, train loss: 0.10194182505432824 test loss: 0.06226027340195621
0    7.637141
dtype: float32
Epoch 70, train loss: 0.13985870110915496 test loss: 0.0885548722504323
0    6.983483
dtype: float32
Epoch 71, train loss: 0.09148814196214242 test loss: 0.07443178410882684
0    7.106032
dtype: float32
Epoch 72, train loss: 0.08890111572299929 test loss: 0.06093091684630491
0    7.34941
dtype: float32
Epoch 73, train loss: 0.09643465228494957 test loss: 0.059627667941178054
0    7.68677
dtype: float32
Epoch 74, train loss: 0.12969104420929625 test loss: 0.07646159930383654
0    7.533282
dtype: float32
Epoch 75, train loss: 0.0994082693242867 test loss: 0.059547313236187116
0    7.473279
dtype: float32
Epoch 76, train loss: 0.09795650221496041 test loss: 0.06065413296133362
0    6.617308
dtype: float32
Epoch 77, train loss: 0.1299374114270663 test loss: 0.11310109734814794
0    6.361125
dtype: float32
Epoch 78, train loss: 0.17969421094849664 test loss: 0.15385550565134343
0    7.193964
dtype: float32
Epoch 79, train loss: 0.08973644841162695 test loss: 0.06198918501903185
0    7.172148
dtype: float32
Epoch 80, train loss: 0.0879193068434836 test loss: 0.06092826783623154
0    6.679929
dtype: float32
Epoch 81, train loss: 0.10817651582743727 test loss: 0.08820099934276873
0    7.281285
dtype: float32
Epoch 82, train loss: 0.09179573699143254 test loss: 0.05988245130037038
0    6.338886
dtype: float32
Epoch 83, train loss: 0.14392475269293206 test loss: 0.11526683721053742
0    7.026366
dtype: float32
Epoch 84, train loss: 0.08762490600127222 test loss: 0.0624286419930964
0    6.730324
dtype: float32
Epoch 85, train loss: 0.10682496904916379 test loss: 0.08119529086861378
0    6.405777
dtype: float32
Epoch 86, train loss: 0.1697424705969797 test loss: 0.14565814306103506
0    6.634421
dtype: float32
Epoch 87, train loss: 0.11870931208337071 test loss: 0.1003820255868925
0    7.058203
dtype: float32
Epoch 88, train loss: 0.08673631934165335 test loss: 0.06159784316037151
0    6.83672
dtype: float32
Epoch 89, train loss: 0.09789967604883426 test loss: 0.08580995065114395
0    6.969537
dtype: float32
Epoch 90, train loss: 0.08682501961737056 test loss: 0.06340640248638045
0    7.569088
dtype: float32
Epoch 91, train loss: 0.10944105175952971 test loss: 0.06465663387864577
0    7.255414
dtype: float32
Epoch 92, train loss: 0.08698213101142663 test loss: 0.06061762770620119
0    7.346335
dtype: float32
Epoch 93, train loss: 0.09624726255725997 test loss: 0.0631573192879746
0    7.53049
dtype: float32
Epoch 94, train loss: 0.10023623157626331 test loss: 0.0609512915815396
0    6.826413
dtype: float32
Epoch 95, train loss: 0.09613116429255827 test loss: 0.08255815436683861
0    7.08346
dtype: float32
Epoch 96, train loss: 0.08383422278520176 test loss: 0.06272106226674033
0    6.842182
dtype: float32
Epoch 97, train loss: 0.09269598012503515 test loss: 0.0676503124624714
0    7.128768
dtype: float32
Epoch 98, train loss: 0.08358807861183586 test loss: 0.06149709547118925
0    7.756647
dtype: float32
Epoch 99, train loss: 0.12993572140195822 test loss: 0.08188100646421763
0    6.991072
dtype: float32
Epoch 100, train loss: 0.08645812764099978 test loss: 0.07136205829130188
0    6.367059
dtype: float32
Epoch 101, train loss: 0.14705303546864568 test loss: 0.12184499147220154
0    7.26506
dtype: float32
Epoch 102, train loss: 0.09081799126914795 test loss: 0.0634817268031434
0    6.757816
dtype: float32
Epoch 103, train loss: 0.10025922279577087 test loss: 0.08758437312192817
0    6.312541
dtype: float32
Epoch 104, train loss: 0.15324083775541927 test loss: 0.13198843481271375
0    6.811448
dtype: float32
Epoch 105, train loss: 0.08709682782084611 test loss: 0.07186984648222117
0    6.596582
dtype: float32
Epoch 106, train loss: 0.1029234173837542 test loss: 0.08042088850784583
0    6.409312
dtype: float32
Epoch 107, train loss: 0.1257701189216904 test loss: 0.0880034854235183
0    6.519729
dtype: float32
Epoch 108, train loss: 0.12114245434291046 test loss: 0.09612190901528099
0    6.867153
dtype: float32
Epoch 109, train loss: 0.08652733069688191 test loss: 0.0641370307937052
0    6.788638
dtype: float32
Epoch 110, train loss: 0.08844068297663142 test loss: 0.0699486784020151
0    6.906189
dtype: float32
Epoch 111, train loss: 0.08289322162540418 test loss: 0.06362328749462215
0    7.329613
dtype: float32
Epoch 112, train loss: 0.0971882126853533 test loss: 0.06290671375664343
0    7.265634
dtype: float32
Epoch 113, train loss: 0.09633015586238619 test loss: 0.07148682242047356
0    7.035813
dtype: float32
Epoch 114, train loss: 0.08220768361402139 test loss: 0.06114022617470918
0    6.93775
dtype: float32
Epoch 115, train loss: 0.08446630553258919 test loss: 0.06262031819639952
0    6.909313
dtype: float32
Epoch 116, train loss: 0.08617382864456029 test loss: 0.06465682067720165
0    7.54184
dtype: float32
Epoch 117, train loss: 0.11730062813242569 test loss: 0.07583277870727016
0    6.672465
dtype: float32
Epoch 118, train loss: 0.0894505256024408 test loss: 0.06842262496956285
0    7.200574
dtype: float32
Epoch 119, train loss: 0.08826225015895225 test loss: 0.05973833823967286
0    7.123624
dtype: float32
Epoch 120, train loss: 0.08542212402316854 test loss: 0.06023464036422546
0    7.065512
dtype: float32
Epoch 121, train loss: 0.08762866505836368 test loss: 0.06363969481732625
0    7.490603
dtype: float32
Epoch 122, train loss: 0.11160138830966812 test loss: 0.07259033097028948
0    7.339005
dtype: float32
Epoch 123, train loss: 0.08662303926223705 test loss: 0.05949437565142224
0    6.716324
dtype: float32
Epoch 124, train loss: 0.09174735686963058 test loss: 0.07498121779316594
0    6.581612
dtype: float32
Epoch 125, train loss: 0.0883991898146839 test loss: 0.06558900003453845
0    6.401445
dtype: float32
Epoch 126, train loss: 0.11941536665264502 test loss: 0.1015339243607811
0    7.06947
dtype: float32
Epoch 127, train loss: 0.09034654308109293 test loss: 0.06895634472058572
0    7.096993
dtype: float32
Epoch 128, train loss: 0.08247883998365134 test loss: 0.062130849258098045
0    7.033076
dtype: float32
Epoch 129, train loss: 0.08029927773176761 test loss: 0.061620163630122946
0    6.71497
dtype: float32
Epoch 130, train loss: 0.08702056513510346 test loss: 0.07668512687697822
0    6.504046
dtype: float32
Epoch 131, train loss: 0.10595515413955456 test loss: 0.09159008284246864
0    7.084448
dtype: float32
Epoch 132, train loss: 0.08385344703800328 test loss: 0.06471973381350449
0    7.653608
dtype: float32
Epoch 133, train loss: 0.13188009433512352 test loss: 0.0931339872410258
0    6.806833
dtype: float32
Epoch 134, train loss: 0.08061942222472752 test loss: 0.06244898521036396
0    7.007521
dtype: float32
Epoch 135, train loss: 0.08078351568792055 test loss: 0.06171341885104227
0    6.975134
dtype: float32
Epoch 136, train loss: 0.0803371798226265 test loss: 0.06100224493024845
0    6.74176
dtype: float32
Epoch 137, train loss: 0.0839723837613565 test loss: 0.06895038249955547
0    7.101827
dtype: float32
Epoch 138, train loss: 0.08712925633426184 test loss: 0.06530171935793488
0    7.063401
dtype: float32
Epoch 139, train loss: 0.08379647235400567 test loss: 0.05890069705576914
0    6.972011
dtype: float32
Epoch 140, train loss: 0.08040046894249375 test loss: 0.06298582087006781
0    6.543749
dtype: float32
Epoch 141, train loss: 0.09668863631289917 test loss: 0.07795451384827133
0    6.645429
dtype: float32
Epoch 142, train loss: 0.08471232349927248 test loss: 0.06871056771957176
0    7.147876
dtype: float32
Epoch 143, train loss: 0.09674244800126677 test loss: 0.07318040242812879
0    7.058069
dtype: float32
Epoch 144, train loss: 0.08582066894585898 test loss: 0.06395991709868439
0    6.70165
dtype: float32
Epoch 145, train loss: 0.08760410655076681 test loss: 0.0715150097693234
0    6.856668
dtype: float32
Epoch 146, train loss: 0.07674648987636833 test loss: 0.06178178459191905
0    7.004789
dtype: float32
Epoch 147, train loss: 0.08124221270227863 test loss: 0.06300484895808312
0    6.849278
dtype: float32
Epoch 148, train loss: 0.07595327622011748 test loss: 0.06156758164374596
0    7.08787
dtype: float32
Epoch 149, train loss: 0.10096159246078115 test loss: 0.08463839341667583
0    6.590609
dtype: float32
Epoch 150, train loss: 0.09333905954769153 test loss: 0.08084713445293056
0    6.858436
dtype: float32
Epoch 151, train loss: 0.07745515869998641 test loss: 0.06096576030227586
0    6.945242
dtype: float32
Epoch 152, train loss: 0.07671010573367329 test loss: 0.060003472277906804
0    6.770498
dtype: float32
Epoch 153, train loss: 0.08207199499751222 test loss: 0.0641689405453405
0    6.35377
dtype: float32
Epoch 154, train loss: 0.13299462553546765 test loss: 0.10569642832402447
0    7.105565
dtype: float32
Epoch 155, train loss: 0.08754761268080402 test loss: 0.07037362904785513
0    7.271492
dtype: float32
Epoch 156, train loss: 0.09996862358451418 test loss: 0.0777757003613505
0    6.892412
dtype: float32
Epoch 157, train loss: 0.07450292398151108 test loss: 0.05964822224723552
0    7.028278
dtype: float32
Epoch 158, train loss: 0.07648863625149321 test loss: 0.05945430119944053
0    6.947844
dtype: float32
Epoch 159, train loss: 0.07409198957500755 test loss: 0.0586160878216162
0    7.271808
dtype: float32
Epoch 160, train loss: 0.0979024606233779 test loss: 0.06819614281978541
0    7.053566
dtype: float32
Epoch 161, train loss: 0.0800943967767758 test loss: 0.061508209970039925
0    7.357572
dtype: float32
Epoch 162, train loss: 0.11316056651086082 test loss: 0.08733111122806944
0    6.653121
dtype: float32
Epoch 163, train loss: 0.07928459105961827 test loss: 0.06522885265233185
0    6.502519
dtype: float32
Epoch 164, train loss: 0.10072746631566713 test loss: 0.08520808978993565
0    6.817327
dtype: float32
Epoch 165, train loss: 0.07416610752904831 test loss: 0.05875994219066524
0    7.014464
dtype: float32
Epoch 166, train loss: 0.08398812891439253 test loss: 0.06700445896602839
0    7.424438
dtype: float32
Epoch 167, train loss: 0.13738394315693422 test loss: 0.11153360074907145
0    7.375666
dtype: float32
Epoch 168, train loss: 0.10980158058157446 test loss: 0.07880302941468578
0    6.877335
dtype: float32
Epoch 169, train loss: 0.07373687195122554 test loss: 0.05964072199568562
0    6.634327
dtype: float32
Epoch 170, train loss: 0.08612317555938294 test loss: 0.07285232382067451
0    6.758794
dtype: float32
Epoch 171, train loss: 0.0744711938923734 test loss: 0.0622198300187602
0    6.618447
dtype: float32
Epoch 172, train loss: 0.08981372322758739 test loss: 0.07695756920291026
0    7.159015
dtype: float32
Epoch 173, train loss: 0.09717954230222328 test loss: 0.08194389950883664
0    6.96128
dtype: float32
Epoch 174, train loss: 0.07435034500569679 test loss: 0.05680867377949444
0    6.808179
dtype: float32
Epoch 175, train loss: 0.07336509270497389 test loss: 0.06056142479987058
0    6.926322
dtype: float32
Epoch 176, train loss: 0.0721301288564455 test loss: 0.059946219974252216
0    7.587325
dtype: float32
Epoch 177, train loss: 0.1437165743027865 test loss: 0.11331042902227215
0    7.58478
dtype: float32
Epoch 178, train loss: 0.12234907008057622 test loss: 0.08239558869553007
0    6.726053
dtype: float32
Epoch 179, train loss: 0.07806821666886865 test loss: 0.06576047885824232
0    6.64669
dtype: float32
Epoch 180, train loss: 0.08519163846935539 test loss: 0.07290264893598636
0    6.809376
dtype: float32
Epoch 181, train loss: 0.07242410573077883 test loss: 0.05940933661243309
0    6.717106
dtype: float32
Epoch 182, train loss: 0.07571402852619079 test loss: 0.06341311353222245
0    6.567717
dtype: float32
Epoch 183, train loss: 0.08770772541819623 test loss: 0.0694116652519098
0    6.49381
dtype: float32
Epoch 184, train loss: 0.10231081845418474 test loss: 0.08217436274189681
0    6.927738
dtype: float32
Epoch 185, train loss: 0.07316218561099808 test loss: 0.061174519656009535
0    6.680809
dtype: float32
Epoch 186, train loss: 0.07914397036746262 test loss: 0.06624429043635531
0    6.830221
dtype: float32
Epoch 187, train loss: 0.0709374102621309 test loss: 0.0616131427321145
0    7.10594
dtype: float32
Epoch 188, train loss: 0.07752337448132204 test loss: 0.06354952306399841
0    7.378579
dtype: float32
Epoch 189, train loss: 0.0949596367097985 test loss: 0.07236601366939631
0    6.892013
dtype: float32
Epoch 190, train loss: 0.06868279608427617 test loss: 0.05943795509592722
0    7.113966
dtype: float32
Epoch 191, train loss: 0.08268715730450338 test loss: 0.06932352349386552
0    6.71116
dtype: float32
Epoch 192, train loss: 0.07470433952382265 test loss: 0.0662902929783796
0    6.448451
dtype: float32
Epoch 193, train loss: 0.10973479099901381 test loss: 0.09167883311606612
0    6.203699
dtype: float32
Epoch 194, train loss: 0.1544799288117957 test loss: 0.12482229450597623
0    6.37841
dtype: float32
Epoch 195, train loss: 0.10417451996228151 test loss: 0.08488963343352274
0    6.850378
dtype: float32
Epoch 196, train loss: 0.0699658935857663 test loss: 0.05827217062548508
0    6.439917
dtype: float32
Epoch 197, train loss: 0.11161422248126995 test loss: 0.09902811909564972
0    7.196738
dtype: float32
Epoch 198, train loss: 0.08756279018994167 test loss: 0.06863642944572236
0    6.609555
dtype: float32
Epoch 199, train loss: 0.08084866714478993 test loss: 0.0665343899539126
0    6.88298
dtype: float32
Epoch 200, train loss: 0.06859374290203757 test loss: 0.057574131009920856
0    6.947313
dtype: float32
Epoch 201, train loss: 0.06898083878481795 test loss: 0.0570435910118776
0    7.087083
dtype: float32
Epoch 202, train loss: 0.07673018681130371 test loss: 0.06067769501455835
0    6.811845
dtype: float32
Epoch 203, train loss: 0.07038869911641932 test loss: 0.061818741649379096
0    6.511907
dtype: float32
Epoch 204, train loss: 0.10848635151297327 test loss: 0.09673058864786573
0    7.059725
dtype: float32
Epoch 205, train loss: 0.0698308902904602 test loss: 0.05563313901202333
0    6.663656
dtype: float32
Epoch 206, train loss: 0.08030596970401047 test loss: 0.07011811451955549
0    6.943195
dtype: float32
Epoch 207, train loss: 0.06879484593945594 test loss: 0.05711867240366955
0    6.954719
dtype: float32
Epoch 208, train loss: 0.072665410740724 test loss: 0.0649818889004158
0    6.889344
dtype: float32
Epoch 209, train loss: 0.06664309001098288 test loss: 0.05912768776432966
0    6.557106
dtype: float32
Epoch 210, train loss: 0.08304063272169575 test loss: 0.07291549261003623
0    6.755696
dtype: float32
Epoch 211, train loss: 0.08629233010430042 test loss: 0.07813345210884234
0    6.837035
dtype: float32
Epoch 212, train loss: 0.06840868555302486 test loss: 0.05744167140972606
0    6.889922
dtype: float32
Epoch 213, train loss: 0.06903891885568618 test loss: 0.057228030526333344
0    6.854929
dtype: float32
Epoch 214, train loss: 0.06735494518962927 test loss: 0.05858561141394782
0    6.791148
dtype: float32
Epoch 215, train loss: 0.07088629181753867 test loss: 0.06444348471549616
0    7.027137
dtype: float32
Epoch 216, train loss: 0.06923705473651633 test loss: 0.05704420694750228
0    6.460436
dtype: float32
Epoch 217, train loss: 0.10321452074510198 test loss: 0.08643428546264617
0    6.905891
dtype: float32
Epoch 218, train loss: 0.06742196651358773 test loss: 0.05973534750445137
0    6.930492
dtype: float32
Epoch 219, train loss: 0.06538609253256596 test loss: 0.05697057476370746
0    6.857533
dtype: float32
Epoch 220, train loss: 0.06540777014634153 test loss: 0.05761040027398674
0    7.144385
dtype: float32
Epoch 221, train loss: 0.08228021000204427 test loss: 0.0610888666842422
0    7.039945
dtype: float32
Epoch 222, train loss: 0.07550319966542982 test loss: 0.05984545173862248
0    7.372894
dtype: float32
Epoch 223, train loss: 0.10473136492292708 test loss: 0.07749887229215544
0    7.172158
dtype: float32
Epoch 224, train loss: 0.08043350672077092 test loss: 0.05925812035372677
0    7.044928
dtype: float32
Epoch 225, train loss: 0.071685194282384 test loss: 0.05904481170943091
0    6.768662
dtype: float32
Epoch 226, train loss: 0.06798659250265007 test loss: 0.0601229974046089
0    6.712126
dtype: float32
Epoch 227, train loss: 0.07305563636071125 test loss: 0.06542962517027422
0    7.028279
dtype: float32
Epoch 228, train loss: 0.07134425001177837 test loss: 0.06232167452798116
0    7.090615
dtype: float32
Epoch 229, train loss: 0.08337512683219116 test loss: 0.06426697639585915
0    7.453984
dtype: float32
Epoch 230, train loss: 0.10947221150257092 test loss: 0.0695422542262861
0    7.215626
dtype: float32
Epoch 231, train loss: 0.0856232844388594 test loss: 0.07622828486227522
0    6.917819
dtype: float32
Epoch 232, train loss: 0.06684440642919896 test loss: 0.057651587773720536
0    7.130983
dtype: float32
Epoch 233, train loss: 0.07329503986697924 test loss: 0.05861436180176189
0    7.089707
dtype: float32
Epoch 234, train loss: 0.06985232026755188 test loss: 0.05475529648717616
0    6.690578
dtype: float32
Epoch 235, train loss: 0.07691405372265753 test loss: 0.06576918678204097
0    7.021419
dtype: float32
Epoch 236, train loss: 0.07277061300225052 test loss: 0.06375876518987611
0    6.426485
dtype: float32
Epoch 237, train loss: 0.09917861183509802 test loss: 0.0808311733296017
0    6.901897
dtype: float32
Epoch 238, train loss: 0.06403785055056677 test loss: 0.05609808703295279
0    6.847829
dtype: float32
Epoch 239, train loss: 0.06456274660852185 test loss: 0.05720039593100103
0    7.285326
dtype: float32
Epoch 240, train loss: 0.08923544537030322 test loss: 0.050393845366938014
0    6.737653
dtype: float32
Epoch 241, train loss: 0.07106533243758745 test loss: 0.059610787860603934
0    7.025723
dtype: float32
Epoch 242, train loss: 0.0664735978108041 test loss: 0.054763431466477976
0    7.490277
dtype: float32
Epoch 243, train loss: 0.1221123848138987 test loss: 0.09766082431720928
0    7.283249
dtype: float32
Epoch 244, train loss: 0.08070333960388916 test loss: 0.05335285171291895
0    6.696183
dtype: float32
Epoch 245, train loss: 0.07222143479847623 test loss: 0.06224214668542487
0    6.96347
dtype: float32
Epoch 246, train loss: 0.06381895564044252 test loss: 0.05617082723717257
0    7.187666
dtype: float32
Epoch 247, train loss: 0.07351365706012065 test loss: 0.05791945785234896
0    6.786511
dtype: float32
Epoch 248, train loss: 0.06466683665625973 test loss: 0.05949220580822389
0    7.137091
dtype: float32
Epoch 249, train loss: 0.07395816611612059 test loss: 0.05932761544397858
0    7.080383
dtype: float32
Epoch 250, train loss: 0.06707221170427144 test loss: 0.05967397942960915
0    7.148055
dtype: float32
Epoch 251, train loss: 0.07288368693473679 test loss: 0.05990026037177865
0    7.172486
dtype: float32
Epoch 252, train loss: 0.07682282047679731 test loss: 0.05607185653485569
0    6.595567
dtype: float32
Epoch 253, train loss: 0.08093713764558395 test loss: 0.0674121411683537
0    6.403162
dtype: float32
Epoch 254, train loss: 0.11160453655670259 test loss: 0.09000914340393036
0    6.826611
dtype: float32
Epoch 255, train loss: 0.06387197052025223 test loss: 0.05926080961185045
0    6.985554
dtype: float32
Epoch 256, train loss: 0.06438022366217988 test loss: 0.05410519978543761
0    6.981647
dtype: float32
Epoch 257, train loss: 0.06398895900316975 test loss: 0.055122603583224336
0    6.832853
dtype: float32
Epoch 258, train loss: 0.06449434462056582 test loss: 0.056967725076989724
0    6.823843
dtype: float32
Epoch 259, train loss: 0.06555326886834377 test loss: 0.058257469104238804
0    6.958846
dtype: float32
Epoch 260, train loss: 0.06156049869351014 test loss: 0.056846968349141096
0    6.906598
dtype: float32
Epoch 261, train loss: 0.06366511584019202 test loss: 0.05795601440663098
0    6.514222
dtype: float32
Epoch 262, train loss: 0.09613563170097188 test loss: 0.08642720412150166
0    7.060403
dtype: float32
Epoch 263, train loss: 0.07309777944530442 test loss: 0.06704455686671584
0    7.174001
dtype: float32
Epoch 264, train loss: 0.07868412513204519 test loss: 0.0605537449512681
0    6.639965
dtype: float32
Epoch 265, train loss: 0.0817832199094802 test loss: 0.07611989089163769
0    6.625588
dtype: float32
Epoch 266, train loss: 0.07796475892222271 test loss: 0.06971578310833662
0    6.731464
dtype: float32
Epoch 267, train loss: 0.07438287314543558 test loss: 0.06848873203805322
0    6.958345
dtype: float32
Epoch 268, train loss: 0.061886116623231555 test loss: 0.05716407506764845
0    7.450716
dtype: float32
Epoch 269, train loss: 0.10832303328976683 test loss: 0.08268012307320663
0    7.389337
dtype: float32
Epoch 270, train loss: 0.0824213832460893 test loss: 0.0564195225616141
0    6.995051
dtype: float32
Epoch 271, train loss: 0.061422723542898225 test loss: 0.05669194992504129
0    7.275783
dtype: float32
Epoch 272, train loss: 0.08573536806299017 test loss: 0.06980532607153665
0    7.338091
dtype: float32
Epoch 273, train loss: 0.07903298620889992 test loss: 0.05946449973539377
0    7.038782
dtype: float32
Epoch 274, train loss: 0.062319968080081396 test loss: 0.05408916269680869
0    6.821052
dtype: float32
Epoch 275, train loss: 0.06841544469060054 test loss: 0.05921530341793179
0    7.138836
dtype: float32
Epoch 276, train loss: 0.06995423489853826 test loss: 0.05579009296297031
0    7.013662
dtype: float32
Epoch 277, train loss: 0.06204518420225728 test loss: 0.05834588074841469
0    6.964741
dtype: float32
Epoch 278, train loss: 0.06253655017436595 test loss: 0.058470750169875955
0    6.884005
dtype: float32
Epoch 279, train loss: 0.06325449288006398 test loss: 0.06053243312649103
0    7.395808
dtype: float32
Epoch 280, train loss: 0.08748586511812645 test loss: 0.06611537234601064
0    7.386833
dtype: float32
Epoch 281, train loss: 0.08719424267904798 test loss: 0.06058740473681949
0    7.043421
dtype: float32
Epoch 282, train loss: 0.06183671345759596 test loss: 0.055020233635034055
0    7.026365
dtype: float32
Epoch 283, train loss: 0.0629128872195061 test loss: 0.05708321182368962
0    6.988104
dtype: float32
Epoch 284, train loss: 0.06148929524982652 test loss: 0.05759283362697584
0    7.018067
dtype: float32
Epoch 285, train loss: 0.06093018316699992 test loss: 0.05743355528099572
0    6.697233
dtype: float32
Epoch 286, train loss: 0.07303676132589651 test loss: 0.06534167631114299
0    6.349026
dtype: float32
Epoch 287, train loss: 0.12250972004483666 test loss: 0.10360129333538404
0    6.536558
dtype: float32
Epoch 288, train loss: 0.08614384095377145 test loss: 0.0748922041831513
0    7.016323
dtype: float32
Epoch 289, train loss: 0.0628240067259926 test loss: 0.055410150860182035
0    6.432423
dtype: float32
Epoch 290, train loss: 0.11806891129265627 test loss: 0.09396304301234824
0    6.928805
dtype: float32
Epoch 291, train loss: 0.061440065727696745 test loss: 0.05728440702642762
0    7.162583
dtype: float32
Epoch 292, train loss: 0.06747184127034925 test loss: 0.056336947495841956
0    7.167631
dtype: float32
Epoch 293, train loss: 0.0670008678469972 test loss: 0.05925052306952236
0    6.789479
dtype: float32
Epoch 294, train loss: 0.06885811276714222 test loss: 0.07091282447880075
0    7.131913
dtype: float32
Epoch 295, train loss: 0.07306945348764474 test loss: 0.06597596351931967
0    7.114852
dtype: float32
Epoch 296, train loss: 0.06443915451475209 test loss: 0.055842533879291174
0    6.76378
dtype: float32
Epoch 297, train loss: 0.06794370777240791 test loss: 0.06879302873136257
0    7.15835
dtype: float32
Epoch 298, train loss: 0.07158832293686493 test loss: 0.06372932057343414
0    6.639419
dtype: float32
Epoch 299, train loss: 0.08013675291721592 test loss: 0.07101632265480781
Final train loss is: 0.08013675291721592, Test loss is: 0.07101632265480781
0    6.639419
dtype: float32
round is 3
0    8.207143
dtype: float32
Epoch 5, train loss: 0.26727851686457765 test loss: 0.34508866288904466
0    6.508416
dtype: float32
Epoch 6, train loss: 0.2012822008013925 test loss: 0.32218694526476216
0    6.015945
dtype: float32
Epoch 8, train loss: 0.25550749795111455 test loss: 0.3972860573379199
0    6.438818
dtype: float32
Epoch 9, train loss: 0.16889857988286233 test loss: 0.263499349623982
0    6.231236
dtype: float32
Epoch 10, train loss: 0.17016679175554994 test loss: 0.2506073350710406
0    6.69517
dtype: float32
Epoch 11, train loss: 0.13966462424448056 test loss: 0.17620272963310332
0    6.497405
dtype: float32
Epoch 12, train loss: 0.17261422816260832 test loss: 0.17641850122059463
0    6.124237
dtype: float32
Epoch 13, train loss: 0.2077346323765688 test loss: 0.13268335635981607
0    6.347194
dtype: float32
Epoch 14, train loss: 0.16003792031059194 test loss: 0.10249974465001709
0    6.499559
dtype: float32
Epoch 15, train loss: 0.1265004998251379 test loss: 0.10212460232410095
0    6.339197
dtype: float32
Epoch 16, train loss: 0.11618090464630737 test loss: 0.10519036329567766
0    7.159098
dtype: float32
Epoch 17, train loss: 0.08180892761193174 test loss: 0.11472712412312637
0    7.055333
dtype: float32
Epoch 18, train loss: 0.07804374484759156 test loss: 0.10115076227326397
0    7.174032
dtype: float32
Epoch 19, train loss: 0.07812255855560184 test loss: 0.10591838686164587
0    6.723951
dtype: float32
Epoch 20, train loss: 0.09471569940763977 test loss: 0.09217650376005189
0    6.551892
dtype: float32
Epoch 21, train loss: 0.09883193787785663 test loss: 0.09964756661597492
0    6.298379
dtype: float32
Epoch 22, train loss: 0.13379622332900173 test loss: 0.13563873728466597
0    7.258266
dtype: float32
Epoch 23, train loss: 0.08631812680719461 test loss: 0.12058192116103517
0    7.655177
dtype: float32
Epoch 24, train loss: 0.12477868213500548 test loss: 0.1698072837485254
0    7.477913
dtype: float32
Epoch 25, train loss: 0.10067153430800894 test loss: 0.14462951098243496
0    7.447121
dtype: float32
Epoch 26, train loss: 0.10486198920728111 test loss: 0.15081568507575122
0    7.000623
dtype: float32
Epoch 27, train loss: 0.07462898642065488 test loss: 0.09725668024843864
0    7.641268
dtype: float32
Epoch 28, train loss: 0.12109486396419657 test loss: 0.15711017152681733
0    6.595125
dtype: float32
Epoch 29, train loss: 0.08882214986323748 test loss: 0.0893785913593169
0    7.297549
dtype: float32
Epoch 30, train loss: 0.08475231997935115 test loss: 0.11761117475022595
0    7.756062
dtype: float32
Epoch 31, train loss: 0.1350908372384052 test loss: 0.17464622935969445
0    7.548136
dtype: float32
Epoch 32, train loss: 0.10408440470451188 test loss: 0.14659113262993267
0    6.914749
dtype: float32
Epoch 33, train loss: 0.07316308605447118 test loss: 0.08995643026782639
0    6.250601
dtype: float32
Epoch 34, train loss: 0.14946093485097725 test loss: 0.15937995863563267
0    5.915503
dtype: float32
Epoch 35, train loss: 0.22393862366375855 test loss: 0.2484567492697868
0    6.266644
dtype: float32
Epoch 36, train loss: 0.15218665791963648 test loss: 0.1549949676914359
0    6.892244
dtype: float32
Epoch 37, train loss: 0.07756483329189379 test loss: 0.09124037311600804
0    7.218262
dtype: float32
Epoch 38, train loss: 0.0732064914384626 test loss: 0.0986674714531551
0    7.141586
dtype: float32
Epoch 39, train loss: 0.07268404124182191 test loss: 0.09625956927776912
0    6.834974
dtype: float32
Epoch 40, train loss: 0.08154731207532431 test loss: 0.0924593304562781
0    7.09148
dtype: float32
Epoch 41, train loss: 0.07240553832613698 test loss: 0.0938413275543371
0    6.428109
dtype: float32
Epoch 42, train loss: 0.12324252146453625 test loss: 0.1342759793590969
0    6.892675
dtype: float32
Epoch 43, train loss: 0.07241279083753342 test loss: 0.08778740426563489
0    7.697566
dtype: float32
Epoch 44, train loss: 0.12127536696682382 test loss: 0.1585759084376604
0    7.655982
dtype: float32
Epoch 45, train loss: 0.1189633753404205 test loss: 0.1529919957342977
0    7.681562
dtype: float32
Epoch 46, train loss: 0.10735950174083042 test loss: 0.14628743099814437
0    7.813025
dtype: float32
Epoch 47, train loss: 0.1128983577816366 test loss: 0.1501723587535299
0    7.774794
dtype: float32
Epoch 48, train loss: 0.12466184653349291 test loss: 0.163294689170081
0    6.980818
dtype: float32
Epoch 49, train loss: 0.07127936750412023 test loss: 0.09142960813233054
0    7.328001
dtype: float32
Epoch 50, train loss: 0.07876848336943246 test loss: 0.1107975341934917
0    6.925958
dtype: float32
Epoch 51, train loss: 0.07513926275558842 test loss: 0.09013252202851128
0    7.429701
dtype: float32
Epoch 52, train loss: 0.09043796020563884 test loss: 0.12237650229858425
0    7.051047
dtype: float32
Epoch 53, train loss: 0.07064641445739368 test loss: 0.09347956954761072
0    7.390295
dtype: float32
Epoch 54, train loss: 0.08556484481979301 test loss: 0.11400625634043285
0    7.93004
dtype: float32
Epoch 55, train loss: 0.13007447653788146 test loss: 0.16999865929987246
0    8.067588
dtype: float32
Epoch 56, train loss: 0.1439117263875902 test loss: 0.1884652372837385
0    7.896446
dtype: float32
Epoch 57, train loss: 0.14342134471994347 test loss: 0.16186494947618713
0    8.035255
dtype: float32
Epoch 58, train loss: 0.15197765104410244 test loss: 0.1924862330136206
0    8.09799
dtype: float32
Epoch 59, train loss: 0.15153647420291844 test loss: 0.18937440210472983
0    7.641368
dtype: float32
Epoch 60, train loss: 0.09346837693073694 test loss: 0.1366701702342977
0    7.165036
dtype: float32
Epoch 61, train loss: 0.07234809044629688 test loss: 0.10673444631464364
0    6.01741
dtype: float32
Epoch 62, train loss: 0.1956253918479791 test loss: 0.23560629274460562
0    6.023617
dtype: float32
Epoch 63, train loss: 0.18375192900019696 test loss: 0.19820735784665336
0    6.619742
dtype: float32
Epoch 64, train loss: 0.09498749848846243 test loss: 0.10850901419466967
0    6.133082
dtype: float32
Epoch 65, train loss: 0.15225080159135945 test loss: 0.17009113833131193
0    6.81664
dtype: float32
Epoch 66, train loss: 0.07424241214494831 test loss: 0.08947718933786532
0    7.120016
dtype: float32
Epoch 67, train loss: 0.0713225997444649 test loss: 0.09377525390998274
0    6.442283
dtype: float32
Epoch 68, train loss: 0.11948360809859102 test loss: 0.13523704312064497
0    6.131386
dtype: float32
Epoch 69, train loss: 0.16193827015276102 test loss: 0.17092025824039525
0    6.642521
dtype: float32
Epoch 70, train loss: 0.09045437641320156 test loss: 0.09692083741284398
0    6.560901
dtype: float32
Epoch 71, train loss: 0.09703311031552056 test loss: 0.10362238450146576
0    7.248095
dtype: float32
Epoch 72, train loss: 0.0792642468398116 test loss: 0.11048074950611463
0    6.344502
dtype: float32
Epoch 73, train loss: 0.11638674557460874 test loss: 0.1320786886608803
0    7.272297
dtype: float32
Epoch 74, train loss: 0.07867287717856881 test loss: 0.10498470003712701
0    7.261559
dtype: float32
Epoch 75, train loss: 0.07765451610519661 test loss: 0.1066769586740587
0    6.288743
dtype: float32
Epoch 76, train loss: 0.12870372090560286 test loss: 0.1518642193837044
0    6.263513
dtype: float32
Epoch 77, train loss: 0.1306635852043024 test loss: 0.14922474407351663
0    6.756765
dtype: float32
Epoch 78, train loss: 0.08139119177868588 test loss: 0.09895478098684722
0    6.687809
dtype: float32
Epoch 79, train loss: 0.08448282754472732 test loss: 0.10013845295471645
0    7.154368
dtype: float32
Epoch 80, train loss: 0.0719639871055497 test loss: 0.09428497064985565
0    6.618925
dtype: float32
Epoch 81, train loss: 0.09815536642983275 test loss: 0.11733380737999852
0    6.768503
dtype: float32
Epoch 82, train loss: 0.08582911615370421 test loss: 0.10034176873739041
0    5.787089
dtype: float32
Epoch 83, train loss: 0.19537091154717454 test loss: 0.22923138570058693
0    6.535453
dtype: float32
Epoch 84, train loss: 0.09376332706959246 test loss: 0.12243763094978281
0    6.906798
dtype: float32
Epoch 85, train loss: 0.06870670963389247 test loss: 0.09161256611269496
0    6.342112
dtype: float32
Epoch 86, train loss: 0.11784774834526411 test loss: 0.14845721253933616
0    6.073864
dtype: float32
Epoch 87, train loss: 0.16164899534560706 test loss: 0.197482674974191
0    5.685204
dtype: float32
Epoch 88, train loss: 0.23293515891639424 test loss: 0.2721639013228708
0    7.203852
dtype: float32
Epoch 89, train loss: 0.06971611834431464 test loss: 0.1007420407943014
0    7.165495
dtype: float32
Epoch 90, train loss: 0.06898760098019141 test loss: 0.0977857161189487
0    6.534401
dtype: float32
Epoch 91, train loss: 0.10598447945167988 test loss: 0.13725141660105347
0    5.74333
dtype: float32
Epoch 92, train loss: 0.21131479529478034 test loss: 0.25638820853275424
0    6.70452
dtype: float32
Epoch 93, train loss: 0.09831099575790028 test loss: 0.1146230662205264
0    6.991575
dtype: float32
Epoch 94, train loss: 0.06858263542883998 test loss: 0.09390659972614389
0    6.80216
dtype: float32
Epoch 95, train loss: 0.08181398535978245 test loss: 0.1078390651770286
0    7.133421
dtype: float32
Epoch 96, train loss: 0.0680171551876645 test loss: 0.1054580355847744
0    6.963978
dtype: float32
Epoch 97, train loss: 0.06841262464315241 test loss: 0.10428319804131893
0    7.47299
dtype: float32
Epoch 98, train loss: 0.0877877330274045 test loss: 0.1263062886065652
0    6.930709
dtype: float32
Epoch 99, train loss: 0.06978842414861092 test loss: 0.10837203491541691
0    7.154912
dtype: float32
Epoch 100, train loss: 0.06897575874405404 test loss: 0.10465451760052798
0    6.714341
dtype: float32
Epoch 101, train loss: 0.08127351490085521 test loss: 0.1191539319220842
0    6.74748
dtype: float32
Epoch 102, train loss: 0.07787617460207591 test loss: 0.11348151420697652
0    7.300179
dtype: float32
Epoch 103, train loss: 0.07633910156262677 test loss: 0.10750186843835832
0    7.712841
dtype: float32
Epoch 104, train loss: 0.11644319509241549 test loss: 0.14630154949154997
0    7.342392
dtype: float32
Epoch 105, train loss: 0.07939266307097552 test loss: 0.11315960176597424
0    7.367939
dtype: float32
Epoch 106, train loss: 0.08118921314931422 test loss: 0.11345554243167628
0    7.85271
dtype: float32
Epoch 107, train loss: 0.12754800764678517 test loss: 0.1535288074392327
0    7.906917
dtype: float32
Epoch 108, train loss: 0.12601379068572907 test loss: 0.1508941336023366
0    7.619636
dtype: float32
Epoch 109, train loss: 0.09201752904741571 test loss: 0.11454674229296752
0    7.076467
dtype: float32
Epoch 110, train loss: 0.06697653025107313 test loss: 0.09262800573542518
0    6.583287
dtype: float32
Epoch 111, train loss: 0.09147489838212816 test loss: 0.1272160501672378
0    5.674694
dtype: float32
Epoch 112, train loss: 0.21034128502983224 test loss: 0.2537808078284893
0    6.762121
dtype: float32
Epoch 113, train loss: 0.07243150364084927 test loss: 0.11845423780000983
0    7.679648
dtype: float32
Epoch 114, train loss: 0.11178579891296657 test loss: 0.13858815600580068
0    6.892366
dtype: float32
Epoch 115, train loss: 0.0713215023235591 test loss: 0.11875339408102949
0    6.727061
dtype: float32
Epoch 116, train loss: 0.08090512368253285 test loss: 0.13684444758499367
0    6.985908
dtype: float32
Epoch 117, train loss: 0.06637948267335281 test loss: 0.107476798440481
0    7.518811
dtype: float32
Epoch 118, train loss: 0.10061345413575447 test loss: 0.12935975047696813
0    7.695817
dtype: float32
Epoch 119, train loss: 0.1101404011350819 test loss: 0.14864609873498744
0    7.289932
dtype: float32
Epoch 120, train loss: 0.07581462818422188 test loss: 0.11704221051043859
0    7.520704
dtype: float32
Epoch 121, train loss: 0.09791255043778625 test loss: 0.1355819871909454
0    7.519982
dtype: float32
Epoch 122, train loss: 0.11023394958124867 test loss: 0.14049370866384178
0    7.196424
dtype: float32
Epoch 123, train loss: 0.07649004301052359 test loss: 0.12851521686152897
0    6.055693
dtype: float32
Epoch 124, train loss: 0.15652373579297804 test loss: 0.2516493249349609
0    6.98763
dtype: float32
Epoch 125, train loss: 0.06733583956101646 test loss: 0.1270022253307108
0    6.570689
dtype: float32
Epoch 126, train loss: 0.0876499311247302 test loss: 0.15186046799342057
0    6.940412
dtype: float32
Epoch 127, train loss: 0.0647035930914646 test loss: 0.11996260143889191
0    6.69537
dtype: float32
Epoch 128, train loss: 0.07755900499136531 test loss: 0.12136236943906989
0    6.94928
dtype: float32
Epoch 129, train loss: 0.06444378166070412 test loss: 0.11149451448345137
0    6.325312
dtype: float32
Epoch 130, train loss: 0.11502924278902615 test loss: 0.16829728642230213
0    5.775807
dtype: float32
Epoch 131, train loss: 0.20475056811920003 test loss: 0.280488725081502
0    6.516653
dtype: float32
Epoch 132, train loss: 0.11715715517380762 test loss: 0.18617464757179608
0    5.673142
dtype: float32
Epoch 133, train loss: 0.21718949443763705 test loss: 0.2283860278843012
0    6.390355
dtype: float32
Epoch 134, train loss: 0.11500634287226599 test loss: 0.18188178003057823
0    6.709162
dtype: float32
Epoch 135, train loss: 0.07752795108831896 test loss: 0.16385175511321232
0    6.90659
dtype: float32
Epoch 136, train loss: 0.06565182025456529 test loss: 0.12500861288815132
0    7.196109
dtype: float32
Epoch 137, train loss: 0.06929568740641051 test loss: 0.13172481858460786
0    6.970797
dtype: float32
Epoch 138, train loss: 0.06400731149431917 test loss: 0.12666112516051412
0    6.657371
dtype: float32
Epoch 139, train loss: 0.08408996966158022 test loss: 0.14359017659724257
0    6.300589
dtype: float32
Epoch 140, train loss: 0.163513005288163 test loss: 0.3225513025548994
0    6.01124
dtype: float32
Epoch 141, train loss: 0.18833603770981425 test loss: 0.2413212099612172
0    6.195244
dtype: float32
Epoch 142, train loss: 0.16439169838035145 test loss: 0.34127574228594204
0    6.817832
dtype: float32
Epoch 143, train loss: 0.0810678997410855 test loss: 0.2066736278646077
0    7.259804
dtype: float32
Epoch 144, train loss: 0.06946259757686923 test loss: 0.14564587488484418
0    7.428345
dtype: float32
Epoch 145, train loss: 0.0796581099947716 test loss: 0.1331465638579138
0    7.629238
dtype: float32
Epoch 146, train loss: 0.10025070223328895 test loss: 0.13927286164889657
0    7.598938
dtype: float32
Epoch 147, train loss: 0.09963059647099277 test loss: 0.13863440276666783
0    7.177196
dtype: float32
Epoch 148, train loss: 0.06905907510004049 test loss: 0.12700334675280384
0    6.598689
dtype: float32
Epoch 149, train loss: 0.08523085423903691 test loss: 0.1418899042909808
0    6.911609
dtype: float32
Epoch 150, train loss: 0.06285248292202417 test loss: 0.1502328604478201
0    7.110231
dtype: float32
Epoch 151, train loss: 0.06579043061413753 test loss: 0.13466196037677527
0    7.558579
dtype: float32
Epoch 152, train loss: 0.09991793716147815 test loss: 0.13955006818598667
0    7.608172
dtype: float32
Epoch 153, train loss: 0.10293719943267247 test loss: 0.15314291942405953
0    7.109426
dtype: float32
Epoch 154, train loss: 0.06527063015694445 test loss: 0.13712191459318981
0    7.228166
dtype: float32
Epoch 155, train loss: 0.06850629807022053 test loss: 0.11992592231699932
0    7.19326
dtype: float32
Epoch 156, train loss: 0.07038894201183443 test loss: 0.11639073469599105
0    6.384681
dtype: float32
Epoch 157, train loss: 0.11041470601356092 test loss: 0.16862251120890184
0    7.187994
dtype: float32
Epoch 158, train loss: 0.06573435532409466 test loss: 0.14282630053271989
0    7.610298
dtype: float32
Epoch 159, train loss: 0.09948577298299222 test loss: 0.1554473014671582
0    7.528811
dtype: float32
Epoch 160, train loss: 0.08720740248915354 test loss: 0.1369051152116985
0    7.159461
dtype: float32
Epoch 161, train loss: 0.06434475977435788 test loss: 0.1310032774751645
0    6.906721
dtype: float32
Epoch 162, train loss: 0.06236437336801104 test loss: 0.1418692659687086
0    7.062684
dtype: float32
Epoch 163, train loss: 0.062270266791844685 test loss: 0.13247425480793829
0    6.206152
dtype: float32
Epoch 164, train loss: 0.14023977240474422 test loss: 0.18556543822696897
0    6.944021
dtype: float32
Epoch 165, train loss: 0.06328362057058509 test loss: 0.1525644369310644
0    7.392872
dtype: float32
Epoch 166, train loss: 0.0809976961577861 test loss: 0.1350863135067603
0    7.541953
dtype: float32
Epoch 167, train loss: 0.08961193284990479 test loss: 0.14570627533424435
0    7.52868
dtype: float32
Epoch 168, train loss: 0.08086419031784124 test loss: 0.14349045619151937
0    7.167139
dtype: float32
Epoch 169, train loss: 0.06299125200578697 test loss: 0.14019897801639447
0    6.888987
dtype: float32
Epoch 170, train loss: 0.06482260630850958 test loss: 0.14534712218693388
0    7.13575
dtype: float32
Epoch 171, train loss: 0.062465904372101505 test loss: 0.12947655298982963
0    7.342228
dtype: float32
Epoch 172, train loss: 0.07734437949346767 test loss: 0.14113111381559312
0    7.53631
dtype: float32
Epoch 173, train loss: 0.0911483221264024 test loss: 0.1396799646534987
0    6.975926
dtype: float32
Epoch 174, train loss: 0.061218912838090805 test loss: 0.11990023188286636
0    6.738018
dtype: float32
Epoch 175, train loss: 0.07548790390908362 test loss: 0.1444991834510098
0    7.285298
dtype: float32
Epoch 176, train loss: 0.06928603495232454 test loss: 0.1376615442303612
0    7.716966
dtype: float32
Epoch 177, train loss: 0.11319576298653951 test loss: 0.15738027440697885
0    7.615725
dtype: float32
Epoch 178, train loss: 0.10031246382322846 test loss: 0.1534809290462306
0    7.865048
dtype: float32
Epoch 179, train loss: 0.11856274409973216 test loss: 0.16745370367401705
0    7.242274
dtype: float32
Epoch 180, train loss: 0.0685162000203323 test loss: 0.10856698228806527
0    6.843062
dtype: float32
Epoch 181, train loss: 0.06511106140034968 test loss: 0.13342433812339233
0    6.642063
dtype: float32
Epoch 182, train loss: 0.0795859178530049 test loss: 0.15379105215342367
0    5.945494
dtype: float32
Epoch 183, train loss: 0.1838685579451355 test loss: 0.23115311352482004
0    6.098411
dtype: float32
Epoch 184, train loss: 0.15268807360868064 test loss: 0.241409383346399
0    6.717376
dtype: float32
Epoch 185, train loss: 0.06647368983703365 test loss: 0.162968649347554
0    6.579623
dtype: float32
Epoch 186, train loss: 0.08159619603989687 test loss: 0.149711849108798
0    6.907596
dtype: float32
Epoch 187, train loss: 0.06248102401973941 test loss: 0.16941827733459983
0    7.705483
dtype: float32
Epoch 188, train loss: 0.10506548013362813 test loss: 0.16000673417927574
0    7.319513
dtype: float32
Epoch 189, train loss: 0.0702792485008745 test loss: 0.17063488547916625
0    7.230914
dtype: float32
Epoch 190, train loss: 0.06596423928854443 test loss: 0.1451900741487584
0    7.282015
dtype: float32
Epoch 191, train loss: 0.07356834843686823 test loss: 0.14274062266330664
0    7.567358
dtype: float32
Epoch 192, train loss: 0.09314713638434179 test loss: 0.1549509193549013
0    7.590431
dtype: float32
Epoch 193, train loss: 0.09931617313920885 test loss: 0.14102545488586515
0    7.159686
dtype: float32
Epoch 194, train loss: 0.061934034282683556 test loss: 0.12355409893188515
0    6.519002
dtype: float32
Epoch 195, train loss: 0.10247860610562672 test loss: 0.1932792371771589
0    7.122305
dtype: float32
Epoch 196, train loss: 0.06180974617262743 test loss: 0.1312087316813743
0    7.379032
dtype: float32
Epoch 197, train loss: 0.07459615767444773 test loss: 0.1280925714590888
0    7.156781
dtype: float32
Epoch 198, train loss: 0.06199786098171154 test loss: 0.13102199761029176
0    6.86914
dtype: float32
Epoch 199, train loss: 0.06348081257912466 test loss: 0.1470453212432732
0    6.792151
dtype: float32
Epoch 200, train loss: 0.07039341871394461 test loss: 0.16108909488428796
0    6.951467
dtype: float32
Epoch 201, train loss: 0.06075255814971067 test loss: 0.13868475105563569
0    7.039855
dtype: float32
Epoch 202, train loss: 0.059665764735006864 test loss: 0.1449852618500414
0    7.295746
dtype: float32
Epoch 203, train loss: 0.07071781344192503 test loss: 0.12908963387442565
0    7.904789
dtype: float32
Epoch 204, train loss: 0.12547265587716788 test loss: 0.16431847205522634
0    7.698269
dtype: float32
Epoch 205, train loss: 0.09634920182512069 test loss: 0.15185905500080768
0    7.25549
dtype: float32
Epoch 206, train loss: 0.06232734221725271 test loss: 0.14261348316192615
0    6.876475
dtype: float32
Epoch 207, train loss: 0.06547372539136144 test loss: 0.15920056066729618
0    6.897122
dtype: float32
Epoch 208, train loss: 0.060571307448530405 test loss: 0.13875446278036352
0    6.853881
dtype: float32
Epoch 209, train loss: 0.0632219454344825 test loss: 0.14622267089788069
0    6.892982
dtype: float32
Epoch 210, train loss: 0.06109278991495293 test loss: 0.15025309742875823
0    5.761389
dtype: float32
Epoch 211, train loss: 0.20558408958469526 test loss: 0.3487965566650287
0    6.713224
dtype: float32
Epoch 212, train loss: 0.09914062560754168 test loss: 0.21515194047308733
0    7.181924
dtype: float32
Epoch 213, train loss: 0.06169121348431878 test loss: 0.12418808519114734
0    7.752238
dtype: float32
Epoch 214, train loss: 0.1051035844788291 test loss: 0.14501354766945326
0    7.223112
dtype: float32
Epoch 215, train loss: 0.06247613601848816 test loss: 0.11814736227103194
0    8.00838
dtype: float32
Epoch 216, train loss: 0.13880763326097623 test loss: 0.1705938383365099
0    7.39197
dtype: float32
Epoch 217, train loss: 0.06923550513909872 test loss: 0.1296637417179464
0    7.877846
dtype: float32
Epoch 218, train loss: 0.1176694043096341 test loss: 0.1556251963547859
0    7.363208
dtype: float32
Epoch 219, train loss: 0.07387759772070032 test loss: 0.12810867558153452
0    7.423849
dtype: float32
Epoch 220, train loss: 0.08152410010578737 test loss: 0.1391751555498608
0    7.852784
dtype: float32
Epoch 221, train loss: 0.11656876904711326 test loss: 0.17196616351474123
0    7.618621
dtype: float32
Epoch 222, train loss: 0.09185984674004193 test loss: 0.1714114495202424
0    7.396065
dtype: float32
Epoch 223, train loss: 0.07665209828559345 test loss: 0.15354119763861945
0    6.854368
dtype: float32
Epoch 224, train loss: 0.061940927644750315 test loss: 0.1686075676549982
0    6.671847
dtype: float32
Epoch 225, train loss: 0.09093482888614914 test loss: 0.2566201901461488
0    7.124628
dtype: float32
Epoch 226, train loss: 0.06095543467481113 test loss: 0.15399640821334612
0    7.184932
dtype: float32
Epoch 227, train loss: 0.06012572102480116 test loss: 0.1556666275434797
0    7.306761
dtype: float32
Epoch 228, train loss: 0.06638887491057804 test loss: 0.1532917299141207
0    7.38208
dtype: float32
Epoch 229, train loss: 0.07539077979311982 test loss: 0.13902967032773575
0    6.866194
dtype: float32
Epoch 230, train loss: 0.06202043202567583 test loss: 0.1503223068455904
0    7.219402
dtype: float32
Epoch 231, train loss: 0.06264923248666919 test loss: 0.14082034190594125
0    7.50255
dtype: float32
Epoch 232, train loss: 0.0835629783243966 test loss: 0.1461595390905053
0    7.907805
dtype: float32
Epoch 233, train loss: 0.1229764783190096 test loss: 0.16321119132599463
0    7.414166
dtype: float32
Epoch 234, train loss: 0.07690328522465348 test loss: 0.162967748462275
0    6.996192
dtype: float32
Epoch 235, train loss: 0.057735866040793365 test loss: 0.1820307826192787
0    6.949607
dtype: float32
Epoch 236, train loss: 0.0580368588490803 test loss: 0.17986847517188762
0    6.585803
dtype: float32
Epoch 237, train loss: 0.08456458418588875 test loss: 0.2184319614983267
0    6.217061
dtype: float32
Epoch 238, train loss: 0.13191348288210322 test loss: 0.252460379063763
0    6.055965
dtype: float32
Epoch 239, train loss: 0.16846783193827047 test loss: 0.37031313976390995
0    6.850996
dtype: float32
Epoch 240, train loss: 0.05813264611928759 test loss: 0.15077836382672852
0    6.610526
dtype: float32
Epoch 241, train loss: 0.07800899124189935 test loss: 0.1858322189678182
0    7.176673
dtype: float32
Epoch 242, train loss: 0.06351625259572394 test loss: 0.13607246635889977
0    6.782869
dtype: float32
Epoch 243, train loss: 0.05899549122221865 test loss: 0.11986932804972909
0    6.052452
dtype: float32
Epoch 244, train loss: 0.14115264682520962 test loss: 0.16826523722580966
0    6.821998
dtype: float32
Epoch 245, train loss: 0.05890546368674987 test loss: 0.10710751325808185
0    7.093829
dtype: float32
Epoch 246, train loss: 0.06373026076722423 test loss: 0.1131683728795884
0    7.437602
dtype: float32
Epoch 247, train loss: 0.08986133604098162 test loss: 0.13453300179719613
0    7.690773
dtype: float32
Epoch 248, train loss: 0.10539264275327624 test loss: 0.17132449534215155
0    7.239646
dtype: float32
Epoch 249, train loss: 0.06685605842450758 test loss: 0.1403922446934852
0    6.945591
dtype: float32
Epoch 250, train loss: 0.056275496922646814 test loss: 0.13568515236566492
0    6.740171
dtype: float32
Epoch 251, train loss: 0.06541022335592857 test loss: 0.12832926185947865
0    6.675085
dtype: float32
Epoch 252, train loss: 0.06862143857409465 test loss: 0.1378605391300885
0    7.059907
dtype: float32
Epoch 253, train loss: 0.05834037474150539 test loss: 0.12162017643167716
0    6.269924
dtype: float32
Epoch 254, train loss: 0.11727324444137618 test loss: 0.15961906240375695
0    6.954982
dtype: float32
Epoch 255, train loss: 0.05731473516101378 test loss: 0.13528861865741382
0    7.273218
dtype: float32
Epoch 256, train loss: 0.07025570053189996 test loss: 0.1326489743916957
0    7.230783
dtype: float32
Epoch 257, train loss: 0.06519702138883865 test loss: 0.14383316427741524
0    6.896967
dtype: float32
Epoch 258, train loss: 0.057616643026809654 test loss: 0.11966060624069477
0    7.067585
dtype: float32
Epoch 259, train loss: 0.05677315218966653 test loss: 0.13740599489745997
0    7.345771
dtype: float32
Epoch 260, train loss: 0.07557049576299273 test loss: 0.1468390887572534
0    7.248406
dtype: float32
Epoch 261, train loss: 0.06529793130376224 test loss: 0.13539428731935318
0    6.845611
dtype: float32
Epoch 262, train loss: 0.06347277178237144 test loss: 0.1709548118367558
0    6.780562
dtype: float32
Epoch 263, train loss: 0.078670807635161 test loss: 0.21483053796471913
0    7.263431
dtype: float32
Epoch 264, train loss: 0.0591615278945339 test loss: 0.14716270607099338
0    7.460529
dtype: float32
Epoch 265, train loss: 0.08041804084751486 test loss: 0.13757885674863166
0    7.715938
dtype: float32
Epoch 266, train loss: 0.11804374154117775 test loss: 0.15091618600554624
0    6.973167
dtype: float32
Epoch 267, train loss: 0.05581824312009332 test loss: 0.1251003364618487
0    7.248663
dtype: float32
Epoch 268, train loss: 0.06405301299260194 test loss: 0.13102889307192503
0    6.642791
dtype: float32
Epoch 269, train loss: 0.07584271062821622 test loss: 0.13378583132593305
0    7.290381
dtype: float32
Epoch 270, train loss: 0.06732231817416413 test loss: 0.13239009519071732
0    7.227398
dtype: float32
Epoch 271, train loss: 0.061553264580501796 test loss: 0.11685540509305888
0    7.064203
dtype: float32
Epoch 272, train loss: 0.05584383717901643 test loss: 0.11970733071503899
0    6.108909
dtype: float32
Epoch 273, train loss: 0.1467903619542005 test loss: 0.19343371911510032
0    6.771132
dtype: float32
Epoch 274, train loss: 0.0645165285187563 test loss: 0.14559460271216154
0    6.641381
dtype: float32
Epoch 275, train loss: 0.07150033943143437 test loss: 0.16186935275420333
0    6.998306
dtype: float32
Epoch 276, train loss: 0.06107246752247162 test loss: 0.18005783362181912
0    7.560984
dtype: float32
Epoch 277, train loss: 0.08969429906764732 test loss: 0.14542468090368033
0    7.467391
dtype: float32
Epoch 278, train loss: 0.08550242851051303 test loss: 0.13430501639942755
0    7.524564
dtype: float32
Epoch 279, train loss: 0.08993926743047748 test loss: 0.1404089534066301
0    6.870322
dtype: float32
Epoch 280, train loss: 0.05799688614553866 test loss: 0.14623642666696832
0    7.292388
dtype: float32
Epoch 281, train loss: 0.06297376660783266 test loss: 0.12483651362039883
0    7.10113
dtype: float32
Epoch 282, train loss: 0.05519739091175268 test loss: 0.13108066926951262
0    7.267467
dtype: float32
Epoch 283, train loss: 0.06626762116017217 test loss: 0.12945049935467307
0    6.912608
dtype: float32
Epoch 284, train loss: 0.0568900871674375 test loss: 0.11908000098114799
0    7.589393
dtype: float32
Epoch 285, train loss: 0.09683044458185651 test loss: 0.14686957645120977
0    7.269345
dtype: float32
Epoch 286, train loss: 0.07066121102757036 test loss: 0.13146809023864248
0    7.148614
dtype: float32
Epoch 287, train loss: 0.059236988489953527 test loss: 0.12320807151258967
0    7.094866
dtype: float32
Epoch 288, train loss: 0.05542825361597157 test loss: 0.12423039987504184
0    7.211044
dtype: float32
Epoch 289, train loss: 0.06524399314688624 test loss: 0.11194128534252115
0    7.289701
dtype: float32
Epoch 290, train loss: 0.06630253916077837 test loss: 0.13231253514039135
0    7.274116
dtype: float32
Epoch 291, train loss: 0.06469845358734315 test loss: 0.1292083752772348
0    7.311109
dtype: float32
Epoch 292, train loss: 0.07710267805929553 test loss: 0.11724207627855013
0    7.17954
dtype: float32
Epoch 293, train loss: 0.05886273397990176 test loss: 0.12504486483484253
0    7.323978
dtype: float32
Epoch 294, train loss: 0.06536667779707915 test loss: 0.12785116370534252
0    7.140635
dtype: float32
Epoch 295, train loss: 0.056776782426674714 test loss: 0.12617433448297663
0    6.625527
dtype: float32
Epoch 296, train loss: 0.07975880097196673 test loss: 0.16585116812033732
0    6.784006
dtype: float32
Epoch 297, train loss: 0.05958921512742765 test loss: 0.13535633416266962
0    6.462463
dtype: float32
Epoch 298, train loss: 0.09356226612173553 test loss: 0.1594793035475644
0    7.176429
dtype: float32
Epoch 299, train loss: 0.059355395982595004 test loss: 0.14118036729421704
Final train loss is: 0.059355395982595004, Test loss is: 0.14118036729421704
0    7.176429
dtype: float32
round is 4
0    12.307483
dtype: float32
Epoch 8, train loss: 0.2847233506869848 test loss: 0.5240675712780416
0    10.232771
dtype: float32
Epoch 11, train loss: 0.2189088517115423 test loss: 0.34072364399223826
0    12.744904
dtype: float32
Epoch 12, train loss: 0.3147835109794749 test loss: 0.5423021632412761
0    11.156896
dtype: float32
Epoch 13, train loss: 0.19925943594957155 test loss: 0.4165032585018024
0    7.764939
dtype: float32
Epoch 14, train loss: 0.2663334142401159 test loss: 0.23078485975224633
0    9.102972
dtype: float32
Epoch 15, train loss: 0.2055187690439815 test loss: 0.21830619593296013
0    11.806688
dtype: float32
Epoch 17, train loss: 0.26918333456467475 test loss: 0.38270900814750775
0    12.664577
dtype: float32
Epoch 20, train loss: 0.2343533689990717 test loss: 0.5339431572303985
0    11.965132
dtype: float32
Epoch 21, train loss: 0.24420119520021752 test loss: 0.4590011063929729
0    7.378615
dtype: float32
Epoch 22, train loss: 0.20873976698306784 test loss: 0.15362347392793319
0    5.606267
dtype: float32
Epoch 23, train loss: 0.3384382683592811 test loss: 0.35623325016169505
0    7.63242
dtype: float32
Epoch 24, train loss: 0.1968968110841819 test loss: 0.1436343323471129
0    6.086122
dtype: float32
Epoch 25, train loss: 0.26133451702315585 test loss: 0.2719847026839967
0    9.045383
dtype: float32
Epoch 26, train loss: 0.11621632013083134 test loss: 0.20972390661534207
0    9.954301
dtype: float32
Epoch 27, train loss: 0.1309868107398139 test loss: 0.28965544355890926
0    9.261811
dtype: float32
Epoch 28, train loss: 0.16342339957658567 test loss: 0.26529030514355584
0    10.347329
dtype: float32
Epoch 29, train loss: 0.177577492359946 test loss: 0.3354687187589998
0    9.503077
dtype: float32
Epoch 30, train loss: 0.16103513443155193 test loss: 0.27332611798388334
0    8.754542
dtype: float32
Epoch 31, train loss: 0.183204503097548 test loss: 0.23169399305897745
0    8.515697
dtype: float32
Epoch 32, train loss: 0.12429130831726122 test loss: 0.20291464720736352
0    9.747179
dtype: float32
Epoch 33, train loss: 0.17330898770956785 test loss: 0.2960082528386873
0    9.104686
dtype: float32
Epoch 34, train loss: 0.1418225212516109 test loss: 0.2153032709098586
0    5.81062
dtype: float32
Epoch 35, train loss: 0.25755386155685467 test loss: 0.29095438936496226
0    6.130411
dtype: float32
Epoch 36, train loss: 0.3146335090660894 test loss: 0.25264639319519083
0    7.301121
dtype: float32
Epoch 37, train loss: 0.1634317995597305 test loss: 0.14592883107192298
0    6.339118
dtype: float32
Epoch 38, train loss: 0.20864205758852364 test loss: 0.23119145787815448
0    6.935202
dtype: float32
Epoch 39, train loss: 0.14927787124627906 test loss: 0.16811335676162203
0    6.931356
dtype: float32
Epoch 40, train loss: 0.19505196953482176 test loss: 0.1514012224310486
0    6.492236
dtype: float32
Epoch 41, train loss: 0.17192475543281494 test loss: 0.19056586993346597
0    6.977914
dtype: float32
Epoch 42, train loss: 0.14574524841249845 test loss: 0.13665415220131014
0    6.732794
dtype: float32
Epoch 43, train loss: 0.2191111630634418 test loss: 0.16506817280884684
0    6.827669
dtype: float32
Epoch 44, train loss: 0.15295129218129053 test loss: 0.1493470620761801
0    6.854976
dtype: float32
Epoch 45, train loss: 0.14705006588112252 test loss: 0.14447261223126992
0    8.608966
dtype: float32
Epoch 46, train loss: 0.11148934846752445 test loss: 0.1903742024957708
0    8.558443
dtype: float32
Epoch 47, train loss: 0.10089778442656487 test loss: 0.1882210503014965
0    8.342562
dtype: float32
Epoch 48, train loss: 0.11944973911963612 test loss: 0.20744455519603688
0    8.631181
dtype: float32
Epoch 49, train loss: 0.14204332180338566 test loss: 0.22383206503217346
0    6.149751
dtype: float32
Epoch 50, train loss: 0.17964334534635037 test loss: 0.25059301414313856
0    9.872758
dtype: float32
Epoch 51, train loss: 0.16457445009280403 test loss: 0.3307944869727029
0    8.666861
dtype: float32
Epoch 52, train loss: 0.12432044676366513 test loss: 0.22092315125158432
0    9.351188
dtype: float32
Epoch 53, train loss: 0.15717289667488404 test loss: 0.27850983455205985
0    8.409933
dtype: float32
Epoch 54, train loss: 0.09718071087997383 test loss: 0.1742326663817509
0    7.843158
dtype: float32
Epoch 55, train loss: 0.10482936934350497 test loss: 0.129630078633911
0    8.340151
dtype: float32
Epoch 56, train loss: 0.0954119389873026 test loss: 0.1892790799568647
0    6.846642
dtype: float32
Epoch 57, train loss: 0.12093158738079354 test loss: 0.1617306927718972
0    5.782277
dtype: float32
Epoch 58, train loss: 0.2412064219226277 test loss: 0.27376184945289894
0    8.856069
dtype: float32
Epoch 59, train loss: 0.09902206827042921 test loss: 0.19452886198969238
0    6.68781
dtype: float32
Epoch 60, train loss: 0.1702289886776072 test loss: 0.15882184037350502
0    7.556317
dtype: float32
Epoch 61, train loss: 0.10070072849863308 test loss: 0.11689239286643888
0    7.959239
dtype: float32
Epoch 62, train loss: 0.09339280259835735 test loss: 0.1285509875228945
0    6.303417
dtype: float32
Epoch 63, train loss: 0.23516291371946071 test loss: 0.1982105422730736
0    6.938958
dtype: float32
Epoch 64, train loss: 0.18661556790968323 test loss: 0.12956697793846847
0    7.696542
dtype: float32
Epoch 65, train loss: 0.10028854952340306 test loss: 0.16362606883937494
0    8.344318
dtype: float32
Epoch 66, train loss: 0.09597602720699487 test loss: 0.16835925723765954
0    5.612454
dtype: float32
Epoch 67, train loss: 0.21981542884959418 test loss: 0.28584115108662744
0    6.729053
dtype: float32
Epoch 68, train loss: 0.2163190761408803 test loss: 0.14732040244992567
0    6.401461
dtype: float32
Epoch 69, train loss: 0.1559488063833845 test loss: 0.19110575524364254
0    8.440513
dtype: float32
Epoch 70, train loss: 0.11331515211633472 test loss: 0.18727761180686975
0    7.397745
dtype: float32
Epoch 71, train loss: 0.11040844386324035 test loss: 0.13851221393218674
0    8.469181
dtype: float32
Epoch 72, train loss: 0.09545977966084115 test loss: 0.17953072349377128
0    8.432445
dtype: float32
Epoch 73, train loss: 0.08874320211313969 test loss: 0.17354339072997862
0    8.957455
dtype: float32
Epoch 74, train loss: 0.12115392048170787 test loss: 0.2273970559559867
0    8.071768
dtype: float32
Epoch 75, train loss: 0.09393077954567444 test loss: 0.12800612413349705
0    5.627642
dtype: float32
Epoch 76, train loss: 0.1945236240037975 test loss: 0.2850753746500327
0    7.934323
dtype: float32
Epoch 77, train loss: 0.08600777850698488 test loss: 0.14157939758184418
0    8.065082
dtype: float32
Epoch 78, train loss: 0.09321984754191848 test loss: 0.1291862549579383
0    6.395555
dtype: float32
Epoch 79, train loss: 0.15530940387148046 test loss: 0.18392783393937565
0    8.576372
dtype: float32
Epoch 81, train loss: 0.09965040623550848 test loss: 0.17036635920890503
0    8.357347
dtype: float32
Epoch 82, train loss: 0.0883120599862842 test loss: 0.15999540152968714
0    7.241467
dtype: float32
Epoch 83, train loss: 0.11233363426645199 test loss: 0.10363750234269858
0    8.135157
dtype: float32
Epoch 84, train loss: 0.0861596589772626 test loss: 0.1455534857589196
0    7.460063
dtype: float32
Epoch 85, train loss: 0.15840995410517117 test loss: 0.0903423345775385
0    6.088728
dtype: float32
Epoch 86, train loss: 0.15142264575893746 test loss: 0.22820386121703257
0    6.783953
dtype: float32
Epoch 87, train loss: 0.14163479008401425 test loss: 0.1408541056772684
0    7.236314
dtype: float32
Epoch 88, train loss: 0.1140541915232825 test loss: 0.10734766098562824
0    7.45641
dtype: float32
Epoch 89, train loss: 0.09100300279343712 test loss: 0.12768094996112145
0    8.054029
dtype: float32
Epoch 90, train loss: 0.08453809282752013 test loss: 0.1459385647579591
0    7.957211
dtype: float32
Epoch 91, train loss: 0.08840601739024072 test loss: 0.14055026561461478
0    8.470486
dtype: float32
Epoch 92, train loss: 0.08574815177593918 test loss: 0.16478335691327659
0    7.948823
dtype: float32
Epoch 93, train loss: 0.0872727691827678 test loss: 0.1368206590862578
0    8.156958
dtype: float32
Epoch 94, train loss: 0.08073014116805473 test loss: 0.14748135063430404
0    7.592206
dtype: float32
Epoch 95, train loss: 0.1021408479014467 test loss: 0.1068325512372426
0    7.862409
dtype: float32
Epoch 96, train loss: 0.08204532970931698 test loss: 0.12662757553879958
0    7.836564
dtype: float32
Epoch 97, train loss: 0.08075487108660379 test loss: 0.12611036039616855
0    8.726483
dtype: float32
Epoch 98, train loss: 0.11770531541366601 test loss: 0.21149589291379944
0    9.886206
dtype: float32
Epoch 99, train loss: 0.15732516152289067 test loss: 0.30071799707645763
0    8.016019
dtype: float32
Epoch 100, train loss: 0.08465664946028709 test loss: 0.13057639907399055
0    7.762843
dtype: float32
Epoch 101, train loss: 0.0830331108350671 test loss: 0.11078916435184208
0    8.614779
dtype: float32
Epoch 102, train loss: 0.0936690231752502 test loss: 0.17910664337786075
0    8.60652
dtype: float32
Epoch 103, train loss: 0.08362016837392079 test loss: 0.16919107182133222
0    7.234589
dtype: float32
Epoch 104, train loss: 0.10900249866622233 test loss: 0.10429186742225989
0    6.476951
dtype: float32
Epoch 105, train loss: 0.19665516217079143 test loss: 0.17219863428548643
0    6.663965
dtype: float32
Epoch 106, train loss: 0.1343975146329147 test loss: 0.14848850039826933
0    7.049335
dtype: float32
Epoch 107, train loss: 0.10830620594640426 test loss: 0.13416511832378133
0    6.280454
dtype: float32
Epoch 108, train loss: 0.20964293735062517 test loss: 0.20000752133732705
0    7.974904
dtype: float32
Epoch 109, train loss: 0.07996534600839922 test loss: 0.11765035140815519
0    5.590641
dtype: float32
Epoch 110, train loss: 0.22774106854682583 test loss: 0.30387287248214667
0    7.219096
dtype: float32
Epoch 111, train loss: 0.10384024488700963 test loss: 0.10563200274895065
0    8.962935
dtype: float32
Epoch 112, train loss: 0.11167440478514926 test loss: 0.20247605170407654
0    9.036813
dtype: float32
Epoch 113, train loss: 0.12489916097005453 test loss: 0.2119916900930516
0    9.515077
dtype: float32
Epoch 114, train loss: 0.11547884433284 test loss: 0.24951301124105194
0    8.194832
dtype: float32
Epoch 115, train loss: 0.08012855518640406 test loss: 0.1209007603529456
0    8.264566
dtype: float32
Epoch 116, train loss: 0.0777321303395893 test loss: 0.13402630072597774
0    8.54982
dtype: float32
Epoch 117, train loss: 0.0815670676316863 test loss: 0.16785854426891167
0    7.69935
dtype: float32
Epoch 118, train loss: 0.10256447078098836 test loss: 0.09212880031029295
0    7.559861
dtype: float32
Epoch 119, train loss: 0.08334042452037826 test loss: 0.10543857908834765
0    8.06893
dtype: float32
Epoch 120, train loss: 0.07727259963513823 test loss: 0.12811488061395163
0    8.466189
dtype: float32
Epoch 121, train loss: 0.08091675918772036 test loss: 0.1576575635350197
0    8.539536
dtype: float32
Epoch 122, train loss: 0.10374342278899357 test loss: 0.1757982819096985
0    7.857902
dtype: float32
Epoch 123, train loss: 0.07606468329067538 test loss: 0.11186153313987532
0    6.892638
dtype: float32
Epoch 124, train loss: 0.11702588632320227 test loss: 0.12658592835157606
0    6.407639
dtype: float32
Epoch 125, train loss: 0.15547748128510813 test loss: 0.1799953311738523
0    7.696037
dtype: float32
Epoch 126, train loss: 0.0814723389712411 test loss: 0.10112073629512597
0    8.903038
dtype: float32
Epoch 127, train loss: 0.1108109823780871 test loss: 0.206123003882995
0    8.460369
dtype: float32
Epoch 128, train loss: 0.07860800559232663 test loss: 0.1445093998461192
0    8.727709
dtype: float32
Epoch 129, train loss: 0.09435129912464622 test loss: 0.1988632257943599
0    7.819975
dtype: float32
Epoch 130, train loss: 0.07618341397133527 test loss: 0.11946430884161181
0    7.124485
dtype: float32
Epoch 131, train loss: 0.11104686710443264 test loss: 0.11244478264877203
0    7.028343
dtype: float32
Epoch 132, train loss: 0.14220984544233997 test loss: 0.11252554887813869
0    8.032328
dtype: float32
Epoch 133, train loss: 0.07612197621262483 test loss: 0.14131396877308983
0    7.444602
dtype: float32
Epoch 134, train loss: 0.08287978937831 test loss: 0.11130307127882534
0    7.032348
dtype: float32
Epoch 135, train loss: 0.15184695726273514 test loss: 0.11079518413265001
0    7.380487
dtype: float32
Epoch 136, train loss: 0.08690785408968982 test loss: 0.0962864130673151
0    7.824207
dtype: float32
Epoch 137, train loss: 0.07507769759558074 test loss: 0.10837721058352048
0    8.133834
dtype: float32
Epoch 138, train loss: 0.07846846721311726 test loss: 0.12265882498953615
0    7.790375
dtype: float32
Epoch 139, train loss: 0.07469556239500116 test loss: 0.11236590150923427
0    5.661522
dtype: float32
Epoch 140, train loss: 0.17114846753360008 test loss: 0.2728127224008766
0    7.984718
dtype: float32
Epoch 141, train loss: 0.0751646635182088 test loss: 0.11216328743141003
0    8.322483
dtype: float32
Epoch 142, train loss: 0.08419356516478153 test loss: 0.14005863288445608
0    8.479285
dtype: float32
Epoch 143, train loss: 0.10017777689954001 test loss: 0.1700616334494525
0    7.708532
dtype: float32
Epoch 144, train loss: 0.07579868755605533 test loss: 0.104608338925431
0    7.887525
dtype: float32
Epoch 145, train loss: 0.08146010503700606 test loss: 0.12479741595549317
0    7.789807
dtype: float32
Epoch 146, train loss: 0.07403244771050199 test loss: 0.10732116943341834
0    6.418462
dtype: float32
Epoch 147, train loss: 0.15516031255188736 test loss: 0.17167666732774733
0    6.766407
dtype: float32
Epoch 148, train loss: 0.15318013150364607 test loss: 0.13645134265894807
0    6.138717
dtype: float32
Epoch 149, train loss: 0.13356536911307967 test loss: 0.206271504767086
0    7.656865
dtype: float32
Epoch 150, train loss: 0.07892714835443276 test loss: 0.12284592717776255
0    7.915167
dtype: float32
Epoch 151, train loss: 0.09342616854064295 test loss: 0.10734295003574353
0    8.273332
dtype: float32
Epoch 152, train loss: 0.08976385549143459 test loss: 0.16196747291813196
0    7.938793
dtype: float32
Epoch 153, train loss: 0.08837974394866879 test loss: 0.13574314427643452
0    8.399043
dtype: float32
Epoch 154, train loss: 0.07958719891497694 test loss: 0.1417931298326455
0    7.919437
dtype: float32
Epoch 155, train loss: 0.07401788640672795 test loss: 0.10833669598054334
0    7.74859
dtype: float32
Epoch 156, train loss: 0.07286502567862735 test loss: 0.10820606248721736
0    7.053973
dtype: float32
Epoch 157, train loss: 0.09166287577089757 test loss: 0.11037982211039063
0    8.26533
dtype: float32
Epoch 158, train loss: 0.07925004909259885 test loss: 0.15507169849522617
0    7.868527
dtype: float32
Epoch 159, train loss: 0.073821796856704 test loss: 0.12115996384985235
0    8.387358
dtype: float32
Epoch 160, train loss: 0.10287246080936281 test loss: 0.1652167918081708
0    8.462691
dtype: float32
Epoch 161, train loss: 0.07896511710744444 test loss: 0.15232745661330618
0    7.785306
dtype: float32
Epoch 162, train loss: 0.08688825137187949 test loss: 0.09237225723623174
0    6.061103
dtype: float32
Epoch 163, train loss: 0.14182321581179874 test loss: 0.21266289009836606
0    6.432599
dtype: float32
Epoch 164, train loss: 0.1521374993560994 test loss: 0.17063768729818696
0    6.465261
dtype: float32
Epoch 165, train loss: 0.14097979666483804 test loss: 0.16812416460086804
0    7.445053
dtype: float32
Epoch 166, train loss: 0.0971767305561862 test loss: 0.0967604142436952
0    7.520407
dtype: float32
Epoch 167, train loss: 0.07853869478570542 test loss: 0.09778941501541975
0    7.521125
dtype: float32
Epoch 168, train loss: 0.07946710332599821 test loss: 0.09344860618591505
0    7.761576
dtype: float32
Epoch 169, train loss: 0.0768348087994136 test loss: 0.10393631277182888
0    8.438465
dtype: float32
Epoch 170, train loss: 0.07592123084137417 test loss: 0.15296401628140846
0    7.997028
dtype: float32
Epoch 171, train loss: 0.0841434275357031 test loss: 0.10664935924738436
0    8.276213
dtype: float32
Epoch 172, train loss: 0.07524778109149038 test loss: 0.13006557200844007
0    7.636676
dtype: float32
Epoch 173, train loss: 0.07419899970939081 test loss: 0.09667894767709356
0    6.373243
dtype: float32
Epoch 174, train loss: 0.1409462054499171 test loss: 0.1787426301393714
0    6.291994
dtype: float32
Epoch 175, train loss: 0.14858560966189868 test loss: 0.1928078768295569
0    7.460393
dtype: float32
Epoch 176, train loss: 0.11562190370497244 test loss: 0.08411769114258223
0    8.258151
dtype: float32
Epoch 177, train loss: 0.07638492827462956 test loss: 0.14008396764124117
0    7.954853
dtype: float32
Epoch 178, train loss: 0.07472924583584267 test loss: 0.10213027889441492
0    8.620308
dtype: float32
Epoch 179, train loss: 0.12282578213223737 test loss: 0.17985893120198643
0    7.906075
dtype: float32
Epoch 180, train loss: 0.0757749980266299 test loss: 0.11819586340443028
0    7.645571
dtype: float32
Epoch 181, train loss: 0.07881718429948112 test loss: 0.09902045887875052
0    7.985122
dtype: float32
Epoch 182, train loss: 0.08503165420362074 test loss: 0.10593375154498838
0    7.654229
dtype: float32
Epoch 183, train loss: 0.07354963057106288 test loss: 0.10358219071033013
0    8.15837
dtype: float32
Epoch 184, train loss: 0.06984311754700982 test loss: 0.12602655608628677
0    6.857736
dtype: float32
Epoch 185, train loss: 0.16855401896698777 test loss: 0.12920874917763506
0    7.449196
dtype: float32
Epoch 186, train loss: 0.07988729399315161 test loss: 0.10072392203181516
0    7.626095
dtype: float32
Epoch 187, train loss: 0.07491843824761779 test loss: 0.10486270719690181
0    8.551221
dtype: float32
Epoch 188, train loss: 0.07567907556282255 test loss: 0.16611294282643674
0    7.922019
dtype: float32
Epoch 189, train loss: 0.07994793750700104 test loss: 0.10830303713176306
0    7.540362
dtype: float32
Epoch 190, train loss: 0.0758211574115853 test loss: 0.09891320429720832
0    8.249319
dtype: float32
Epoch 191, train loss: 0.08579293827578348 test loss: 0.12607091625416417
0    7.883627
dtype: float32
Epoch 192, train loss: 0.0724379891845516 test loss: 0.11876066376629442
0    8.632639
dtype: float32
Epoch 193, train loss: 0.12397651274732241 test loss: 0.18837941383480156
0    7.762584
dtype: float32
Epoch 194, train loss: 0.09340372214672008 test loss: 0.08391883935861943
0    7.75501
dtype: float32
Epoch 195, train loss: 0.10491389317228259 test loss: 0.08959978093500534
0    6.626191
dtype: float32
Epoch 196, train loss: 0.13141793237125934 test loss: 0.15054149764885202
0    7.173337
dtype: float32
Epoch 197, train loss: 0.09133779937463612 test loss: 0.10437953146863833
0    7.400047
dtype: float32
Epoch 198, train loss: 0.09161115529137144 test loss: 0.0911837307342355
0    7.254888
dtype: float32
Epoch 199, train loss: 0.0920402248827369 test loss: 0.09223347180347735
0    7.453543
dtype: float32
Epoch 200, train loss: 0.08395407233905591 test loss: 0.08305184061770395
0    7.009278
dtype: float32
Epoch 201, train loss: 0.1051037755031018 test loss: 0.11204613714453467
0    7.652519
dtype: float32
Epoch 202, train loss: 0.07490717346749245 test loss: 0.08608977046714378
0    7.998979
dtype: float32
Epoch 203, train loss: 0.06891306197780116 test loss: 0.10934352565304037
0    6.840558
dtype: float32
Epoch 204, train loss: 0.10202218862933934 test loss: 0.1284600183494612
0    7.720578
dtype: float32
Epoch 205, train loss: 0.09484569325627361 test loss: 0.09338060182657522
0    7.428706
dtype: float32
Epoch 206, train loss: 0.07771296616219688 test loss: 0.1016271161696067
0    7.174448
dtype: float32
Epoch 207, train loss: 0.09172219103659622 test loss: 0.110146729790163
0    7.722718
dtype: float32
Epoch 208, train loss: 0.07283329272361914 test loss: 0.09915369322097485
0    7.459769
dtype: float32
Epoch 209, train loss: 0.08025810573038278 test loss: 0.0952644793290391
0    7.227131
dtype: float32
Epoch 210, train loss: 0.086261718093647 test loss: 0.10339348869532591
0    8.060153
dtype: float32
Epoch 211, train loss: 0.0680075196213999 test loss: 0.11462512980341397
0    8.645131
dtype: float32
Epoch 212, train loss: 0.08749994191906371 test loss: 0.17073943349134393
0    7.752327
dtype: float32
Epoch 213, train loss: 0.07363500148486313 test loss: 0.09424348082916754
0    8.471638
dtype: float32
Epoch 214, train loss: 0.07241715975679351 test loss: 0.14260351811630448
0    8.541813
dtype: float32
Epoch 215, train loss: 0.082437915530466 test loss: 0.1590505330366101
0    8.724065
dtype: float32
Epoch 216, train loss: 0.07679205304839946 test loss: 0.1648123981809072
0    8.175949
dtype: float32
Epoch 217, train loss: 0.06818959197151903 test loss: 0.11889374293942458
0    7.164182
dtype: float32
Epoch 218, train loss: 0.09468459028948689 test loss: 0.10306044265969472
0    8.232533
dtype: float32
Epoch 219, train loss: 0.06814408669024118 test loss: 0.12327654953971243
0    8.521639
dtype: float32
Epoch 220, train loss: 0.07329308812437332 test loss: 0.1509573884223027
0    8.37964
dtype: float32
Epoch 221, train loss: 0.07587751792831945 test loss: 0.1423063012449675
0    7.655293
dtype: float32
Epoch 222, train loss: 0.0816269666456818 test loss: 0.09206668719957033
0    8.351614
dtype: float32
Epoch 223, train loss: 0.06877499541240838 test loss: 0.13874757141476735
0    7.875427
dtype: float32
Epoch 224, train loss: 0.07670004890805235 test loss: 0.09667900932921866
0    8.548692
dtype: float32
Epoch 225, train loss: 0.07419690262326803 test loss: 0.15352001273318086
0    8.252981
dtype: float32
Epoch 226, train loss: 0.06912390863870062 test loss: 0.11970738836889147
0    8.808858
dtype: float32
Epoch 227, train loss: 0.1053782530279688 test loss: 0.19050020176201918
0    8.131801
dtype: float32
Epoch 228, train loss: 0.06835419140429584 test loss: 0.1147234052929784
0    7.317623
dtype: float32
Epoch 229, train loss: 0.08205773253554648 test loss: 0.0983514809884287
0    7.51124
dtype: float32
Epoch 230, train loss: 0.08394971153200388 test loss: 0.08604587492948121
0    6.737793
dtype: float32
Epoch 231, train loss: 0.11599658496835268 test loss: 0.13865268085229557
0    7.336561
dtype: float32
Epoch 232, train loss: 0.08825856784915988 test loss: 0.08976890187190517
0    7.266722
dtype: float32
Epoch 233, train loss: 0.08428328885662131 test loss: 0.09238578984297621
0    7.897481
dtype: float32
Epoch 234, train loss: 0.09090541442596405 test loss: 0.08387299602992122
0    7.02466
dtype: float32
Epoch 235, train loss: 0.09396972005261725 test loss: 0.10968582616510737
0    7.817617
dtype: float32
Epoch 236, train loss: 0.06851101684274863 test loss: 0.09173481072330389
0    8.290029
dtype: float32
Epoch 237, train loss: 0.06988747391783524 test loss: 0.1289041619382694
0    7.932442
dtype: float32
Epoch 238, train loss: 0.06716250931867174 test loss: 0.10032828366156343
0    7.968676
dtype: float32
Epoch 239, train loss: 0.06630345706013642 test loss: 0.10365864061596514
0    7.759157
dtype: float32
Epoch 240, train loss: 0.06905546135679785 test loss: 0.09205358819595638
0    7.513777
dtype: float32
Epoch 241, train loss: 0.08864674980593737 test loss: 0.08528656541248761
0    6.759346
dtype: float32
Epoch 242, train loss: 0.16186135234327834 test loss: 0.15272107468863863
0    7.890836
dtype: float32
Epoch 243, train loss: 0.07734127253651481 test loss: 0.08822756068812661
0    8.200318
dtype: float32
Epoch 244, train loss: 0.06791855331024164 test loss: 0.11716603935896094
0    8.112847
dtype: float32
Epoch 245, train loss: 0.07317355611211838 test loss: 0.10736736173815804
0    7.188372
dtype: float32
Epoch 246, train loss: 0.12529409845990472 test loss: 0.100000093485136
0    7.80166
dtype: float32
Epoch 247, train loss: 0.07890522903012456 test loss: 0.12191861462342032
0    8.692152
dtype: float32
Epoch 248, train loss: 0.14627668253163922 test loss: 0.2056571141309189
0    7.976187
dtype: float32
Epoch 249, train loss: 0.09598752877308471 test loss: 0.12119056963137372
0    7.672804
dtype: float32
Epoch 250, train loss: 0.07330897448385558 test loss: 0.09388993176666777
0    8.500946
dtype: float32
Epoch 251, train loss: 0.07632759845775818 test loss: 0.14502904476453732
0    8.412723
dtype: float32
Epoch 252, train loss: 0.07420976748226255 test loss: 0.13617175365578169
0    9.276405
dtype: float32
Epoch 253, train loss: 0.09964333536978735 test loss: 0.2199649086485443
0    7.632753
dtype: float32
Epoch 254, train loss: 0.08028132423975305 test loss: 0.09145325941807803
0    8.31876
dtype: float32
Epoch 255, train loss: 0.06790542514226225 test loss: 0.1410419150957776
0    8.028473
dtype: float32
Epoch 256, train loss: 0.06576375609224018 test loss: 0.11375192661540208
0    7.286316
dtype: float32/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters

Epoch 257, train loss: 0.08293886137686134 test loss: 0.09550703797905498
0    7.146035
dtype: float32
Epoch 258, train loss: 0.09198166380692072 test loss: 0.10283059497508422
0    7.723433
dtype: float32
Epoch 259, train loss: 0.10161612018021704 test loss: 0.08327338756303404
0    7.945008
dtype: float32
Epoch 260, train loss: 0.06700623104445819 test loss: 0.09984009028687751
0    8.771251
dtype: float32
Epoch 261, train loss: 0.0792662494397406 test loss: 0.1720684878895621
0    8.551113
dtype: float32
Epoch 262, train loss: 0.09669618927110694 test loss: 0.1683435821858852
0    8.533221
dtype: float32
Epoch 263, train loss: 0.08628356466724635 test loss: 0.15451694883784056
0    8.291644
dtype: float32
Epoch 264, train loss: 0.06772442779557204 test loss: 0.13068035673273007
0    8.855373
dtype: float32
Epoch 265, train loss: 0.0826466017103614 test loss: 0.17794636427783178
0    7.933697
dtype: float32
Epoch 266, train loss: 0.07847799761494469 test loss: 0.12219869379828605
0    8.188272
dtype: float32
Epoch 267, train loss: 0.06569254561244642 test loss: 0.11583672750233781
0    8.456649
dtype: float32
Epoch 268, train loss: 0.06784278657758087 test loss: 0.13572102114090068
0    8.823256
dtype: float32
Epoch 269, train loss: 0.0805600201815145 test loss: 0.1704484059324768
0    7.753941
dtype: float32
Epoch 270, train loss: 0.07303589798240297 test loss: 0.0906581914805232
0    8.212259
dtype: float32
Epoch 271, train loss: 0.06834144070209829 test loss: 0.11413977768579149
0    8.554369
dtype: float32
Epoch 272, train loss: 0.07566653514381569 test loss: 0.1475509076570051
0    8.54
dtype: float32
Epoch 273, train loss: 0.09038694446322114 test loss: 0.14850903422624942
0    7.077971
dtype: float32
Epoch 274, train loss: 0.08776477749465737 test loss: 0.11017792913080672
0    8.35743
dtype: float32
Epoch 275, train loss: 0.0700313972208737 test loss: 0.12771481238768922
0    7.781674
dtype: float32
Epoch 276, train loss: 0.07656486745220485 test loss: 0.09892025124114728
0    8.200922
dtype: float32
Epoch 277, train loss: 0.07767131581310294 test loss: 0.12850098002425478
0    8.664724
dtype: float32
Epoch 278, train loss: 0.09548421996787532 test loss: 0.15912134162368125
0    7.513184
dtype: float32
Epoch 279, train loss: 0.08883811250012069 test loss: 0.08723854929352896
0    8.197622
dtype: float32
Epoch 280, train loss: 0.06518453382550454 test loss: 0.10464629795614275
0    8.207758
dtype: float32
Epoch 281, train loss: 0.06573060652066613 test loss: 0.11145135570275427
0    8.472448
dtype: float32
Epoch 282, train loss: 0.07904716341362111 test loss: 0.1415686506457831
0    7.653719
dtype: float32
Epoch 283, train loss: 0.07033629210081488 test loss: 0.08861475979473013
0    8.65093
dtype: float32
Epoch 284, train loss: 0.09560450339149101 test loss: 0.15971469953577452
0    8.214467
dtype: float32
Epoch 285, train loss: 0.06648443479321171 test loss: 0.11139710773259233
0    8.976877
dtype: float32
Epoch 286, train loss: 0.08265390447632913 test loss: 0.1835964224045248
0    7.453074
dtype: float32
Epoch 287, train loss: 0.08982054107272722 test loss: 0.08919818366517338
0    8.165775
dtype: float32
Epoch 288, train loss: 0.07124253826572517 test loss: 0.10638908990221231
0    8.638137
dtype: float32
Epoch 289, train loss: 0.0908959928857737 test loss: 0.15704539181143679
0    9.04113
dtype: float32
Epoch 290, train loss: 0.1004369444102265 test loss: 0.19241319233564494
0    7.583405
dtype: float32
Epoch 291, train loss: 0.07279562931117796 test loss: 0.08759828726307262
0    8.163268
dtype: float32
Epoch 292, train loss: 0.06570034100221643 test loss: 0.10860504819601513
0    8.408043
dtype: float32
Epoch 293, train loss: 0.07791221552613463 test loss: 0.13404926521607474
0    8.211532
dtype: float32
Epoch 294, train loss: 0.06530233426546563 test loss: 0.10757424968884889
0    8.571195
dtype: float32
Epoch 295, train loss: 0.06998202645291957 test loss: 0.1403743137954822
0    8.723404
dtype: float32
Epoch 296, train loss: 0.07819987272996003 test loss: 0.15687126726351802
0    8.544374
dtype: float32
Epoch 297, train loss: 0.10409480845488193 test loss: 0.14386739411070681
0    8.672419
dtype: float32
Epoch 298, train loss: 0.0753144473615324 test loss: 0.14021173620764638
0    7.257154
dtype: float32
Epoch 299, train loss: 0.0808505567780499 test loss: 0.09992923616998237
Final train loss is: 0.0808505567780499, Test loss is: 0.09992923616998237
0    7.257154
dtype: float32
